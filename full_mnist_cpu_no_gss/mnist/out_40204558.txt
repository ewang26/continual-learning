Using CPU
Running experiment mnist:
Results are stored in: full_mnist_cpu_no_gss/mnist
with hyperparameters {'p': 0.9, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 3, 'class_balanced': True, 'max_data_size': 6000, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 2348.918, val loss: 113.659, train acc: 0.967, val acc: 0.986
diff inf
epoch 2 train loss: 806.905, val loss: 161.954, train acc: 0.988, val acc: 0.980
diff 48.295173542943104
Training model M2
epoch 1 train loss: 3769.536, val loss: 274.117, train acc: 0.958, val acc: 0.971
diff inf
epoch 2 train loss: 1321.017, val loss: 188.129, train acc: 0.985, val acc: 0.981
diff 85.98819326701798
Training model M3
epoch 1 train loss: 3865.131, val loss: 138.112, train acc: 0.957, val acc: 0.988
diff inf
epoch 2 train loss: 1283.463, val loss: 86.504, train acc: 0.985, val acc: 0.992
diff 51.608348219590255
Training model M3
epoch 1 train loss: 778.071, val loss: 193.495, train acc: 0.992, val acc: 0.980
diff inf
epoch 2 train loss: 467.767, val loss: 185.648, train acc: 0.995, val acc: 0.987
diff 7.8474611589147685
Training model M3
epoch 1 train loss: 786.172, val loss: 44.298, train acc: 0.991, val acc: 0.994
diff inf
epoch 2 train loss: 371.611, val loss: 68.411, train acc: 0.996, val acc: 0.995
diff 24.113504921109893
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
