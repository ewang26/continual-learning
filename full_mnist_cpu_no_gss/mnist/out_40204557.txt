Using CPU
Running experiment mnist:
Results are stored in: full_mnist_cpu_no_gss/mnist
with hyperparameters {'p': 0.9, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 2, 'class_balanced': True, 'max_data_size': 6000, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 2437.255, val loss: 116.238, train acc: 0.966, val acc: 0.985
diff inf
epoch 2 train loss: 754.569, val loss: 121.453, train acc: 0.988, val acc: 0.983
diff 5.214810472920405
Training model M2
epoch 1 train loss: 3905.566, val loss: 298.949, train acc: 0.955, val acc: 0.971
diff inf
epoch 2 train loss: 1372.606, val loss: 178.319, train acc: 0.985, val acc: 0.982
diff 120.630036545694
Training model M3
epoch 1 train loss: 3888.825, val loss: 157.647, train acc: 0.956, val acc: 0.986
diff inf
epoch 2 train loss: 1315.666, val loss: 98.884, train acc: 0.985, val acc: 0.990
diff 58.76253265157753
Training model M3
epoch 1 train loss: 829.170, val loss: 187.727, train acc: 0.990, val acc: 0.981
diff inf
epoch 2 train loss: 448.675, val loss: 200.039, train acc: 0.995, val acc: 0.983
diff 12.31246467087334
Training model M3
epoch 1 train loss: 822.493, val loss: 69.677, train acc: 0.992, val acc: 0.994
diff inf
epoch 2 train loss: 458.232, val loss: 59.196, train acc: 0.995, val acc: 0.996
diff 10.480978174531565
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
