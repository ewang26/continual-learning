Using CPU
Running experiment mnist:
Results are stored in: random_new_architecture_low_threshold/mnist
with hyperparameters {'p': 0.5, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 1, 'class_balanced': True, 'max_data_size': 6000, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 6372.800, val loss: 595.340, train acc: 0.907, val acc: 0.923
diff inf
epoch 2 train loss: 3612.034, val loss: 342.224, train acc: 0.949, val acc: 0.958
diff 253.11630836440912
Training model M2
epoch 1 train loss: 11220.106, val loss: 734.569, train acc: 0.867, val acc: 0.927
diff inf
epoch 2 train loss: 6141.854, val loss: 550.070, train acc: 0.928, val acc: 0.944
diff 184.498754953642
Training model M3
epoch 1 train loss: 8450.947, val loss: 830.664, train acc: 0.842, val acc: 0.918
diff inf
epoch 2 train loss: 4828.264, val loss: 1000.054, train acc: 0.915, val acc: 0.893
diff 169.38979756477124
Training model M3
epoch 1 train loss: 1916.788, val loss: 1333.970, train acc: 0.966, val acc: 0.887
diff inf
epoch 2 train loss: 1585.917, val loss: 1895.096, train acc: 0.971, val acc: 0.863
diff 561.1260322717842
Training model M3
epoch 1 train loss: 5857.278, val loss: 611.985, train acc: 0.903, val acc: 0.941
diff inf
epoch 2 train loss: 4334.917, val loss: 555.448, train acc: 0.922, val acc: 0.939
diff 56.53668301539517
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
