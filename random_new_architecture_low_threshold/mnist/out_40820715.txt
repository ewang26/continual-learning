Using CPU
Running experiment mnist:
Results are stored in: random_new_architecture_low_threshold/mnist
with hyperparameters {'p': 0.9, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 3, 'class_balanced': True, 'max_data_size': 6000, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 6544.706, val loss: 529.270, train acc: 0.902, val acc: 0.929
diff inf
epoch 2 train loss: 3598.274, val loss: 356.767, train acc: 0.949, val acc: 0.958
diff 172.502918485186
Training model M2
epoch 1 train loss: 11345.812, val loss: 914.330, train acc: 0.869, val acc: 0.909
diff inf
epoch 2 train loss: 6255.239, val loss: 611.721, train acc: 0.929, val acc: 0.938
diff 302.60915272860757
Training model M3
epoch 1 train loss: 11413.184, val loss: 829.282, train acc: 0.869, val acc: 0.913
diff inf
epoch 2 train loss: 6647.851, val loss: 659.745, train acc: 0.923, val acc: 0.929
diff 169.53691274273478
Training model M3
epoch 1 train loss: 4070.714, val loss: 841.431, train acc: 0.953, val acc: 0.932
diff inf
epoch 2 train loss: 3525.764, val loss: 652.442, train acc: 0.958, val acc: 0.946
diff 188.98944792771272
Training model M3
epoch 1 train loss: 5153.454, val loss: 601.795, train acc: 0.944, val acc: 0.942
diff inf
epoch 2 train loss: 4499.657, val loss: 419.934, train acc: 0.949, val acc: 0.957
diff 181.86107571856826
training representation using icarl loss
training representation using icarl loss
