Using CPU
Running experiment mnist:
Results are stored in: random_new_architecture_low_threshold/mnist
with hyperparameters {'p': 0.9, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 4, 'class_balanced': True, 'max_data_size': 6000, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 6346.257, val loss: 524.697, train acc: 0.908, val acc: 0.932
diff inf
epoch 2 train loss: 3526.833, val loss: 352.165, train acc: 0.948, val acc: 0.957
diff 172.53181481284304
Training model M2
epoch 1 train loss: 10975.165, val loss: 774.336, train acc: 0.870, val acc: 0.927
diff inf
epoch 2 train loss: 6043.323, val loss: 675.637, train acc: 0.930, val acc: 0.935
diff 98.69857538267831
Training model M3
epoch 1 train loss: 11246.384, val loss: 784.408, train acc: 0.870, val acc: 0.922
diff inf
epoch 2 train loss: 6369.356, val loss: 542.440, train acc: 0.927, val acc: 0.945
diff 241.9675622404784
Training model M3
epoch 1 train loss: 3972.069, val loss: 696.925, train acc: 0.953, val acc: 0.938
diff inf
epoch 2 train loss: 3402.373, val loss: 660.167, train acc: 0.959, val acc: 0.945
diff 36.75791089673851
Training model M3
epoch 1 train loss: 5004.153, val loss: 710.400, train acc: 0.946, val acc: 0.931
diff inf
epoch 2 train loss: 4337.424, val loss: 556.649, train acc: 0.951, val acc: 0.942
diff 153.75122598910866
training representation using icarl loss
training representation using icarl loss
