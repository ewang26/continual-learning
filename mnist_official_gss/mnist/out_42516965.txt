Using CPU
Running experiment mnist:
Results are stored in: mnist_official_gss/mnist
with hyperparameters {'p': 0.002, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 4, 'class_balanced': True, 'execute_early_stopping': False, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 6346.257, val loss: 524.697, train acc: 0.908, val acc: 0.932
diff inf
epoch 2 train loss: 3526.833, val loss: 352.165, train acc: 0.948, val acc: 0.957
diff 172.53181481284304
epoch 3 train loss: 2853.400, val loss: 356.926, train acc: 0.959, val acc: 0.956
diff 4.761417214120911
epoch 4 train loss: 2357.192, val loss: 298.681, train acc: 0.966, val acc: 0.968
diff 58.244707854412354
epoch 5 train loss: 2048.086, val loss: 315.725, train acc: 0.971, val acc: 0.963
diff 17.043988375709716
epoch 6 train loss: 1850.673, val loss: 359.747, train acc: 0.973, val acc: 0.968
diff 44.02180887088798
epoch 7 train loss: 1741.574, val loss: 356.018, train acc: 0.974, val acc: 0.960
diff 3.729557415687907
epoch 8 train loss: 1673.385, val loss: 316.747, train acc: 0.976, val acc: 0.966
diff 39.27058034856515
epoch 9 train loss: 1471.840, val loss: 284.985, train acc: 0.979, val acc: 0.974
diff 31.76194097323804
epoch 10 train loss: 1531.501, val loss: 295.490, train acc: 0.979, val acc: 0.974
diff 10.505207275188525
epoch 11 train loss: 1224.543, val loss: 341.147, train acc: 0.982, val acc: 0.973
diff 45.6566016502415
epoch 12 train loss: 1240.388, val loss: 398.917, train acc: 0.981, val acc: 0.965
diff 57.76951407069356
epoch 13 train loss: 1212.409, val loss: 379.070, train acc: 0.982, val acc: 0.972
diff 19.846723325450796
epoch 14 train loss: 1292.740, val loss: 342.477, train acc: 0.982, val acc: 0.970
diff 36.59276563676207
epoch 15 train loss: 1072.005, val loss: 320.578, train acc: 0.984, val acc: 0.970
diff 21.898870412607778
epoch 16 train loss: 1071.659, val loss: 363.456, train acc: 0.985, val acc: 0.971
diff 42.878034418912534
epoch 17 train loss: 1035.882, val loss: 354.481, train acc: 0.984, val acc: 0.969
diff 8.974939940417812
epoch 18 train loss: 1096.481, val loss: 453.749, train acc: 0.985, val acc: 0.964
diff 99.26749143898132
epoch 19 train loss: 1050.807, val loss: 490.040, train acc: 0.986, val acc: 0.958
diff 36.29114551047667
epoch 20 train loss: 836.123, val loss: 465.786, train acc: 0.988, val acc: 0.966
diff 24.25389968512917
epoch 21 train loss: 1070.807, val loss: 458.245, train acc: 0.986, val acc: 0.968
diff 7.541428992910767
epoch 22 train loss: 981.378, val loss: 548.052, train acc: 0.988, val acc: 0.968
diff 89.80742186202798
epoch 23 train loss: 948.288, val loss: 396.682, train acc: 0.987, val acc: 0.973
diff 151.3697100898549
epoch 24 train loss: 951.577, val loss: 439.052, train acc: 0.988, val acc: 0.971
diff 42.36961184039359
epoch 25 train loss: 876.708, val loss: 562.593, train acc: 0.988, val acc: 0.964
diff 123.54067614582095
epoch 26 train loss: 845.559, val loss: 371.951, train acc: 0.989, val acc: 0.978
diff 190.64197092881045
epoch 27 train loss: 805.899, val loss: 618.872, train acc: 0.990, val acc: 0.966
diff 246.92146520673987
epoch 28 train loss: 781.318, val loss: 562.027, train acc: 0.990, val acc: 0.969
diff 56.845230255657384
epoch 29 train loss: 773.377, val loss: 468.716, train acc: 0.989, val acc: 0.969
diff 93.31110017140116
epoch 30 train loss: 761.449, val loss: 544.143, train acc: 0.990, val acc: 0.971
diff 75.4272536615594
Training model M2
epoch 1 train loss: 11123.883, val loss: 762.668, train acc: 0.871, val acc: 0.925
diff inf
epoch 2 train loss: 6305.916, val loss: 667.822, train acc: 0.928, val acc: 0.931
diff 94.84616058711913
epoch 3 train loss: 5148.517, val loss: 637.993, train acc: 0.942, val acc: 0.934
diff 29.82843260923198
epoch 4 train loss: 4493.907, val loss: 540.583, train acc: 0.949, val acc: 0.950
diff 97.41014899651441
