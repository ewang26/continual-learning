Using CPU
Running experiment mnist:
Results are stored in: mnist_official_gss/mnist
with hyperparameters {'p': 0.005, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 3, 'class_balanced': True, 'execute_early_stopping': False, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 6544.706, val loss: 529.270, train acc: 0.902, val acc: 0.929
diff inf
epoch 2 train loss: 3598.274, val loss: 356.767, train acc: 0.949, val acc: 0.958
diff 172.502918485186
epoch 3 train loss: 2865.322, val loss: 326.673, train acc: 0.960, val acc: 0.963
diff 30.093525699260283
epoch 4 train loss: 2434.285, val loss: 325.554, train acc: 0.965, val acc: 0.965
diff 1.1196443550580284
epoch 5 train loss: 2124.135, val loss: 370.508, train acc: 0.970, val acc: 0.959
diff 44.95381532711468
epoch 6 train loss: 1896.747, val loss: 340.304, train acc: 0.973, val acc: 0.967
diff 30.203918904497925
epoch 7 train loss: 1825.603, val loss: 348.021, train acc: 0.973, val acc: 0.963
diff 7.717271263609916
epoch 8 train loss: 1550.792, val loss: 353.684, train acc: 0.977, val acc: 0.961
diff 5.662952542066023
epoch 9 train loss: 1425.594, val loss: 413.720, train acc: 0.979, val acc: 0.966
diff 60.03564486992025
epoch 10 train loss: 1499.523, val loss: 265.443, train acc: 0.978, val acc: 0.974
diff 148.2767500721406
epoch 11 train loss: 1283.842, val loss: 314.927, train acc: 0.982, val acc: 0.973
diff 49.48387406740392
epoch 12 train loss: 1249.339, val loss: 341.353, train acc: 0.983, val acc: 0.977
diff 26.426196772515937
epoch 13 train loss: 1189.309, val loss: 403.903, train acc: 0.983, val acc: 0.967
diff 62.55012311248777
epoch 14 train loss: 1192.046, val loss: 396.305, train acc: 0.984, val acc: 0.966
diff 7.598415699227303
epoch 15 train loss: 1123.997, val loss: 437.911, train acc: 0.984, val acc: 0.972
diff 41.60600492501317
epoch 16 train loss: 1008.327, val loss: 430.852, train acc: 0.986, val acc: 0.967
diff 7.05860511572422
epoch 17 train loss: 1067.609, val loss: 398.000, train acc: 0.985, val acc: 0.973
diff 32.85170925877475
epoch 18 train loss: 869.089, val loss: 390.318, train acc: 0.988, val acc: 0.975
diff 7.68269074729551
epoch 19 train loss: 1093.116, val loss: 468.987, train acc: 0.986, val acc: 0.966
diff 78.66897891026474
epoch 20 train loss: 867.340, val loss: 649.596, train acc: 0.987, val acc: 0.964
diff 180.60940969808246
epoch 21 train loss: 1073.541, val loss: 505.019, train acc: 0.986, val acc: 0.960
diff 144.577090650007
epoch 22 train loss: 959.907, val loss: 485.509, train acc: 0.987, val acc: 0.964
diff 19.50982314070086
epoch 23 train loss: 833.350, val loss: 438.610, train acc: 0.989, val acc: 0.975
diff 46.89892994802307
epoch 24 train loss: 987.605, val loss: 444.300, train acc: 0.987, val acc: 0.975
diff 5.689819287525324
epoch 25 train loss: 799.887, val loss: 591.264, train acc: 0.990, val acc: 0.968
diff 146.96419110801452
epoch 26 train loss: 938.811, val loss: 595.185, train acc: 0.988, val acc: 0.965
diff 3.9211678152887544
epoch 27 train loss: 715.676, val loss: 545.163, train acc: 0.991, val acc: 0.972
diff 50.02228763544872
