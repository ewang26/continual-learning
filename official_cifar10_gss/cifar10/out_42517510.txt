Using CUDA
Running experiment cifar10:
Results are stored in: official_cifar10_gss/cifar10
with hyperparameters {'p': 0.002, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 4, 'class_balanced': True, 'execute_early_stopping': False, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 31513.551, val loss: 2814.641, train acc: 0.453, val acc: 0.560
diff inf
epoch 2 train loss: 23120.487, val loss: 2322.676, train acc: 0.610, val acc: 0.642
diff 491.9648940972079
epoch 3 train loss: 18665.670, val loss: 2199.630, train acc: 0.688, val acc: 0.668
diff 123.04574563456572
epoch 4 train loss: 15020.577, val loss: 2154.095, train acc: 0.749, val acc: 0.683
diff 45.5347701687092
epoch 5 train loss: 11613.415, val loss: 2217.707, train acc: 0.808, val acc: 0.702
diff 63.61213955614403
epoch 6 train loss: 8203.218, val loss: 2531.719, train acc: 0.865, val acc: 0.691
diff 314.0111709795342
epoch 7 train loss: 5673.170, val loss: 3026.112, train acc: 0.907, val acc: 0.692
diff 494.3929835549402
epoch 8 train loss: 4417.314, val loss: 3748.576, train acc: 0.929, val acc: 0.672
diff 722.464107617237
epoch 9 train loss: 3547.556, val loss: 3926.199, train acc: 0.944, val acc: 0.685
diff 177.6229630286075
epoch 10 train loss: 3298.230, val loss: 4336.236, train acc: 0.949, val acc: 0.661
diff 410.03763715669356
epoch 11 train loss: 2951.444, val loss: 4416.404, train acc: 0.954, val acc: 0.674
diff 80.16827282819304
epoch 12 train loss: 2614.494, val loss: 4710.485, train acc: 0.962, val acc: 0.663
diff 294.0807057108532
epoch 13 train loss: 2723.102, val loss: 5051.430, train acc: 0.960, val acc: 0.682
diff 340.9446370908954
epoch 14 train loss: 2500.508, val loss: 5541.403, train acc: 0.964, val acc: 0.684
diff 489.9727470313637
epoch 15 train loss: 2124.267, val loss: 5362.362, train acc: 0.967, val acc: 0.680
diff 179.040244283221
epoch 16 train loss: 2554.844, val loss: 5282.215, train acc: 0.965, val acc: 0.680
diff 80.14750658884441
epoch 17 train loss: 2252.232, val loss: 5757.758, train acc: 0.968, val acc: 0.665
diff 475.5435090636902
epoch 18 train loss: 1986.830, val loss: 7099.814, train acc: 0.972, val acc: 0.674
diff 1342.0560672642996
epoch 19 train loss: 2287.301, val loss: 6419.294, train acc: 0.969, val acc: 0.677
diff 680.5203905654271
epoch 20 train loss: 1999.537, val loss: 7403.026, train acc: 0.973, val acc: 0.667
diff 983.7320845049335
epoch 21 train loss: 2048.803, val loss: 6790.054, train acc: 0.973, val acc: 0.675
diff 612.9722970729799
epoch 22 train loss: 2117.006, val loss: 6972.502, train acc: 0.973, val acc: 0.668
diff 182.44820278274983
epoch 23 train loss: 1908.440, val loss: 7662.651, train acc: 0.975, val acc: 0.660
diff 690.1492408117674
epoch 24 train loss: 2080.903, val loss: 7677.866, train acc: 0.973, val acc: 0.660
diff 15.214621638237077
epoch 25 train loss: 2419.216, val loss: 8590.031, train acc: 0.972, val acc: 0.671
diff 912.1653155483882
epoch 26 train loss: 1765.639, val loss: 8301.547, train acc: 0.977, val acc: 0.659
diff 288.4841174670619
epoch 27 train loss: 2174.733, val loss: 8446.016, train acc: 0.973, val acc: 0.665
diff 144.46886743522737
epoch 28 train loss: 1695.715, val loss: 8085.904, train acc: 0.978, val acc: 0.675
diff 360.1118401658232
epoch 29 train loss: 1929.027, val loss: 8423.168, train acc: 0.977, val acc: 0.666
diff 337.2636145731476
epoch 30 train loss: 1974.411, val loss: 8964.852, train acc: 0.976, val acc: 0.672
diff 541.684627648212
Training model M2
epoch 1 train loss: 40052.048, val loss: 3423.240, train acc: 0.452, val acc: 0.577
diff inf
epoch 2 train loss: 28754.415, val loss: 3333.002, train acc: 0.620, val acc: 0.594
diff 90.23820765033497
epoch 3 train loss: 22809.486, val loss: 2756.611, train acc: 0.703, val acc: 0.677
diff 576.390895018832
epoch 4 train loss: 18170.425, val loss: 2924.932, train acc: 0.760, val acc: 0.672
diff 168.32071761018324
epoch 5 train loss: 14031.143, val loss: 3074.500, train acc: 0.816, val acc: 0.679
diff 149.56805554541415
epoch 6 train loss: 10565.960, val loss: 3484.980, train acc: 0.861, val acc: 0.674
diff 410.48017747463246
epoch 7 train loss: 7564.935, val loss: 3906.449, train acc: 0.901, val acc: 0.690
diff 421.46949603647454
epoch 8 train loss: 6122.765, val loss: 4342.668, train acc: 0.921, val acc: 0.694
diff 436.21826266465405
epoch 9 train loss: 5313.796, val loss: 4816.915, train acc: 0.935, val acc: 0.686
diff 474.2472833935726
epoch 10 train loss: 4613.999, val loss: 5091.338, train acc: 0.944, val acc: 0.683
diff 274.4234873876667
epoch 11 train loss: 4389.507, val loss: 5620.934, train acc: 0.946, val acc: 0.686
diff 529.5952375992711
epoch 12 train loss: 4120.234, val loss: 5632.688, train acc: 0.952, val acc: 0.693
diff 11.753831245728179
epoch 13 train loss: 3988.907, val loss: 6156.429, train acc: 0.953, val acc: 0.694
diff 523.7413365738566
epoch 14 train loss: 3565.918, val loss: 6379.714, train acc: 0.957, val acc: 0.696
diff 223.2852639072089
epoch 15 train loss: 3705.008, val loss: 6781.231, train acc: 0.959, val acc: 0.685
diff 401.51722885776144
epoch 16 train loss: 3366.936, val loss: 6963.078, train acc: 0.963, val acc: 0.679
diff 181.8467712854963
epoch 17 train loss: 3565.691, val loss: 6670.998, train acc: 0.961, val acc: 0.677
diff 292.08034219170713
epoch 18 train loss: 3499.692, val loss: 6911.179, train acc: 0.962, val acc: 0.672
diff 240.1816643125012
epoch 19 train loss: 3028.213, val loss: 7727.213, train acc: 0.966, val acc: 0.683
diff 816.0338487920108
epoch 20 train loss: 3321.398, val loss: 8411.910, train acc: 0.964, val acc: 0.669
diff 684.6966836031979
epoch 21 train loss: 3210.048, val loss: 7917.262, train acc: 0.966, val acc: 0.681
diff 494.6479116202627
epoch 22 train loss: 3079.509, val loss: 7855.909, train acc: 0.967, val acc: 0.690
diff 61.35298968762436
epoch 23 train loss: 3143.888, val loss: 8477.317, train acc: 0.968, val acc: 0.677
diff 621.4080882837479
epoch 24 train loss: 2943.218, val loss: 8088.587, train acc: 0.970, val acc: 0.682
diff 388.73034205128897
epoch 25 train loss: 3446.238, val loss: 8265.023, train acc: 0.965, val acc: 0.688
diff 176.43613533069765
epoch 26 train loss: 2737.438, val loss: 8729.585, train acc: 0.973, val acc: 0.677
diff 464.56188203362944
epoch 27 train loss: 3254.787, val loss: 9177.144, train acc: 0.967, val acc: 0.669
diff 447.55886889929025
epoch 28 train loss: 2893.931, val loss: 9772.711, train acc: 0.972, val acc: 0.681
diff 595.5676684415484
epoch 29 train loss: 2933.148, val loss: 9984.270, train acc: 0.972, val acc: 0.681
diff 211.5582398487204
epoch 30 train loss: 3047.376, val loss: 9675.478, train acc: 0.971, val acc: 0.673
diff 308.7917816335921
Selecting using RandomMemorySetManager
RandomMemorySetManager
Start time: 2024-08-04 12:24:26
Training model M3
epoch 1 train loss: 2807.279, val loss: 21927.999, train acc: 0.784, val acc: 0.178
diff inf
epoch 2 train loss: 1832.446, val loss: 11871.019, train acc: 0.885, val acc: 0.185
diff 10056.979688585785
epoch 3 train loss: 1476.520, val loss: 12921.092, train acc: 0.908, val acc: 0.187
diff 1050.0726592800402
epoch 4 train loss: 1249.711, val loss: 12109.504, train acc: 0.925, val acc: 0.188
diff 811.5872695848466
epoch 5 train loss: 1026.130, val loss: 14415.360, train acc: 0.941, val acc: 0.186
diff 2305.855462302323
epoch 6 train loss: 840.655, val loss: 17101.207, train acc: 0.943, val acc: 0.186
diff 2685.84756944758
epoch 7 train loss: 675.632, val loss: 16664.629, train acc: 0.954, val acc: 0.192
diff 436.5779331845297
epoch 8 train loss: 512.581, val loss: 22284.040, train acc: 0.966, val acc: 0.196
diff 5619.410357236287
epoch 9 train loss: 429.840, val loss: 25782.080, train acc: 0.971, val acc: 0.189
diff 3498.0399364318655
epoch 10 train loss: 322.070, val loss: 24825.710, train acc: 0.977, val acc: 0.195
diff 956.3699033399316
epoch 11 train loss: 252.693, val loss: 28731.021, train acc: 0.983, val acc: 0.195
diff 3905.3110529549012
epoch 12 train loss: 154.048, val loss: 23956.411, train acc: 0.991, val acc: 0.206
diff 4774.609582984529
epoch 13 train loss: 163.348, val loss: 41063.197, train acc: 0.990, val acc: 0.197
diff 17106.78565810442
epoch 14 train loss: 165.077, val loss: 39331.597, train acc: 0.990, val acc: 0.196
diff 1731.5997284269688
epoch 15 train loss: 157.644, val loss: 44510.153, train acc: 0.990, val acc: 0.193
diff 5178.55547323783
epoch 16 train loss: 127.223, val loss: 43633.949, train acc: 0.993, val acc: 0.195
diff 876.2037022999793
epoch 17 train loss: 219.100, val loss: 40586.933, train acc: 0.988, val acc: 0.194
diff 3047.0155051649126
epoch 18 train loss: 99.049, val loss: 40825.976, train acc: 0.993, val acc: 0.195
diff 239.0424542634937
epoch 19 train loss: 152.982, val loss: 43844.931, train acc: 0.991, val acc: 0.203
diff 3018.954916958057
epoch 20 train loss: 103.730, val loss: 38003.547, train acc: 0.993, val acc: 0.201
diff 5841.383346982613
epoch 21 train loss: 106.285, val loss: 43961.867, train acc: 0.995, val acc: 0.197
diff 5958.319394975559
epoch 22 train loss: 145.214, val loss: 37038.665, train acc: 0.991, val acc: 0.198
diff 6923.202199275169
epoch 23 train loss: 62.293, val loss: 49362.977, train acc: 0.996, val acc: 0.196
diff 12324.312081034252
epoch 24 train loss: 117.257, val loss: 56796.498, train acc: 0.991, val acc: 0.195
diff 7433.521630856725
epoch 25 train loss: 147.149, val loss: 52965.038, train acc: 0.991, val acc: 0.196
diff 3831.4599805304388
epoch 26 train loss: 56.779, val loss: 50415.623, train acc: 0.997, val acc: 0.197
diff 2549.415765695965
epoch 27 train loss: 3.643, val loss: 54117.951, train acc: 1.000, val acc: 0.197
diff 3702.328361709311
epoch 28 train loss: 0.498, val loss: 57192.341, train acc: 1.000, val acc: 0.197
diff 3074.390351355978
epoch 29 train loss: 253.188, val loss: 47250.554, train acc: 0.987, val acc: 0.188
diff 9941.787598549017
epoch 30 train loss: 65.476, val loss: 55131.158, train acc: 0.996, val acc: 0.196
diff 7880.603831430497
End time: 2024-08-04 12:53:26
Time to complete: 00:28:59.97
Selecting using KMeansMemorySetManager
KMeansMemorySetManager
Start time: 2024-08-04 12:53:26
Training model M3
epoch 1 train loss: 573.806, val loss: 46490.314, train acc: 0.984, val acc: 0.200
diff inf
epoch 2 train loss: 218.059, val loss: 33927.107, train acc: 0.990, val acc: 0.222
diff 12563.20708007914
epoch 3 train loss: 183.642, val loss: 43356.022, train acc: 0.990, val acc: 0.208
diff 9428.91548428544
epoch 4 train loss: 232.213, val loss: 38468.037, train acc: 0.989, val acc: 0.214
diff 4887.985570069679
epoch 5 train loss: 16.419, val loss: 53062.110, train acc: 1.000, val acc: 0.208
diff 14594.07284706091
epoch 6 train loss: 2.076, val loss: 55094.358, train acc: 1.000, val acc: 0.209
diff 2032.2480323470882
epoch 7 train loss: 0.506, val loss: 58596.795, train acc: 1.000, val acc: 0.209
diff 3502.437692625361
epoch 8 train loss: 0.285, val loss: 61883.360, train acc: 1.000, val acc: 0.208
diff 3286.564360122946
epoch 9 train loss: 0.182, val loss: 65373.036, train acc: 1.000, val acc: 0.206
diff 3489.6765674162743
epoch 10 train loss: 0.122, val loss: 68425.748, train acc: 1.000, val acc: 0.206
diff 3052.7119663287813
epoch 11 train loss: 0.083, val loss: 71892.059, train acc: 1.000, val acc: 0.206
diff 3466.310696967208
epoch 12 train loss: 0.057, val loss: 76319.859, train acc: 1.000, val acc: 0.206
diff 4427.80027267788
epoch 13 train loss: 0.040, val loss: 79538.513, train acc: 1.000, val acc: 0.205
diff 3218.6534101500292
epoch 14 train loss: 0.027, val loss: 83424.702, train acc: 1.000, val acc: 0.205
diff 3886.1898194217792
epoch 15 train loss: 0.019, val loss: 87451.169, train acc: 1.000, val acc: 0.204
diff 4026.466866405666
epoch 16 train loss: 0.014, val loss: 89696.509, train acc: 1.000, val acc: 0.205
diff 2245.3394409928005
epoch 17 train loss: 0.010, val loss: 92886.811, train acc: 1.000, val acc: 0.204
diff 3190.302469714574
epoch 18 train loss: 0.007, val loss: 95848.098, train acc: 1.000, val acc: 0.204
diff 2961.2867241494096
epoch 19 train loss: 0.005, val loss: 99574.400, train acc: 1.000, val acc: 0.204
diff 3726.3017470645864
epoch 20 train loss: 0.004, val loss: 102336.360, train acc: 1.000, val acc: 0.205
diff 2761.9602447102516
epoch 21 train loss: 0.003, val loss: 104880.916, train acc: 1.000, val acc: 0.205
diff 2544.556510418217
epoch 22 train loss: 0.002, val loss: 106170.025, train acc: 1.000, val acc: 0.205
diff 1289.108837629945
epoch 23 train loss: 0.001, val loss: 109061.415, train acc: 1.000, val acc: 0.205
diff 2891.389744416432
epoch 24 train loss: 0.001, val loss: 113637.515, train acc: 1.000, val acc: 0.205
diff 4576.099535489804
epoch 25 train loss: 0.001, val loss: 116224.675, train acc: 1.000, val acc: 0.205
diff 2587.160521082187
epoch 26 train loss: 0.000, val loss: 115632.240, train acc: 1.000, val acc: 0.205
diff 592.4346501907858
epoch 27 train loss: 0.000, val loss: 118963.997, train acc: 1.000, val acc: 0.206
diff 3331.757009069959
epoch 28 train loss: 0.000, val loss: 119378.556, train acc: 1.000, val acc: 0.206
diff 414.5587969282642
epoch 29 train loss: 0.000, val loss: 122734.766, train acc: 1.000, val acc: 0.205
diff 3356.209558437462
epoch 30 train loss: 0.000, val loss: 124743.470, train acc: 1.000, val acc: 0.205
diff 2008.7037291123706
End time: 2024-08-04 13:21:54
Time to complete: 00:28:28.12
Selecting using LambdaMemorySetManager
LambdaMemorySetManager
Start time: 2024-08-04 13:21:54
Training model M3
epoch 1 train loss: 960.468, val loss: 26817.202, train acc: 0.985, val acc: 0.201
diff inf
epoch 2 train loss: 237.679, val loss: 21212.914, train acc: 0.991, val acc: 0.233
diff 5604.287256358926
epoch 3 train loss: 77.581, val loss: 24114.487, train acc: 0.997, val acc: 0.253
diff 2901.5730412890007
epoch 4 train loss: 249.427, val loss: 32578.759, train acc: 0.989, val acc: 0.209
diff 8464.271338029681
epoch 5 train loss: 121.704, val loss: 38686.849, train acc: 0.991, val acc: 0.213
diff 6108.090351617746
epoch 6 train loss: 35.027, val loss: 48468.483, train acc: 0.998, val acc: 0.214
diff 9781.633628303898
epoch 7 train loss: 54.142, val loss: 57704.462, train acc: 0.997, val acc: 0.200
diff 9235.979107710511
epoch 8 train loss: 293.749, val loss: 42982.737, train acc: 0.986, val acc: 0.217
diff 14721.725123417025
epoch 9 train loss: 28.591, val loss: 48949.580, train acc: 0.998, val acc: 0.212
diff 5966.843037144514
epoch 10 train loss: 2.246, val loss: 56423.739, train acc: 1.000, val acc: 0.211
diff 7474.1596411149585
epoch 11 train loss: 0.208, val loss: 57709.162, train acc: 1.000, val acc: 0.210
diff 1285.4230969563068
epoch 12 train loss: 0.100, val loss: 58703.199, train acc: 1.000, val acc: 0.210
diff 994.0362594818071
epoch 13 train loss: 0.070, val loss: 59653.465, train acc: 1.000, val acc: 0.211
diff 950.2664959754111
epoch 14 train loss: 0.050, val loss: 60677.489, train acc: 1.000, val acc: 0.211
diff 1024.0241953627046
epoch 15 train loss: 0.037, val loss: 61658.355, train acc: 1.000, val acc: 0.212
diff 980.8656066765252
epoch 16 train loss: 0.027, val loss: 62631.464, train acc: 1.000, val acc: 0.211
diff 973.1084639356413
epoch 17 train loss: 0.020, val loss: 63595.867, train acc: 1.000, val acc: 0.211
diff 964.4033611337436
epoch 18 train loss: 0.015, val loss: 64719.273, train acc: 1.000, val acc: 0.211
diff 1123.4064034871553
epoch 19 train loss: 0.011, val loss: 65757.588, train acc: 1.000, val acc: 0.211
diff 1038.314722662406
epoch 20 train loss: 0.008, val loss: 66954.768, train acc: 1.000, val acc: 0.210
diff 1197.1798761275131
epoch 21 train loss: 0.006, val loss: 68299.129, train acc: 1.000, val acc: 0.210
diff 1344.361515696044
epoch 22 train loss: 0.004, val loss: 70070.803, train acc: 1.000, val acc: 0.210
diff 1771.6734747476003
epoch 23 train loss: 0.003, val loss: 72033.742, train acc: 1.000, val acc: 0.210
diff 1962.9391441042826
epoch 24 train loss: 0.002, val loss: 74178.174, train acc: 1.000, val acc: 0.210
diff 2144.431970652411
epoch 25 train loss: 0.002, val loss: 77264.290, train acc: 1.000, val acc: 0.209
diff 3086.115717341818
epoch 26 train loss: 0.001, val loss: 78847.279, train acc: 1.000, val acc: 0.209
diff 1582.9892005811562
epoch 27 train loss: 0.001, val loss: 81856.887, train acc: 1.000, val acc: 0.210
diff 3009.6079115949833
epoch 28 train loss: 0.001, val loss: 83370.665, train acc: 1.000, val acc: 0.210
diff 1513.7778083739831
epoch 29 train loss: 0.000, val loss: 85290.996, train acc: 1.000, val acc: 0.210
diff 1920.3315094462741
epoch 30 train loss: 0.000, val loss: 88457.336, train acc: 1.000, val acc: 0.210
diff 3166.340000826269
End time: 2024-08-04 13:51:17
Time to complete: 00:29:22.52
Selecting using iCaRL
iCaRL (icarl)
Start time: 2024-08-04 13:51:17
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
Training model M3
epoch 1 train loss: 760.498, val loss: 38020.200, train acc: 0.984, val acc: 0.205
diff inf
epoch 2 train loss: 277.571, val loss: 24660.394, train acc: 0.989, val acc: 0.250
diff 13359.80588915493
epoch 3 train loss: 68.686, val loss: 33074.480, train acc: 0.997, val acc: 0.233
diff 8414.08592320804
epoch 4 train loss: 263.086, val loss: 33307.186, train acc: 0.989, val acc: 0.220
diff 232.7056121354908
epoch 5 train loss: 80.652, val loss: 41072.669, train acc: 0.997, val acc: 0.216
diff 7765.4830560919
epoch 6 train loss: 36.750, val loss: 43830.098, train acc: 0.998, val acc: 0.213
diff 2757.4292317714135
epoch 7 train loss: 77.358, val loss: 35448.275, train acc: 0.995, val acc: 0.222
diff 8381.822921665625
epoch 8 train loss: 246.373, val loss: 35268.978, train acc: 0.988, val acc: 0.229
diff 179.2964819163317
epoch 9 train loss: 53.314, val loss: 62795.301, train acc: 0.997, val acc: 0.202
diff 27526.32276790765
epoch 10 train loss: 170.468, val loss: 37940.901, train acc: 0.992, val acc: 0.228
diff 24854.400323798203
epoch 11 train loss: 52.834, val loss: 46096.066, train acc: 0.997, val acc: 0.210
diff 8155.164844121406
epoch 12 train loss: 68.569, val loss: 55670.843, train acc: 0.996, val acc: 0.212
diff 9574.77715328736
epoch 13 train loss: 77.560, val loss: 65623.119, train acc: 0.996, val acc: 0.197
diff 9952.276449171717
epoch 14 train loss: 65.301, val loss: 65193.439, train acc: 0.998, val acc: 0.203
diff 429.6805962040162
epoch 15 train loss: 327.467, val loss: 53182.363, train acc: 0.985, val acc: 0.192
diff 12011.075539338322
epoch 16 train loss: 59.909, val loss: 63158.296, train acc: 0.997, val acc: 0.212
diff 9975.932893786863
epoch 17 train loss: 85.793, val loss: 44460.529, train acc: 0.995, val acc: 0.221
diff 18697.766712704703
epoch 18 train loss: 26.688, val loss: 55394.872, train acc: 0.998, val acc: 0.206
diff 10934.342482335021
epoch 19 train loss: 165.755, val loss: 54199.571, train acc: 0.992, val acc: 0.205
diff 1195.3004283369737
epoch 20 train loss: 119.198, val loss: 67917.492, train acc: 0.994, val acc: 0.206
diff 13717.92067853376
epoch 21 train loss: 126.551, val loss: 51265.304, train acc: 0.995, val acc: 0.217
diff 16652.187939143754
epoch 22 train loss: 66.912, val loss: 65708.969, train acc: 0.996, val acc: 0.213
diff 14443.665247927958
epoch 23 train loss: 208.005, val loss: 63389.749, train acc: 0.992, val acc: 0.211
diff 2319.2199149527733
epoch 24 train loss: 9.991, val loss: 74411.819, train acc: 0.999, val acc: 0.202
diff 11022.069866927253
epoch 25 train loss: 19.255, val loss: 82916.891, train acc: 1.000, val acc: 0.198
diff 8505.071404767266
epoch 26 train loss: 29.132, val loss: 79732.090, train acc: 0.999, val acc: 0.197
diff 3184.800965089962
epoch 27 train loss: 76.707, val loss: 90238.881, train acc: 0.995, val acc: 0.201
diff 10506.790780554831
epoch 28 train loss: 197.788, val loss: 67663.839, train acc: 0.994, val acc: 0.199
diff 22575.041809799746
epoch 29 train loss: 142.743, val loss: 102709.766, train acc: 0.994, val acc: 0.190
diff 35045.927085010844
epoch 30 train loss: 80.225, val loss: 78267.926, train acc: 0.995, val acc: 0.209
diff 24441.840299930773
End time: 2024-08-04 15:49:30
Time to complete: 01:58:13.23
Selecting using iCaRL
iCaRL (replay)
Start time: 2024-08-04 15:49:30
training representation using replay loss
training representation using replay loss
training representation using replay loss
training representation using replay loss
Training model M3
