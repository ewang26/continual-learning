Using CUDA
Running experiment cifar10:
Results are stored in: official_cifar10_gss/cifar10
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 4, 'class_balanced': True, 'execute_early_stopping': False, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 31513.551, val loss: 2814.641, train acc: 0.453, val acc: 0.560
diff inf
epoch 2 train loss: 23120.487, val loss: 2322.676, train acc: 0.610, val acc: 0.642
diff 491.9648940972079
epoch 3 train loss: 18665.670, val loss: 2199.630, train acc: 0.688, val acc: 0.668
diff 123.04574563456572
epoch 4 train loss: 15020.577, val loss: 2154.095, train acc: 0.749, val acc: 0.683
diff 45.5347701687092
epoch 5 train loss: 11613.415, val loss: 2217.707, train acc: 0.808, val acc: 0.702
diff 63.61213955614403
epoch 6 train loss: 8203.218, val loss: 2531.719, train acc: 0.865, val acc: 0.691
diff 314.0111709795342
epoch 7 train loss: 5673.170, val loss: 3026.112, train acc: 0.907, val acc: 0.692
diff 494.3929835549402
epoch 8 train loss: 4417.314, val loss: 3748.576, train acc: 0.929, val acc: 0.672
diff 722.464107617237
epoch 9 train loss: 3547.556, val loss: 3926.199, train acc: 0.944, val acc: 0.685
diff 177.6229630286075
epoch 10 train loss: 3298.230, val loss: 4336.236, train acc: 0.949, val acc: 0.661
diff 410.03763715669356
epoch 11 train loss: 2951.444, val loss: 4416.404, train acc: 0.954, val acc: 0.674
diff 80.16827282819304
epoch 12 train loss: 2614.494, val loss: 4710.485, train acc: 0.962, val acc: 0.663
diff 294.0807057108532
epoch 13 train loss: 2723.102, val loss: 5051.430, train acc: 0.960, val acc: 0.682
diff 340.9446370908954
epoch 14 train loss: 2500.508, val loss: 5541.403, train acc: 0.964, val acc: 0.684
diff 489.9727470313637
epoch 15 train loss: 2124.267, val loss: 5362.362, train acc: 0.967, val acc: 0.680
diff 179.040244283221
epoch 16 train loss: 2554.844, val loss: 5282.215, train acc: 0.965, val acc: 0.680
diff 80.14750658884441
epoch 17 train loss: 2252.232, val loss: 5757.758, train acc: 0.968, val acc: 0.665
diff 475.5435090636902
epoch 18 train loss: 1986.830, val loss: 7099.814, train acc: 0.972, val acc: 0.674
diff 1342.0560672642996
epoch 19 train loss: 2287.301, val loss: 6419.294, train acc: 0.969, val acc: 0.677
diff 680.5203905654271
epoch 20 train loss: 1999.537, val loss: 7403.026, train acc: 0.973, val acc: 0.667
diff 983.7320845049335
epoch 21 train loss: 2048.803, val loss: 6790.054, train acc: 0.973, val acc: 0.675
diff 612.9722970729799
epoch 22 train loss: 2117.006, val loss: 6972.502, train acc: 0.973, val acc: 0.668
diff 182.44820278274983
epoch 23 train loss: 1908.440, val loss: 7662.651, train acc: 0.975, val acc: 0.660
diff 690.1492408117674
epoch 24 train loss: 2080.903, val loss: 7677.866, train acc: 0.973, val acc: 0.660
diff 15.214621638237077
epoch 25 train loss: 2419.216, val loss: 8590.031, train acc: 0.972, val acc: 0.671
diff 912.1653155483882
epoch 26 train loss: 1765.639, val loss: 8301.547, train acc: 0.977, val acc: 0.659
diff 288.4841174670619
epoch 27 train loss: 2174.733, val loss: 8446.016, train acc: 0.973, val acc: 0.665
diff 144.46886743522737
epoch 28 train loss: 1695.715, val loss: 8085.904, train acc: 0.978, val acc: 0.675
diff 360.1118401658232
epoch 29 train loss: 1929.027, val loss: 8423.168, train acc: 0.977, val acc: 0.666
diff 337.2636145731476
epoch 30 train loss: 1974.411, val loss: 8964.852, train acc: 0.976, val acc: 0.672
diff 541.684627648212
Training model M2
epoch 1 train loss: 40052.048, val loss: 3423.240, train acc: 0.452, val acc: 0.577
diff inf
epoch 2 train loss: 28754.415, val loss: 3333.002, train acc: 0.620, val acc: 0.594
diff 90.23820765033497
epoch 3 train loss: 22809.486, val loss: 2756.611, train acc: 0.703, val acc: 0.677
diff 576.390895018832
epoch 4 train loss: 18170.425, val loss: 2924.932, train acc: 0.760, val acc: 0.672
diff 168.32071761018324
epoch 5 train loss: 14031.143, val loss: 3074.500, train acc: 0.816, val acc: 0.679
diff 149.56805554541415
epoch 6 train loss: 10565.960, val loss: 3484.980, train acc: 0.861, val acc: 0.674
diff 410.48017747463246
epoch 7 train loss: 7564.935, val loss: 3906.449, train acc: 0.901, val acc: 0.690
diff 421.46949603647454
epoch 8 train loss: 6122.765, val loss: 4342.668, train acc: 0.921, val acc: 0.694
diff 436.21826266465405
epoch 9 train loss: 5313.796, val loss: 4816.915, train acc: 0.935, val acc: 0.686
diff 474.2472833935726
epoch 10 train loss: 4613.999, val loss: 5091.338, train acc: 0.944, val acc: 0.683
diff 274.4234873876667
epoch 11 train loss: 4389.507, val loss: 5620.934, train acc: 0.946, val acc: 0.686
diff 529.5952375992711
epoch 12 train loss: 4120.234, val loss: 5632.688, train acc: 0.952, val acc: 0.693
diff 11.753831245728179
epoch 13 train loss: 3988.907, val loss: 6156.429, train acc: 0.953, val acc: 0.694
diff 523.7413365738566
epoch 14 train loss: 3565.918, val loss: 6379.714, train acc: 0.957, val acc: 0.696
diff 223.2852639072089
epoch 15 train loss: 3705.008, val loss: 6781.231, train acc: 0.959, val acc: 0.685
diff 401.51722885776144
epoch 16 train loss: 3366.936, val loss: 6963.078, train acc: 0.963, val acc: 0.679
diff 181.8467712854963
epoch 17 train loss: 3565.691, val loss: 6670.998, train acc: 0.961, val acc: 0.677
diff 292.08034219170713
epoch 18 train loss: 3499.692, val loss: 6911.179, train acc: 0.962, val acc: 0.672
diff 240.1816643125012
epoch 19 train loss: 3028.213, val loss: 7727.213, train acc: 0.966, val acc: 0.683
diff 816.0338487920108
epoch 20 train loss: 3321.398, val loss: 8411.910, train acc: 0.964, val acc: 0.669
diff 684.6966836031979
epoch 21 train loss: 3210.048, val loss: 7917.262, train acc: 0.966, val acc: 0.681
diff 494.6479116202627
epoch 22 train loss: 3079.509, val loss: 7855.909, train acc: 0.967, val acc: 0.690
diff 61.35298968762436
epoch 23 train loss: 3143.888, val loss: 8477.317, train acc: 0.968, val acc: 0.677
diff 621.4080882837479
epoch 24 train loss: 2943.218, val loss: 8088.587, train acc: 0.970, val acc: 0.682
diff 388.73034205128897
epoch 25 train loss: 3446.238, val loss: 8265.023, train acc: 0.965, val acc: 0.688
diff 176.43613533069765
epoch 26 train loss: 2737.438, val loss: 8729.585, train acc: 0.973, val acc: 0.677
diff 464.56188203362944
epoch 27 train loss: 3254.787, val loss: 9177.144, train acc: 0.967, val acc: 0.669
diff 447.55886889929025
epoch 28 train loss: 2893.931, val loss: 9772.711, train acc: 0.972, val acc: 0.681
diff 595.5676684415484
epoch 29 train loss: 2933.148, val loss: 9984.270, train acc: 0.972, val acc: 0.681
diff 211.5582398487204
epoch 30 train loss: 3047.376, val loss: 9675.478, train acc: 0.971, val acc: 0.673
diff 308.7917816335921
Selecting using RandomMemorySetManager
RandomMemorySetManager
Start time: 2024-08-04 13:28:32
Training model M3
epoch 1 train loss: 3994.880, val loss: 10514.531, train acc: 0.737, val acc: 0.173
diff inf
epoch 2 train loss: 2632.370, val loss: 9767.947, train acc: 0.857, val acc: 0.182
diff 746.5838594005927
epoch 3 train loss: 2261.938, val loss: 9750.458, train acc: 0.878, val acc: 0.185
diff 17.48977488579476
epoch 4 train loss: 1914.834, val loss: 10553.827, train acc: 0.896, val acc: 0.200
diff 803.3688985275458
epoch 5 train loss: 1534.139, val loss: 8945.487, train acc: 0.911, val acc: 0.256
diff 1608.3397426647098
epoch 6 train loss: 1221.509, val loss: 9149.654, train acc: 0.930, val acc: 0.273
diff 204.1676712023218
epoch 7 train loss: 855.541, val loss: 12124.104, train acc: 0.948, val acc: 0.283
diff 2974.4498376640513
epoch 8 train loss: 550.188, val loss: 17203.852, train acc: 0.968, val acc: 0.261
diff 5079.747412321334
epoch 9 train loss: 421.904, val loss: 15192.042, train acc: 0.973, val acc: 0.281
diff 2011.809854477402
epoch 10 train loss: 353.766, val loss: 22794.213, train acc: 0.982, val acc: 0.261
diff 7602.170820994286
epoch 11 train loss: 263.630, val loss: 23555.920, train acc: 0.985, val acc: 0.280
diff 761.7077412349026
epoch 12 train loss: 266.750, val loss: 21409.147, train acc: 0.985, val acc: 0.296
diff 2146.773028494623
epoch 13 train loss: 224.358, val loss: 23084.825, train acc: 0.986, val acc: 0.294
diff 1675.6773500426352
epoch 14 train loss: 69.501, val loss: 32444.645, train acc: 0.997, val acc: 0.266
diff 9359.820676880721
epoch 15 train loss: 311.704, val loss: 23437.157, train acc: 0.985, val acc: 0.281
diff 9007.487896076913
epoch 16 train loss: 269.458, val loss: 26912.022, train acc: 0.984, val acc: 0.278
diff 3474.86470871203
epoch 17 train loss: 161.973, val loss: 27033.427, train acc: 0.991, val acc: 0.283
diff 121.4052429634794
epoch 18 train loss: 121.094, val loss: 28322.480, train acc: 0.992, val acc: 0.281
diff 1289.052104915656
epoch 19 train loss: 93.930, val loss: 30942.836, train acc: 0.995, val acc: 0.290
diff 2620.3568473706764
epoch 20 train loss: 347.962, val loss: 25130.097, train acc: 0.983, val acc: 0.287
diff 5812.739518546372
epoch 21 train loss: 62.040, val loss: 36241.065, train acc: 0.998, val acc: 0.260
diff 11110.968462360339
epoch 22 train loss: 156.050, val loss: 33341.170, train acc: 0.992, val acc: 0.266
diff 2899.8957738799218
epoch 23 train loss: 27.255, val loss: 40233.880, train acc: 0.998, val acc: 0.241
diff 6892.7103791360205
epoch 24 train loss: 255.424, val loss: 39290.289, train acc: 0.988, val acc: 0.239
diff 943.5907628023415
epoch 25 train loss: 216.975, val loss: 42871.134, train acc: 0.990, val acc: 0.244
diff 3580.8446720321153
epoch 26 train loss: 89.519, val loss: 39853.370, train acc: 0.995, val acc: 0.268
diff 3017.764082772097
epoch 27 train loss: 21.604, val loss: 39022.804, train acc: 0.999, val acc: 0.262
diff 830.5655504327369
epoch 28 train loss: 4.433, val loss: 39596.801, train acc: 1.000, val acc: 0.268
diff 573.996685117083
epoch 29 train loss: 278.284, val loss: 40925.056, train acc: 0.985, val acc: 0.258
diff 1328.255358322851
epoch 30 train loss: 144.072, val loss: 41101.601, train acc: 0.991, val acc: 0.273
diff 176.54475301555794
End time: 2024-08-04 13:58:38
Time to complete: 00:30:06.66
Selecting using KMeansMemorySetManager
KMeansMemorySetManager
Start time: 2024-08-04 13:58:38
Training model M3
epoch 1 train loss: 1186.778, val loss: 25206.901, train acc: 0.954, val acc: 0.257
diff inf
epoch 2 train loss: 416.119, val loss: 33582.490, train acc: 0.976, val acc: 0.255
diff 8375.589492841103
epoch 3 train loss: 254.729, val loss: 32343.706, train acc: 0.986, val acc: 0.288
diff 1238.7845872791004
epoch 4 train loss: 102.263, val loss: 38401.747, train acc: 0.995, val acc: 0.288
diff 6058.041053166446
epoch 5 train loss: 359.467, val loss: 30168.788, train acc: 0.983, val acc: 0.287
diff 8232.958527381426
epoch 6 train loss: 138.081, val loss: 42667.067, train acc: 0.993, val acc: 0.251
diff 12498.2790924916
epoch 7 train loss: 118.685, val loss: 34411.895, train acc: 0.994, val acc: 0.296
diff 8255.172059359305
epoch 8 train loss: 187.488, val loss: 53776.495, train acc: 0.991, val acc: 0.237
diff 19364.59974936914
epoch 9 train loss: 331.046, val loss: 33537.899, train acc: 0.985, val acc: 0.285
diff 20238.596210366406
epoch 10 train loss: 39.711, val loss: 39987.846, train acc: 0.997, val acc: 0.280
diff 6449.94727226621
epoch 11 train loss: 4.812, val loss: 46971.143, train acc: 1.000, val acc: 0.272
diff 6983.296651334422
epoch 12 train loss: 0.732, val loss: 46337.053, train acc: 1.000, val acc: 0.278
diff 634.0901567525434
epoch 13 train loss: 0.362, val loss: 47419.546, train acc: 1.000, val acc: 0.278
diff 1082.4931852760274
epoch 14 train loss: 0.251, val loss: 48395.067, train acc: 1.000, val acc: 0.278
diff 975.5211567512233
epoch 15 train loss: 0.181, val loss: 49251.837, train acc: 1.000, val acc: 0.278
diff 856.7704678615846
epoch 16 train loss: 0.132, val loss: 50241.967, train acc: 1.000, val acc: 0.279
diff 990.1300055451138
epoch 17 train loss: 0.097, val loss: 51023.175, train acc: 1.000, val acc: 0.279
diff 781.2074656342593
epoch 18 train loss: 0.070, val loss: 51642.531, train acc: 1.000, val acc: 0.281
diff 619.356231379199
epoch 19 train loss: 0.051, val loss: 52712.946, train acc: 1.000, val acc: 0.279
diff 1070.4150633570025
epoch 20 train loss: 0.036, val loss: 53424.524, train acc: 1.000, val acc: 0.281
diff 711.5776038300319
epoch 21 train loss: 0.026, val loss: 54494.173, train acc: 1.000, val acc: 0.282
diff 1069.6493939324864
epoch 22 train loss: 0.019, val loss: 55360.060, train acc: 1.000, val acc: 0.282
diff 865.8867160226728
epoch 23 train loss: 0.013, val loss: 56172.743, train acc: 1.000, val acc: 0.284
diff 812.6826819670387
epoch 24 train loss: 0.009, val loss: 57024.103, train acc: 1.000, val acc: 0.282
diff 851.3601608187746
epoch 25 train loss: 0.007, val loss: 58022.348, train acc: 1.000, val acc: 0.284
diff 998.2452036669274
epoch 26 train loss: 0.005, val loss: 58708.449, train acc: 1.000, val acc: 0.283
diff 686.1006544703196
epoch 27 train loss: 0.003, val loss: 59662.049, train acc: 1.000, val acc: 0.284
diff 953.600028929075
epoch 28 train loss: 0.002, val loss: 60489.313, train acc: 1.000, val acc: 0.286
diff 827.2641106247393
epoch 29 train loss: 0.002, val loss: 61412.780, train acc: 1.000, val acc: 0.286
diff 923.4669182255457
epoch 30 train loss: 0.001, val loss: 62262.360, train acc: 1.000, val acc: 0.286
diff 849.5802557044008
End time: 2024-08-04 14:28:13
Time to complete: 00:29:34.54
Selecting using LambdaMemorySetManager
LambdaMemorySetManager
Start time: 2024-08-04 14:28:13
Training model M3
epoch 1 train loss: 2249.350, val loss: 11698.975, train acc: 0.947, val acc: 0.315
diff inf
epoch 2 train loss: 569.556, val loss: 12831.026, train acc: 0.971, val acc: 0.352
diff 1132.0507252503703
epoch 3 train loss: 207.985, val loss: 15533.957, train acc: 0.989, val acc: 0.355
diff 2702.931031888411
epoch 4 train loss: 79.152, val loss: 19235.044, train acc: 0.997, val acc: 0.363
diff 3701.0873927700814
epoch 5 train loss: 293.909, val loss: 21141.245, train acc: 0.983, val acc: 0.337
diff 1906.2012540332835
epoch 6 train loss: 243.948, val loss: 24980.828, train acc: 0.988, val acc: 0.302
diff 3839.582769366585
epoch 7 train loss: 80.024, val loss: 23611.958, train acc: 0.996, val acc: 0.342
diff 1368.870145036315
epoch 8 train loss: 75.759, val loss: 29023.867, train acc: 0.997, val acc: 0.325
diff 5411.908768442645
epoch 9 train loss: 68.422, val loss: 35221.902, train acc: 0.997, val acc: 0.289
diff 6198.034950732483
epoch 10 train loss: 278.780, val loss: 21650.629, train acc: 0.987, val acc: 0.342
diff 13571.272885823488
epoch 11 train loss: 242.351, val loss: 30904.889, train acc: 0.988, val acc: 0.308
diff 9254.260135041717
epoch 12 train loss: 55.917, val loss: 36018.451, train acc: 0.997, val acc: 0.300
diff 5113.561763476009
epoch 13 train loss: 93.289, val loss: 35118.063, train acc: 0.997, val acc: 0.311
diff 900.38741847044
epoch 14 train loss: 225.649, val loss: 33914.111, train acc: 0.991, val acc: 0.296
diff 1203.9528536185462
epoch 15 train loss: 256.536, val loss: 35754.792, train acc: 0.988, val acc: 0.298
diff 1840.6814958000832
epoch 16 train loss: 120.117, val loss: 38718.684, train acc: 0.995, val acc: 0.298
diff 2963.8923179712583
epoch 17 train loss: 56.326, val loss: 29623.637, train acc: 0.998, val acc: 0.318
diff 9095.047682298657
epoch 18 train loss: 121.970, val loss: 40888.617, train acc: 0.994, val acc: 0.301
diff 11264.979879561226
epoch 19 train loss: 30.916, val loss: 47347.306, train acc: 0.998, val acc: 0.301
diff 6458.689165518052
epoch 20 train loss: 226.844, val loss: 50637.649, train acc: 0.988, val acc: 0.303
diff 3290.3435801332525
epoch 21 train loss: 139.209, val loss: 37906.675, train acc: 0.994, val acc: 0.310
diff 12730.97449069489
epoch 22 train loss: 50.447, val loss: 61192.074, train acc: 0.998, val acc: 0.271
diff 23285.39967250317
epoch 23 train loss: 99.795, val loss: 53329.452, train acc: 0.996, val acc: 0.296
diff 7862.622529144319
epoch 24 train loss: 134.584, val loss: 45644.427, train acc: 0.995, val acc: 0.308
diff 7685.025170130328
epoch 25 train loss: 126.129, val loss: 43995.717, train acc: 0.996, val acc: 0.304
diff 1648.7093152328525
epoch 26 train loss: 201.893, val loss: 40941.305, train acc: 0.993, val acc: 0.312
diff 3054.4128419499466
epoch 27 train loss: 62.344, val loss: 61726.850, train acc: 0.997, val acc: 0.268
diff 20785.54580535742
epoch 28 train loss: 66.648, val loss: 54099.299, train acc: 0.997, val acc: 0.292
diff 7627.551687190324
epoch 29 train loss: 163.092, val loss: 59285.367, train acc: 0.994, val acc: 0.285
diff 5186.067837119386
epoch 30 train loss: 69.396, val loss: 55987.958, train acc: 0.995, val acc: 0.292
diff 3297.408137651473
End time: 2024-08-04 14:57:47
Time to complete: 00:29:33.59
Selecting using iCaRL
iCaRL (icarl)
Start time: 2024-08-04 14:57:47
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
