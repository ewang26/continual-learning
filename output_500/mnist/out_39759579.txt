Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 7, 'class_balanced': True, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 6667.943, val loss: 464.122, train acc: 0.931, val acc: 0.957
diff inf
epoch 2 train loss: 3520.186, val loss: 356.248, train acc: 0.962, val acc: 0.963
diff 107.87371961462696
epoch 3 train loss: 2187.636, val loss: 317.362, train acc: 0.973, val acc: 0.975
diff 38.88534986566458
epoch 4 train loss: 2777.457, val loss: 256.715, train acc: 0.970, val acc: 0.972
diff 60.647223048075375
epoch 5 train loss: 2325.017, val loss: 379.213, train acc: 0.974, val acc: 0.973
diff 122.498054140075
epoch 6 train loss: 2327.070, val loss: 335.084, train acc: 0.974, val acc: 0.972
diff 44.12925425798835
epoch 7 train loss: 2936.419, val loss: 344.675, train acc: 0.972, val acc: 0.973
diff 9.590550662506928
epoch 8 train loss: 2537.434, val loss: 448.496, train acc: 0.976, val acc: 0.963
diff 103.82110638484079
epoch 9 train loss: 2323.204, val loss: 560.624, train acc: 0.974, val acc: 0.958
diff 112.12795127417849
epoch 10 train loss: 2559.735, val loss: 359.912, train acc: 0.974, val acc: 0.973
diff 200.7118731942445
Training model M2
epoch 1 train loss: 9595.768, val loss: 723.891, train acc: 0.896, val acc: 0.924
diff inf
epoch 2 train loss: 6083.795, val loss: 703.040, train acc: 0.933, val acc: 0.937
diff 20.851383904122713
epoch 3 train loss: 5242.126, val loss: 631.750, train acc: 0.945, val acc: 0.944
diff 71.29021419623814
epoch 4 train loss: 4788.788, val loss: 576.874, train acc: 0.951, val acc: 0.944
diff 54.87537002465001
epoch 5 train loss: 4830.349, val loss: 772.748, train acc: 0.951, val acc: 0.949
diff 195.87358382088962
epoch 6 train loss: 4934.999, val loss: 656.206, train acc: 0.953, val acc: 0.949
diff 116.5414728164227
epoch 7 train loss: 4108.142, val loss: 668.197, train acc: 0.957, val acc: 0.955
diff 11.990675645767396
epoch 8 train loss: 3959.740, val loss: 884.745, train acc: 0.959, val acc: 0.942
diff 216.5477751820448
epoch 9 train loss: 3957.000, val loss: 600.298, train acc: 0.961, val acc: 0.952
diff 284.44678501523435
epoch 10 train loss: 4087.936, val loss: 690.978, train acc: 0.961, val acc: 0.949
diff 90.68007791677985
Training model M3
epoch 1 train loss: 5745.884, val loss: 13891.605, train acc: 0.480, val acc: 0.096
diff inf
epoch 2 train loss: 5292.499, val loss: 13384.475, train acc: 0.471, val acc: 0.096
diff 507.12997993262434
epoch 3 train loss: 5286.267, val loss: 13915.932, train acc: 0.480, val acc: 0.096
diff 531.4562692431355
epoch 4 train loss: 5276.006, val loss: 13862.655, train acc: 0.487, val acc: 0.096
diff 53.276737942424006
epoch 5 train loss: 5294.204, val loss: 13266.012, train acc: 0.482, val acc: 0.096
diff 596.6428910401537
epoch 6 train loss: 5280.942, val loss: 11807.297, train acc: 0.478, val acc: 0.096
diff 1458.714773126585
epoch 7 train loss: 5285.161, val loss: 12807.716, train acc: 0.480, val acc: 0.096
diff 1000.4188812350276
epoch 8 train loss: 5260.182, val loss: 13318.050, train acc: 0.493, val acc: 0.096
diff 510.334036670929
epoch 9 train loss: 5290.565, val loss: 13582.975, train acc: 0.476, val acc: 0.104
diff 264.92479705249025
epoch 10 train loss: 5274.150, val loss: 12724.823, train acc: 0.477, val acc: 0.104
diff 858.1520159906322
Training model M3
epoch 1 train loss: 5263.085, val loss: 13799.658, train acc: 0.485, val acc: 0.096
diff inf
epoch 2 train loss: 5263.479, val loss: 13290.252, train acc: 0.467, val acc: 0.104
diff 509.4056058814276
epoch 3 train loss: 5260.814, val loss: 13312.364, train acc: 0.479, val acc: 0.096
diff 22.111750574073085
epoch 4 train loss: 5260.063, val loss: 12788.170, train acc: 0.490, val acc: 0.096
diff 524.1938388718536
epoch 5 train loss: 5263.660, val loss: 13446.331, train acc: 0.484, val acc: 0.096
diff 658.1603942558686
epoch 6 train loss: 5259.972, val loss: 12089.505, train acc: 0.475, val acc: 0.096
diff 1356.8256503297725
epoch 7 train loss: 5264.291, val loss: 12128.457, train acc: 0.478, val acc: 0.096
diff 38.95197600060601
epoch 8 train loss: 5242.808, val loss: 13209.766, train acc: 0.492, val acc: 0.096
diff 1081.3091474711637
epoch 9 train loss: 5265.712, val loss: 13170.642, train acc: 0.481, val acc: 0.104
diff 39.12453701937011
epoch 10 train loss: 5257.336, val loss: 12664.021, train acc: 0.474, val acc: 0.104
diff 506.6203794029443
Training model M3
epoch 1 train loss: 5253.952, val loss: 13773.558, train acc: 0.482, val acc: 0.104
diff inf
epoch 2 train loss: 5255.875, val loss: 13248.599, train acc: 0.468, val acc: 0.104
diff 524.9591301427281
epoch 3 train loss: 5253.934, val loss: 13186.719, train acc: 0.484, val acc: 0.096
diff 61.87962702084951
epoch 4 train loss: 5255.588, val loss: 12633.236, train acc: 0.489, val acc: 0.096
diff 553.482998073303
epoch 5 train loss: 5255.376, val loss: 13505.277, train acc: 0.485, val acc: 0.096
diff 872.0406701318352
epoch 6 train loss: 5253.597, val loss: 12166.532, train acc: 0.480, val acc: 0.096
diff 1338.7448641640658
epoch 7 train loss: 5257.434, val loss: 12085.047, train acc: 0.477, val acc: 0.096
diff 81.48493183412575
epoch 8 train loss: 5239.822, val loss: 13193.381, train acc: 0.495, val acc: 0.096
diff 1108.334100580225
epoch 9 train loss: 5259.470, val loss: 13103.377, train acc: 0.480, val acc: 0.104
diff 90.00434155548828
epoch 10 train loss: 5252.874, val loss: 12654.781, train acc: 0.480, val acc: 0.104
diff 448.5955717393863
2
Training model M3
epoch 1 train loss: 5248.738, val loss: 13724.490, train acc: 0.481, val acc: 0.104
diff inf
epoch 2 train loss: 5252.137, val loss: 13146.945, train acc: 0.469, val acc: 0.104
diff 577.5447430175791
epoch 3 train loss: 5248.533, val loss: 13001.224, train acc: 0.488, val acc: 0.096
diff 145.72069458342594
epoch 4 train loss: 5251.394, val loss: 12542.360, train acc: 0.488, val acc: 0.096
diff 458.8644550607114
epoch 5 train loss: 5249.525, val loss: 13487.633, train acc: 0.484, val acc: 0.096
diff 945.2735692961105
epoch 6 train loss: 5249.451, val loss: 12334.472, train acc: 0.473, val acc: 0.096
diff 1153.1616544917597
epoch 7 train loss: 5252.895, val loss: 12173.714, train acc: 0.475, val acc: 0.096
diff 160.75825687895303
epoch 8 train loss: 5237.375, val loss: 13117.263, train acc: 0.496, val acc: 0.096
diff 943.5496927315162
epoch 9 train loss: 5254.557, val loss: 13014.103, train acc: 0.478, val acc: 0.104
diff 103.16053190676575
epoch 10 train loss: 5249.609, val loss: 12624.361, train acc: 0.482, val acc: 0.104
diff 389.74199409842004
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
Training model M3
epoch 1 train loss: 5245.277, val loss: 13557.931, train acc: 0.483, val acc: 0.104
diff inf
epoch 2 train loss: 5246.314, val loss: 13159.052, train acc: 0.475, val acc: 0.104
diff 398.87892864211244
epoch 3 train loss: 5244.196, val loss: 12939.008, train acc: 0.488, val acc: 0.104
diff 220.0446562754496
epoch 4 train loss: 5246.129, val loss: 12581.369, train acc: 0.482, val acc: 0.096
diff 357.6382539041733
epoch 5 train loss: 5243.821, val loss: 13340.392, train acc: 0.485, val acc: 0.096
diff 759.0227529709682
epoch 6 train loss: 5246.316, val loss: 12573.268, train acc: 0.472, val acc: 0.096
diff 767.1237510208248
epoch 7 train loss: 5248.821, val loss: 12499.484, train acc: 0.475, val acc: 0.096
diff 73.78447180528929
epoch 8 train loss: 5239.541, val loss: 13021.932, train acc: 0.494, val acc: 0.096
diff 522.4477757099412
epoch 9 train loss: 5245.425, val loss: 13033.525, train acc: 0.474, val acc: 0.104
diff 11.593152648239993
epoch 10 train loss: 5243.609, val loss: 13017.762, train acc: 0.483, val acc: 0.104
diff 15.763048793380221
training representation using replay loss
training representation using replay loss
training representation using replay loss
training representation using replay loss
