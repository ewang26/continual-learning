Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 3, 'class_balanced': False, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 45253.846, val loss: 5002.212, train acc: 0.127, val acc: 0.121
diff inf
epoch 2 train loss: 44964.403, val loss: 4987.038, train acc: 0.126, val acc: 0.141
diff 15.173936725406747
epoch 3 train loss: 44945.975, val loss: 4994.446, train acc: 0.131, val acc: 0.124
diff 7.407998281858454
epoch 4 train loss: 44950.160, val loss: 4996.242, train acc: 0.126, val acc: 0.124
diff 1.7962048947911171
epoch 5 train loss: 44949.128, val loss: 4990.326, train acc: 0.129, val acc: 0.141
diff 5.91545437269815
epoch 6 train loss: 44938.614, val loss: 5000.968, train acc: 0.127, val acc: 0.124
diff 10.641364870859434
epoch 7 train loss: 44952.249, val loss: 4991.362, train acc: 0.129, val acc: 0.141
diff 9.605841630605937
epoch 8 train loss: 44938.163, val loss: 4994.234, train acc: 0.131, val acc: 0.141
diff 2.8722522221878535
epoch 9 train loss: 44945.088, val loss: 4994.460, train acc: 0.128, val acc: 0.121
diff 0.22555564891899849
epoch 10 train loss: 44943.481, val loss: 4989.413, train acc: 0.130, val acc: 0.124
diff 5.0471852828422925
Training model M2
epoch 1 train loss: 62695.053, val loss: 6920.710, train acc: 0.099, val acc: 0.097
diff inf
epoch 2 train loss: 62224.969, val loss: 6912.970, train acc: 0.104, val acc: 0.113
diff 7.73987354773999
epoch 3 train loss: 62212.343, val loss: 6908.954, train acc: 0.104, val acc: 0.113
diff 4.01618113548011
epoch 4 train loss: 62211.131, val loss: 6919.074, train acc: 0.103, val acc: 0.099
diff 10.12038459100404
epoch 5 train loss: 62205.283, val loss: 6915.846, train acc: 0.105, val acc: 0.101
diff 3.2280348862514074
epoch 6 train loss: 62214.910, val loss: 6911.750, train acc: 0.102, val acc: 0.113
diff 4.096548960099426
epoch 7 train loss: 62216.204, val loss: 6914.878, train acc: 0.105, val acc: 0.099
diff 3.128438307541728
epoch 8 train loss: 62227.571, val loss: 6907.103, train acc: 0.103, val acc: 0.113
diff 7.775433541468374
epoch 9 train loss: 62212.651, val loss: 6909.962, train acc: 0.104, val acc: 0.104
diff 2.8592951102727966
epoch 10 train loss: 62219.863, val loss: 6908.252, train acc: 0.100, val acc: 0.097
diff 1.710296375240432
Training model M3
epoch 1 train loss: 5714.372, val loss: 13957.844, train acc: 0.482, val acc: 0.096
diff inf
epoch 2 train loss: 5291.820, val loss: 13515.414, train acc: 0.473, val acc: 0.096
diff 442.4300227665626
epoch 3 train loss: 5285.861, val loss: 13861.804, train acc: 0.478, val acc: 0.096
diff 346.3898047610255
epoch 4 train loss: 5275.399, val loss: 13847.520, train acc: 0.485, val acc: 0.096
diff 14.28395878410447
epoch 5 train loss: 5293.509, val loss: 13248.232, train acc: 0.483, val acc: 0.096
diff 599.2885227856405
epoch 6 train loss: 5279.927, val loss: 11852.407, train acc: 0.478, val acc: 0.096
diff 1395.824992960539
epoch 7 train loss: 5283.972, val loss: 12755.767, train acc: 0.480, val acc: 0.096
diff 903.3602581829709
epoch 8 train loss: 5258.556, val loss: 13332.218, train acc: 0.494, val acc: 0.096
diff 576.4512231309709
epoch 9 train loss: 5287.108, val loss: 13525.316, train acc: 0.476, val acc: 0.104
diff 193.0981931574879
epoch 10 train loss: 5271.515, val loss: 12688.478, train acc: 0.477, val acc: 0.104
diff 836.8378434702263
Training model M3
epoch 1 train loss: 5262.418, val loss: 13805.318, train acc: 0.486, val acc: 0.096
diff inf
epoch 2 train loss: 5264.241, val loss: 13295.166, train acc: 0.466, val acc: 0.104
diff 510.1517073465129
epoch 3 train loss: 5261.563, val loss: 13379.502, train acc: 0.479, val acc: 0.096
diff 84.33588672221595
epoch 4 train loss: 5260.634, val loss: 12837.451, train acc: 0.491, val acc: 0.096
diff 542.0509344204293
epoch 5 train loss: 5264.686, val loss: 13427.724, train acc: 0.486, val acc: 0.096
diff 590.2727208031993
epoch 6 train loss: 5260.000, val loss: 12102.071, train acc: 0.475, val acc: 0.096
diff 1325.6524571630089
epoch 7 train loss: 5264.034, val loss: 12030.658, train acc: 0.479, val acc: 0.096
diff 71.41380650999236
epoch 8 train loss: 5242.960, val loss: 13222.111, train acc: 0.492, val acc: 0.096
diff 1191.453478741494
epoch 9 train loss: 5265.671, val loss: 13176.272, train acc: 0.481, val acc: 0.104
diff 45.83949427988409
epoch 10 train loss: 5257.322, val loss: 12643.394, train acc: 0.475, val acc: 0.104
diff 532.8771126616466
Training model M3
epoch 1 train loss: 5254.467, val loss: 13794.681, train acc: 0.483, val acc: 0.104
diff inf
epoch 2 train loss: 5256.368, val loss: 13273.686, train acc: 0.466, val acc: 0.104
diff 520.9952564269588
epoch 3 train loss: 5252.956, val loss: 13199.241, train acc: 0.484, val acc: 0.096
diff 74.4446727905688
epoch 4 train loss: 5255.566, val loss: 12652.641, train acc: 0.488, val acc: 0.096
diff 546.6003336928952
epoch 5 train loss: 5256.150, val loss: 13469.195, train acc: 0.485, val acc: 0.096
diff 816.5540186814687
epoch 6 train loss: 5252.052, val loss: 12215.610, train acc: 0.481, val acc: 0.096
diff 1253.5847173642142
epoch 7 train loss: 5257.710, val loss: 12052.891, train acc: 0.477, val acc: 0.096
diff 162.7195492769606
epoch 8 train loss: 5239.583, val loss: 13218.366, train acc: 0.496, val acc: 0.096
diff 1165.4755997616467
epoch 9 train loss: 5261.044, val loss: 13161.408, train acc: 0.479, val acc: 0.104
diff 56.95875319371589
epoch 10 train loss: 5251.630, val loss: 12623.141, train acc: 0.481, val acc: 0.104
diff 538.2669363493278
Training model M3
epoch 1 train loss: 5250.044, val loss: 13776.319, train acc: 0.481, val acc: 0.104
diff inf
epoch 2 train loss: 5252.491, val loss: 13214.616, train acc: 0.467, val acc: 0.104
diff 561.7026554829044
epoch 3 train loss: 5249.337, val loss: 13081.233, train acc: 0.490, val acc: 0.096
diff 133.38270845801708
epoch 4 train loss: 5252.067, val loss: 12567.573, train acc: 0.489, val acc: 0.096
diff 513.6608353290248
epoch 5 train loss: 5249.935, val loss: 13480.195, train acc: 0.485, val acc: 0.096
diff 912.6221753603168
epoch 6 train loss: 5248.857, val loss: 12308.181, train acc: 0.473, val acc: 0.096
diff 1172.0134918946933
epoch 7 train loss: 5252.202, val loss: 12184.848, train acc: 0.475, val acc: 0.096
diff 123.33289400710783
epoch 8 train loss: 5236.552, val loss: 13139.316, train acc: 0.496, val acc: 0.096
diff 954.4680353661006
epoch 9 train loss: 5253.175, val loss: 13001.996, train acc: 0.478, val acc: 0.104
diff 137.31999987171002
epoch 10 train loss: 5247.822, val loss: 12684.897, train acc: 0.481, val acc: 0.104
diff 317.0996022429172
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
Training model M3
epoch 1 train loss: 5246.384, val loss: 13656.155, train acc: 0.483, val acc: 0.104
diff inf
epoch 2 train loss: 5247.408, val loss: 13163.356, train acc: 0.473, val acc: 0.104
diff 492.79891065487755
epoch 3 train loss: 5245.508, val loss: 12982.254, train acc: 0.488, val acc: 0.104
diff 181.10198844324987
epoch 4 train loss: 5247.418, val loss: 12480.097, train acc: 0.485, val acc: 0.096
diff 502.1569969148295
epoch 5 train loss: 5243.297, val loss: 13282.252, train acc: 0.484, val acc: 0.096
diff 802.1546989228809
epoch 6 train loss: 5245.807, val loss: 12651.735, train acc: 0.473, val acc: 0.096
diff 630.5166269814799
epoch 7 train loss: 5247.189, val loss: 12913.934, train acc: 0.476, val acc: 0.096
diff 262.199266693091
epoch 8 train loss: 5236.375, val loss: 13110.156, train acc: 0.495, val acc: 0.096
diff 196.2218774466437
epoch 9 train loss: 5245.490, val loss: 13044.948, train acc: 0.474, val acc: 0.104
diff 65.20806269783861
epoch 10 train loss: 5243.620, val loss: 13019.284, train acc: 0.483, val acc: 0.104
diff 25.664230016524016
training representation using replay loss
