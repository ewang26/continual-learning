Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 5, 'class_balanced': True, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 7204.570, val loss: 467.984, train acc: 0.905, val acc: 0.948
diff inf
epoch 2 train loss: 4235.690, val loss: 445.701, train acc: 0.943, val acc: 0.953
diff 22.28253558486307
epoch 3 train loss: 3667.377, val loss: 475.022, train acc: 0.952, val acc: 0.951
diff 29.320644139051694
epoch 4 train loss: 3967.212, val loss: 598.643, train acc: 0.949, val acc: 0.941
diff 123.62079333720538
epoch 5 train loss: 3285.021, val loss: 813.076, train acc: 0.957, val acc: 0.934
diff 214.43320493862223
epoch 6 train loss: 3196.252, val loss: 452.802, train acc: 0.959, val acc: 0.954
diff 360.2736306534274
epoch 7 train loss: 5475.210, val loss: 456.572, train acc: 0.932, val acc: 0.955
diff 3.7697543570527046
epoch 8 train loss: 2971.460, val loss: 448.811, train acc: 0.965, val acc: 0.949
diff 7.760671859966749
epoch 9 train loss: 3153.686, val loss: 477.410, train acc: 0.962, val acc: 0.950
diff 28.598714559731434
epoch 10 train loss: 4090.777, val loss: 442.451, train acc: 0.960, val acc: 0.954
diff 34.95904087463117
Training model M2
epoch 1 train loss: 62667.957, val loss: 6920.723, train acc: 0.099, val acc: 0.097
diff inf
epoch 2 train loss: 62224.969, val loss: 6912.970, train acc: 0.104, val acc: 0.113
diff 7.752879671315895
epoch 3 train loss: 62212.343, val loss: 6908.954, train acc: 0.104, val acc: 0.113
diff 4.01640223486902
epoch 4 train loss: 62211.131, val loss: 6919.074, train acc: 0.103, val acc: 0.099
diff 10.120378155660546
epoch 5 train loss: 62205.283, val loss: 6915.846, train acc: 0.105, val acc: 0.101
diff 3.228032564078603
epoch 6 train loss: 62214.910, val loss: 6911.750, train acc: 0.102, val acc: 0.113
diff 4.096549002902066
epoch 7 train loss: 62216.204, val loss: 6914.878, train acc: 0.105, val acc: 0.099
diff 3.12843830521615
epoch 8 train loss: 62227.571, val loss: 6907.103, train acc: 0.103, val acc: 0.113
diff 7.775433540603444
epoch 9 train loss: 62212.651, val loss: 6909.962, train acc: 0.104, val acc: 0.104
diff 2.8592951102618827
epoch 10 train loss: 62219.863, val loss: 6908.252, train acc: 0.100, val acc: 0.097
diff 1.710296375238613
Training model M3
epoch 1 train loss: 2320.129, val loss: 9048.592, train acc: 0.910, val acc: 0.198
diff inf
epoch 2 train loss: 1353.151, val loss: 8372.452, train acc: 0.938, val acc: 0.245
diff 676.1401103216122
epoch 3 train loss: 1211.505, val loss: 12611.709, train acc: 0.944, val acc: 0.285
diff 4239.256325535769
epoch 4 train loss: 1086.883, val loss: 6721.400, train acc: 0.947, val acc: 0.387
diff 5890.308287075794
epoch 5 train loss: 937.503, val loss: 5945.565, train acc: 0.951, val acc: 0.437
diff 775.835168298574
epoch 6 train loss: 875.310, val loss: 6201.931, train acc: 0.958, val acc: 0.462
diff 256.3655707511971
epoch 7 train loss: 972.852, val loss: 10713.567, train acc: 0.950, val acc: 0.427
diff 4511.636512976645
epoch 8 train loss: 952.919, val loss: 7121.480, train acc: 0.956, val acc: 0.465
diff 3592.0869264812754
epoch 9 train loss: 743.266, val loss: 6385.565, train acc: 0.964, val acc: 0.489
diff 735.9151154468755
epoch 10 train loss: 705.317, val loss: 7456.422, train acc: 0.964, val acc: 0.495
diff 1070.856338056803
Training model M3
epoch 1 train loss: 666.526, val loss: 11152.333, train acc: 0.967, val acc: 0.444
diff inf
epoch 2 train loss: 1008.393, val loss: 11980.808, train acc: 0.958, val acc: 0.505
diff 828.4750093616676
epoch 3 train loss: 688.427, val loss: 12912.894, train acc: 0.965, val acc: 0.514
diff 932.0858248305085
epoch 4 train loss: 450.519, val loss: 16217.913, train acc: 0.976, val acc: 0.434
diff 3305.018669031175
epoch 5 train loss: 334.279, val loss: 14963.270, train acc: 0.982, val acc: 0.546
diff 1254.6429871367309
epoch 6 train loss: 1446.470, val loss: 20396.021, train acc: 0.954, val acc: 0.479
diff 5432.750934257745
epoch 7 train loss: 431.167, val loss: 19205.893, train acc: 0.977, val acc: 0.518
diff 1190.1281418322724
epoch 8 train loss: 277.860, val loss: 20527.689, train acc: 0.984, val acc: 0.558
diff 1321.7959550977503
epoch 9 train loss: 339.335, val loss: 22972.155, train acc: 0.982, val acc: 0.513
diff 2444.465992136582
epoch 10 train loss: 337.723, val loss: 27590.673, train acc: 0.983, val acc: 0.481
diff 4618.517926269611
Training model M3
epoch 1 train loss: 2470.484, val loss: 8375.825, train acc: 0.928, val acc: 0.324
diff inf
epoch 2 train loss: 1554.702, val loss: 8010.851, train acc: 0.945, val acc: 0.285
diff 364.9743963780493
epoch 3 train loss: 1306.697, val loss: 7190.936, train acc: 0.944, val acc: 0.365
diff 819.9148150087531
epoch 4 train loss: 1198.160, val loss: 6982.698, train acc: 0.949, val acc: 0.305
diff 208.23805197018646
epoch 5 train loss: 1367.322, val loss: 7930.134, train acc: 0.943, val acc: 0.292
diff 947.4356071160737
epoch 6 train loss: 1079.868, val loss: 7091.487, train acc: 0.952, val acc: 0.330
diff 838.6472318202932
epoch 7 train loss: 1027.697, val loss: 7906.161, train acc: 0.952, val acc: 0.396
diff 814.6746365715444
epoch 8 train loss: 1217.135, val loss: 8978.120, train acc: 0.948, val acc: 0.318
diff 1071.958747356629
epoch 9 train loss: 1356.141, val loss: 8237.852, train acc: 0.946, val acc: 0.227
diff 740.267505886346
epoch 10 train loss: 1267.540, val loss: 7368.060, train acc: 0.944, val acc: 0.322
diff 869.7925113556112
2
2
Training model M3
epoch 1 train loss: 1171.164, val loss: 9525.167, train acc: 0.949, val acc: 0.435
diff inf
epoch 2 train loss: 1144.808, val loss: 7163.922, train acc: 0.949, val acc: 0.394
diff 2361.2448277137782
epoch 3 train loss: 1066.721, val loss: 20536.882, train acc: 0.952, val acc: 0.363
diff 13372.959758215482
epoch 4 train loss: 1023.812, val loss: 7647.659, train acc: 0.955, val acc: 0.438
diff 12889.223552314339
epoch 5 train loss: 881.023, val loss: 7070.693, train acc: 0.960, val acc: 0.503
diff 576.9658016047297
epoch 6 train loss: 1161.985, val loss: 6373.477, train acc: 0.955, val acc: 0.480
diff 697.2157418603783
epoch 7 train loss: 949.228, val loss: 7320.653, train acc: 0.960, val acc: 0.476
diff 947.175620603417
epoch 8 train loss: 1054.314, val loss: 9144.521, train acc: 0.954, val acc: 0.471
diff 1823.868082946129
epoch 9 train loss: 930.324, val loss: 7555.154, train acc: 0.957, val acc: 0.461
diff 1589.3666433156186
epoch 10 train loss: 1210.161, val loss: 7631.014, train acc: 0.940, val acc: 0.507
diff 75.85976712952925
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
Training model M3
epoch 1 train loss: 1590.986, val loss: 7100.413, train acc: 0.956, val acc: 0.446
diff inf
epoch 2 train loss: 1092.469, val loss: 6827.480, train acc: 0.957, val acc: 0.479
diff 272.9329261131552
epoch 3 train loss: 1019.490, val loss: 6632.758, train acc: 0.957, val acc: 0.456
diff 194.72137792987724
epoch 4 train loss: 989.285, val loss: 6873.669, train acc: 0.959, val acc: 0.477
diff 240.9105210834905
epoch 5 train loss: 1010.381, val loss: 7677.835, train acc: 0.957, val acc: 0.474
diff 804.165557949188
epoch 6 train loss: 950.938, val loss: 6041.841, train acc: 0.958, val acc: 0.473
diff 1635.9933911726603
epoch 7 train loss: 884.310, val loss: 8763.897, train acc: 0.961, val acc: 0.481
diff 2722.0558113512425
epoch 8 train loss: 1198.111, val loss: 7322.697, train acc: 0.958, val acc: 0.466
diff 1441.2002862491881
epoch 9 train loss: 878.704, val loss: 7116.274, train acc: 0.962, val acc: 0.463
diff 206.4222326310237
epoch 10 train loss: 799.305, val loss: 7573.585, train acc: 0.963, val acc: 0.512
diff 457.3107084021867
training representation using replay loss
training representation using replay loss
training representation using replay loss
