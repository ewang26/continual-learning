Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 10, 'class_balanced': False, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 4702.812, val loss: 392.226, train acc: 0.946, val acc: 0.964
diff inf
epoch 2 train loss: 3101.314, val loss: 435.615, train acc: 0.966, val acc: 0.960
diff 43.388476488531126
epoch 3 train loss: 2431.234, val loss: 216.018, train acc: 0.975, val acc: 0.976
diff 219.59669856073066
epoch 4 train loss: 2096.348, val loss: 310.692, train acc: 0.976, val acc: 0.969
diff 94.67376284964661
epoch 5 train loss: 1919.275, val loss: 233.299, train acc: 0.980, val acc: 0.977
diff 77.39308147881954
epoch 6 train loss: 2559.068, val loss: 741.731, train acc: 0.975, val acc: 0.955
diff 508.43193009909953
epoch 7 train loss: 2474.943, val loss: 1122.976, train acc: 0.977, val acc: 0.951
diff 381.24530075869336
epoch 8 train loss: 2088.459, val loss: 315.975, train acc: 0.980, val acc: 0.976
diff 807.0007835698412
epoch 9 train loss: 1690.846, val loss: 576.895, train acc: 0.983, val acc: 0.971
diff 260.92025199524096
epoch 10 train loss: 2276.319, val loss: 533.733, train acc: 0.981, val acc: 0.963
diff 43.16249248035808
Training model M2
epoch 1 train loss: 62506.381, val loss: 6920.723, train acc: 0.099, val acc: 0.097
diff inf
epoch 2 train loss: 62224.970, val loss: 6912.970, train acc: 0.104, val acc: 0.113
diff 7.753101183495346
epoch 3 train loss: 62212.343, val loss: 6908.954, train acc: 0.104, val acc: 0.113
diff 4.016343319442058
epoch 4 train loss: 62211.131, val loss: 6919.074, train acc: 0.103, val acc: 0.099
diff 10.120380362509422
epoch 5 train loss: 62205.283, val loss: 6915.846, train acc: 0.105, val acc: 0.101
diff 3.2280326832287756
epoch 6 train loss: 62214.910, val loss: 6911.750, train acc: 0.102, val acc: 0.113
diff 4.096548986438393
epoch 7 train loss: 62216.204, val loss: 6914.878, train acc: 0.105, val acc: 0.099
diff 3.1284382997491775
epoch 8 train loss: 62227.571, val loss: 6907.103, train acc: 0.103, val acc: 0.113
diff 7.775433540733502
epoch 9 train loss: 62212.651, val loss: 6909.962, train acc: 0.104, val acc: 0.104
diff 2.859295110260973
epoch 10 train loss: 62219.863, val loss: 6908.252, train acc: 0.100, val acc: 0.097
diff 1.7102963752340656
Training model M3
epoch 1 train loss: 5644.380, val loss: 13901.962, train acc: 0.480, val acc: 0.096
diff inf
epoch 2 train loss: 5295.241, val loss: 13336.700, train acc: 0.472, val acc: 0.096
diff 565.2626978663775
epoch 3 train loss: 5288.704, val loss: 14070.637, train acc: 0.480, val acc: 0.096
diff 733.9379886432744
epoch 4 train loss: 5278.366, val loss: 14065.598, train acc: 0.485, val acc: 0.096
diff 5.039912805626955
epoch 5 train loss: 5297.691, val loss: 13252.181, train acc: 0.479, val acc: 0.096
diff 813.4165092965995
epoch 6 train loss: 5283.244, val loss: 11753.855, train acc: 0.478, val acc: 0.096
diff 1498.3258857125093
epoch 7 train loss: 5287.934, val loss: 12906.985, train acc: 0.478, val acc: 0.096
diff 1153.1302357851273
epoch 8 train loss: 5262.723, val loss: 13306.083, train acc: 0.492, val acc: 0.096
diff 399.0980536913594
epoch 9 train loss: 5294.098, val loss: 13582.131, train acc: 0.477, val acc: 0.104
diff 276.0470592199872
epoch 10 train loss: 5277.557, val loss: 12792.349, train acc: 0.478, val acc: 0.104
diff 789.7820220517842
Training model M3
epoch 1 train loss: 5269.737, val loss: 13806.909, train acc: 0.486, val acc: 0.096
diff inf
epoch 2 train loss: 5268.674, val loss: 13257.121, train acc: 0.465, val acc: 0.104
diff 549.787782220219
epoch 3 train loss: 5264.987, val loss: 13563.012, train acc: 0.481, val acc: 0.096
diff 305.89130490733623
epoch 4 train loss: 5262.616, val loss: 12898.203, train acc: 0.489, val acc: 0.096
diff 664.8091410677898
epoch 5 train loss: 5266.480, val loss: 13404.203, train acc: 0.486, val acc: 0.096
diff 505.99959248609775
epoch 6 train loss: 5261.064, val loss: 12073.895, train acc: 0.475, val acc: 0.096
diff 1330.3081998607468
epoch 7 train loss: 5264.101, val loss: 12120.718, train acc: 0.478, val acc: 0.096
diff 46.8234697574826
epoch 8 train loss: 5243.098, val loss: 13229.158, train acc: 0.493, val acc: 0.096
diff 1108.4399659288283
epoch 9 train loss: 5265.739, val loss: 13186.924, train acc: 0.481, val acc: 0.104
diff 42.23453868312572
epoch 10 train loss: 5257.158, val loss: 12653.258, train acc: 0.475, val acc: 0.104
diff 533.6652287525158
Training model M3
epoch 1 train loss: 5242.633, val loss: 13862.153, train acc: 0.483, val acc: 0.104
diff inf
epoch 2 train loss: 5243.511, val loss: 13380.775, train acc: 0.469, val acc: 0.104
diff 481.37799929819266
epoch 3 train loss: 5240.699, val loss: 13198.177, train acc: 0.487, val acc: 0.096
diff 182.5973337241412
epoch 4 train loss: 5242.985, val loss: 12765.927, train acc: 0.487, val acc: 0.096
diff 432.2501688382763
epoch 5 train loss: 5242.004, val loss: 13507.860, train acc: 0.486, val acc: 0.096
diff 741.9325793203552
epoch 6 train loss: 5241.588, val loss: 12359.867, train acc: 0.478, val acc: 0.096
diff 1147.9926320546547
epoch 7 train loss: 5246.178, val loss: 12146.219, train acc: 0.476, val acc: 0.096
diff 213.64774177487197
epoch 8 train loss: 5227.880, val loss: 13262.290, train acc: 0.496, val acc: 0.096
diff 1116.0707028135712
epoch 9 train loss: 5247.050, val loss: 13166.330, train acc: 0.482, val acc: 0.104
diff 95.95989292186096
epoch 10 train loss: 5240.776, val loss: 12729.123, train acc: 0.480, val acc: 0.104
diff 437.2076159592216
