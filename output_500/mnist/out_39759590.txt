Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 12, 'class_balanced': True, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 5043.666, val loss: 325.970, train acc: 0.937, val acc: 0.963
diff inf
epoch 2 train loss: 3351.089, val loss: 275.202, train acc: 0.960, val acc: 0.966
diff 50.767481339432265
epoch 3 train loss: 2924.395, val loss: 396.133, train acc: 0.965, val acc: 0.960
diff 120.93046700301517
epoch 4 train loss: 2326.416, val loss: 236.221, train acc: 0.974, val acc: 0.973
diff 159.91162880940735
epoch 5 train loss: 2039.470, val loss: 255.085, train acc: 0.975, val acc: 0.976
diff 18.863753384625085
epoch 6 train loss: 3271.181, val loss: 773.875, train acc: 0.974, val acc: 0.957
diff 518.7901633194248
epoch 7 train loss: 2595.232, val loss: 419.085, train acc: 0.974, val acc: 0.973
diff 354.7901999028299
epoch 8 train loss: 1612.221, val loss: 430.784, train acc: 0.981, val acc: 0.968
diff 11.699054219338166
epoch 9 train loss: 1575.701, val loss: 244.599, train acc: 0.982, val acc: 0.970
diff 186.18528732303662
epoch 10 train loss: 1852.216, val loss: 369.620, train acc: 0.980, val acc: 0.968
diff 125.02130940130047
Training model M2
epoch 1 train loss: 13504.559, val loss: 1065.205, train acc: 0.845, val acc: 0.886
diff inf
epoch 2 train loss: 8124.593, val loss: 863.349, train acc: 0.908, val acc: 0.910
diff 201.85592308276352
epoch 3 train loss: 7052.728, val loss: 1147.394, train acc: 0.920, val acc: 0.885
diff 284.04466632155425
epoch 4 train loss: 6457.541, val loss: 871.054, train acc: 0.926, val acc: 0.910
diff 276.3399538559628
epoch 5 train loss: 6195.881, val loss: 676.956, train acc: 0.929, val acc: 0.935
diff 194.09734644703212
epoch 6 train loss: 6031.330, val loss: 963.430, train acc: 0.932, val acc: 0.919
diff 286.4736295971088
epoch 7 train loss: 5895.337, val loss: 680.524, train acc: 0.938, val acc: 0.933
diff 282.9060768522032
epoch 8 train loss: 7110.806, val loss: 834.285, train acc: 0.927, val acc: 0.925
diff 153.76151825268175
epoch 9 train loss: 5611.534, val loss: 650.821, train acc: 0.937, val acc: 0.937
diff 183.4644766389141
epoch 10 train loss: 5669.060, val loss: 882.856, train acc: 0.938, val acc: 0.924
diff 232.0353520313223
Training model M3
epoch 1 train loss: 6001.305, val loss: 13873.690, train acc: 0.481, val acc: 0.096
diff inf
epoch 2 train loss: 5292.133, val loss: 13430.554, train acc: 0.469, val acc: 0.096
diff 443.1362986027034
epoch 3 train loss: 5285.554, val loss: 13839.434, train acc: 0.481, val acc: 0.096
diff 408.88021361364554
epoch 4 train loss: 5275.129, val loss: 13822.385, train acc: 0.488, val acc: 0.096
diff 17.049250631614996
epoch 5 train loss: 5292.130, val loss: 13295.879, train acc: 0.485, val acc: 0.096
diff 526.5054714134476
epoch 6 train loss: 5279.325, val loss: 11832.891, train acc: 0.476, val acc: 0.096
diff 1462.9880363802276
epoch 7 train loss: 5282.667, val loss: 12677.462, train acc: 0.479, val acc: 0.096
diff 844.5712540967743
epoch 8 train loss: 5257.805, val loss: 13329.169, train acc: 0.493, val acc: 0.096
diff 651.706617547612
epoch 9 train loss: 5287.040, val loss: 13542.840, train acc: 0.478, val acc: 0.104
diff 213.6708253877423
epoch 10 train loss: 5271.600, val loss: 12678.399, train acc: 0.478, val acc: 0.104
diff 864.4402823069067
Training model M3
epoch 1 train loss: 5262.743, val loss: 13791.490, train acc: 0.484, val acc: 0.096
diff inf
epoch 2 train loss: 5263.464, val loss: 13299.434, train acc: 0.467, val acc: 0.104
diff 492.0554021562948
epoch 3 train loss: 5260.551, val loss: 13299.705, train acc: 0.479, val acc: 0.096
diff 0.2704170357374096
epoch 4 train loss: 5259.842, val loss: 12743.063, train acc: 0.490, val acc: 0.096
diff 556.6421190859019
epoch 5 train loss: 5262.148, val loss: 13474.743, train acc: 0.485, val acc: 0.096
diff 731.6799518072894
epoch 6 train loss: 5259.120, val loss: 12112.719, train acc: 0.474, val acc: 0.096
diff 1362.023620780863
epoch 7 train loss: 5263.451, val loss: 12091.186, train acc: 0.478, val acc: 0.096
diff 21.53314566690642
epoch 8 train loss: 5243.463, val loss: 13227.284, train acc: 0.493, val acc: 0.096
diff 1136.0981345922337
epoch 9 train loss: 5267.061, val loss: 13235.496, train acc: 0.481, val acc: 0.104
diff 8.21175319538088
epoch 10 train loss: 5258.346, val loss: 12659.770, train acc: 0.475, val acc: 0.104
diff 575.7253551683461
Training model M3
epoch 1 train loss: 5254.581, val loss: 13766.899, train acc: 0.483, val acc: 0.104
diff inf
epoch 2 train loss: 5255.906, val loss: 13255.973, train acc: 0.468, val acc: 0.104
diff 510.9258487727129
epoch 3 train loss: 5253.855, val loss: 13173.342, train acc: 0.485, val acc: 0.096
diff 82.63088231306028
epoch 4 train loss: 5255.494, val loss: 12583.091, train acc: 0.488, val acc: 0.096
diff 590.2513977559938
epoch 5 train loss: 5253.669, val loss: 13532.471, train acc: 0.486, val acc: 0.096
diff 949.3798080644756
epoch 6 train loss: 5252.890, val loss: 12215.727, train acc: 0.479, val acc: 0.096
diff 1316.743100950138
epoch 7 train loss: 5257.205, val loss: 12084.734, train acc: 0.476, val acc: 0.096
diff 130.9934080551484
epoch 8 train loss: 5239.828, val loss: 13197.626, train acc: 0.497, val acc: 0.096
diff 1112.8917998399957
epoch 9 train loss: 5259.628, val loss: 13110.252, train acc: 0.480, val acc: 0.104
diff 87.3739742552043
epoch 10 train loss: 5253.041, val loss: 12648.357, train acc: 0.480, val acc: 0.104
diff 461.8945628251313
2
