Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 6, 'class_balanced': False, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 5533.298, val loss: 316.746, train acc: 0.927, val acc: 0.964
diff inf
epoch 2 train loss: 3685.357, val loss: 474.375, train acc: 0.959, val acc: 0.955
diff 157.62882444512343
epoch 3 train loss: 2818.597, val loss: 283.247, train acc: 0.965, val acc: 0.971
diff 191.1280672164445
epoch 4 train loss: 2483.270, val loss: 232.336, train acc: 0.970, val acc: 0.975
diff 50.91063426502177
epoch 5 train loss: 2796.353, val loss: 214.035, train acc: 0.968, val acc: 0.974
diff 18.3012621272039
epoch 6 train loss: 2440.586, val loss: 334.706, train acc: 0.976, val acc: 0.972
diff 120.67116634763167
epoch 7 train loss: 2232.339, val loss: 276.674, train acc: 0.976, val acc: 0.977
diff 58.03198645936658
epoch 8 train loss: 2136.045, val loss: 326.299, train acc: 0.980, val acc: 0.975
diff 49.62492984290634
epoch 9 train loss: 1873.953, val loss: 401.196, train acc: 0.981, val acc: 0.974
diff 74.89685688242866
epoch 10 train loss: 1621.712, val loss: 361.355, train acc: 0.982, val acc: 0.964
diff 39.841249185102015
Training model M2
epoch 1 train loss: 62499.925, val loss: 6920.704, train acc: 0.098, val acc: 0.097
diff inf
epoch 2 train loss: 62224.970, val loss: 6912.970, train acc: 0.104, val acc: 0.113
diff 7.734277885897427
epoch 3 train loss: 62212.343, val loss: 6908.954, train acc: 0.104, val acc: 0.113
diff 4.016325116500411
epoch 4 train loss: 62211.131, val loss: 6919.074, train acc: 0.103, val acc: 0.099
diff 10.120388002446816
epoch 5 train loss: 62205.283, val loss: 6915.846, train acc: 0.105, val acc: 0.101
diff 3.228034987666433
epoch 6 train loss: 62214.910, val loss: 6911.750, train acc: 0.102, val acc: 0.113
diff 4.096548923813316
epoch 7 train loss: 62216.204, val loss: 6914.878, train acc: 0.105, val acc: 0.099
diff 3.128438299805566
epoch 8 train loss: 62227.571, val loss: 6907.103, train acc: 0.103, val acc: 0.113
diff 7.7754335413847
epoch 9 train loss: 62212.651, val loss: 6909.962, train acc: 0.104, val acc: 0.104
diff 2.859295110255516
epoch 10 train loss: 62219.863, val loss: 6908.252, train acc: 0.100, val acc: 0.097
diff 1.7102963752367941
Training model M3
epoch 1 train loss: 2175.607, val loss: 10334.046, train acc: 0.914, val acc: 0.292
diff inf
epoch 2 train loss: 1195.981, val loss: 5929.757, train acc: 0.946, val acc: 0.552
diff 4404.288941492186
epoch 3 train loss: 1092.385, val loss: 5945.058, train acc: 0.951, val acc: 0.508
diff 15.301152305236428
epoch 4 train loss: 935.206, val loss: 5312.043, train acc: 0.954, val acc: 0.557
diff 633.0150798377272
epoch 5 train loss: 646.243, val loss: 6804.681, train acc: 0.970, val acc: 0.583
diff 1492.6379136363366
epoch 6 train loss: 2017.535, val loss: 10204.031, train acc: 0.925, val acc: 0.501
diff 3399.3498519851846
epoch 7 train loss: 1215.211, val loss: 9650.310, train acc: 0.957, val acc: 0.490
diff 553.7209567051013
epoch 8 train loss: 712.708, val loss: 7285.116, train acc: 0.965, val acc: 0.542
diff 2365.1935851963663
epoch 9 train loss: 587.535, val loss: 8991.117, train acc: 0.971, val acc: 0.575
diff 1706.001203371019
epoch 10 train loss: 857.444, val loss: 8679.013, train acc: 0.965, val acc: 0.625
diff 312.1044037796182
Training model M3
epoch 1 train loss: 912.339, val loss: 25926.424, train acc: 0.965, val acc: 0.459
diff inf
epoch 2 train loss: 1134.832, val loss: 22999.702, train acc: 0.965, val acc: 0.413
diff 2926.722093660188
epoch 3 train loss: 524.636, val loss: 18695.430, train acc: 0.979, val acc: 0.476
diff 4304.271348798451
epoch 4 train loss: 522.282, val loss: 62936.778, train acc: 0.984, val acc: 0.506
diff 44241.34732579919
epoch 5 train loss: 428.464, val loss: 24355.338, train acc: 0.986, val acc: 0.516
diff 38581.439536182195
epoch 6 train loss: 575.404, val loss: 63047.595, train acc: 0.980, val acc: 0.507
diff 38692.257192116536
epoch 7 train loss: 664.135, val loss: 28902.397, train acc: 0.979, val acc: 0.537
diff 34145.19804673242
epoch 8 train loss: 655.746, val loss: 23800.064, train acc: 0.985, val acc: 0.521
diff 5102.333301554827
epoch 9 train loss: 306.172, val loss: 28806.062, train acc: 0.988, val acc: 0.511
diff 5005.9974589723715
epoch 10 train loss: 104.371, val loss: 34661.273, train acc: 0.994, val acc: 0.520
diff 5855.211224718227
Training model M3
epoch 1 train loss: 2997.331, val loss: 14156.257, train acc: 0.933, val acc: 0.309
diff inf
epoch 2 train loss: 1568.490, val loss: 10941.311, train acc: 0.947, val acc: 0.381
diff 3214.9456291496153
epoch 3 train loss: 1191.748, val loss: 11200.293, train acc: 0.952, val acc: 0.405
diff 258.98164298789743
epoch 4 train loss: 1009.861, val loss: 12655.537, train acc: 0.958, val acc: 0.451
diff 1455.2442834974463
epoch 5 train loss: 888.115, val loss: 13907.060, train acc: 0.959, val acc: 0.458
diff 1251.522579210623
epoch 6 train loss: 1017.578, val loss: 18091.880, train acc: 0.961, val acc: 0.411
diff 4184.820189082569
epoch 7 train loss: 724.885, val loss: 16236.489, train acc: 0.966, val acc: 0.449
diff 1855.390640056954
epoch 8 train loss: 504.473, val loss: 27818.126, train acc: 0.975, val acc: 0.449
diff 11581.636131104675
epoch 9 train loss: 556.180, val loss: 19694.038, train acc: 0.975, val acc: 0.405
diff 8124.0875681308025
epoch 10 train loss: 514.381, val loss: 25835.557, train acc: 0.973, val acc: 0.425
diff 6141.519261401601
Training model M3
epoch 1 train loss: 1306.816, val loss: 10864.661, train acc: 0.955, val acc: 0.515
diff inf
epoch 2 train loss: 988.290, val loss: 5771.870, train acc: 0.958, val acc: 0.542
diff 5092.790137369748
epoch 3 train loss: 3486.760, val loss: 9990.328, train acc: 0.893, val acc: 0.275
diff 4218.457329432598
epoch 4 train loss: 1724.817, val loss: 7888.964, train acc: 0.933, val acc: 0.459
diff 2101.3637778114153
epoch 5 train loss: 767.757, val loss: 6083.470, train acc: 0.965, val acc: 0.589
diff 1805.4940147358393
epoch 6 train loss: 577.156, val loss: 10960.844, train acc: 0.972, val acc: 0.645
diff 4877.374028545351
epoch 7 train loss: 447.745, val loss: 9340.895, train acc: 0.973, val acc: 0.607
diff 1619.9492738947101
epoch 8 train loss: 402.247, val loss: 9295.104, train acc: 0.978, val acc: 0.622
diff 45.79026682032236
epoch 9 train loss: 418.606, val loss: 7256.548, train acc: 0.981, val acc: 0.594
diff 2038.5563901307678
epoch 10 train loss: 362.077, val loss: 7988.423, train acc: 0.983, val acc: 0.615
diff 731.8747716620774
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
Training model M3
epoch 1 train loss: 1177.110, val loss: 8047.383, train acc: 0.958, val acc: 0.559
diff inf
epoch 2 train loss: 1414.624, val loss: 7331.184, train acc: 0.940, val acc: 0.389
diff 716.1985942526153
epoch 3 train loss: 1162.758, val loss: 6058.186, train acc: 0.954, val acc: 0.461
diff 1272.9980535772993
epoch 4 train loss: 945.861, val loss: 5914.857, train acc: 0.959, val acc: 0.545
diff 143.32904595864784
epoch 5 train loss: 730.179, val loss: 7116.687, train acc: 0.968, val acc: 0.498
diff 1201.8297251440035
epoch 6 train loss: 610.820, val loss: 7592.281, train acc: 0.970, val acc: 0.517
diff 475.59422158576217
epoch 7 train loss: 502.625, val loss: 6202.516, train acc: 0.974, val acc: 0.521
diff 1389.7653239058936
epoch 8 train loss: 782.834, val loss: 8885.410, train acc: 0.968, val acc: 0.377
diff 2682.8939571738474
epoch 9 train loss: 711.831, val loss: 7045.482, train acc: 0.968, val acc: 0.558
diff 1839.9279017968747
epoch 10 train loss: 477.960, val loss: 13092.933, train acc: 0.974, val acc: 0.545
diff 6047.45091783775
training representation using replay loss
