Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 5, 'class_balanced': False, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 7204.570, val loss: 467.984, train acc: 0.905, val acc: 0.948
diff inf
epoch 2 train loss: 4235.690, val loss: 445.701, train acc: 0.943, val acc: 0.953
diff 22.28253558486307
epoch 3 train loss: 3667.377, val loss: 475.022, train acc: 0.952, val acc: 0.951
diff 29.320644139051694
epoch 4 train loss: 3967.212, val loss: 598.643, train acc: 0.949, val acc: 0.941
diff 123.62079333720538
epoch 5 train loss: 3285.021, val loss: 813.076, train acc: 0.957, val acc: 0.934
diff 214.43320493862223
epoch 6 train loss: 3196.252, val loss: 452.802, train acc: 0.959, val acc: 0.954
diff 360.2736306534274
epoch 7 train loss: 5475.210, val loss: 456.572, train acc: 0.932, val acc: 0.955
diff 3.7697543570527046
epoch 8 train loss: 2971.460, val loss: 448.811, train acc: 0.965, val acc: 0.949
diff 7.760671859966749
epoch 9 train loss: 3153.686, val loss: 477.410, train acc: 0.962, val acc: 0.950
diff 28.598714559731434
epoch 10 train loss: 4090.777, val loss: 442.451, train acc: 0.960, val acc: 0.954
diff 34.95904087463117
Training model M2
epoch 1 train loss: 62667.957, val loss: 6920.723, train acc: 0.099, val acc: 0.097
diff inf
epoch 2 train loss: 62224.969, val loss: 6912.970, train acc: 0.104, val acc: 0.113
diff 7.752879671315895
epoch 3 train loss: 62212.343, val loss: 6908.954, train acc: 0.104, val acc: 0.113
diff 4.01640223486902
epoch 4 train loss: 62211.131, val loss: 6919.074, train acc: 0.103, val acc: 0.099
diff 10.120378155660546
epoch 5 train loss: 62205.283, val loss: 6915.846, train acc: 0.105, val acc: 0.101
diff 3.228032564078603
epoch 6 train loss: 62214.910, val loss: 6911.750, train acc: 0.102, val acc: 0.113
diff 4.096549002902066
epoch 7 train loss: 62216.204, val loss: 6914.878, train acc: 0.105, val acc: 0.099
diff 3.12843830521615
epoch 8 train loss: 62227.571, val loss: 6907.103, train acc: 0.103, val acc: 0.113
diff 7.775433540603444
epoch 9 train loss: 62212.651, val loss: 6909.962, train acc: 0.104, val acc: 0.104
diff 2.8592951102618827
epoch 10 train loss: 62219.863, val loss: 6908.252, train acc: 0.100, val acc: 0.097
diff 1.710296375238613
Training model M3
epoch 1 train loss: 2320.129, val loss: 9048.592, train acc: 0.910, val acc: 0.198
diff inf
epoch 2 train loss: 1353.151, val loss: 8372.452, train acc: 0.938, val acc: 0.245
diff 676.1401103216122
epoch 3 train loss: 1211.505, val loss: 12611.709, train acc: 0.944, val acc: 0.285
diff 4239.256325535769
epoch 4 train loss: 1086.883, val loss: 6721.400, train acc: 0.947, val acc: 0.387
diff 5890.308287075794
epoch 5 train loss: 937.503, val loss: 5945.565, train acc: 0.951, val acc: 0.437
diff 775.835168298574
epoch 6 train loss: 875.310, val loss: 6201.931, train acc: 0.958, val acc: 0.462
diff 256.3655707511971
epoch 7 train loss: 972.852, val loss: 10713.567, train acc: 0.950, val acc: 0.427
diff 4511.636512976645
epoch 8 train loss: 952.919, val loss: 7121.480, train acc: 0.956, val acc: 0.465
diff 3592.0869264812754
epoch 9 train loss: 743.266, val loss: 6385.565, train acc: 0.964, val acc: 0.489
diff 735.9151154468755
epoch 10 train loss: 705.317, val loss: 7456.422, train acc: 0.964, val acc: 0.495
diff 1070.856338056803
Training model M3
epoch 1 train loss: 666.526, val loss: 11152.333, train acc: 0.967, val acc: 0.444
diff inf
epoch 2 train loss: 1008.393, val loss: 11980.808, train acc: 0.958, val acc: 0.505
diff 828.4750093616676
epoch 3 train loss: 688.427, val loss: 12912.894, train acc: 0.965, val acc: 0.514
diff 932.0858248305085
epoch 4 train loss: 450.519, val loss: 16217.913, train acc: 0.976, val acc: 0.434
diff 3305.018669031175
epoch 5 train loss: 334.279, val loss: 14963.270, train acc: 0.982, val acc: 0.546
diff 1254.6429871367309
epoch 6 train loss: 1446.470, val loss: 20396.021, train acc: 0.954, val acc: 0.479
diff 5432.750934257745
epoch 7 train loss: 431.167, val loss: 19205.893, train acc: 0.977, val acc: 0.518
diff 1190.1281418322724
epoch 8 train loss: 277.860, val loss: 20527.689, train acc: 0.984, val acc: 0.558
diff 1321.7959550977503
epoch 9 train loss: 339.335, val loss: 22972.155, train acc: 0.982, val acc: 0.513
diff 2444.465992136582
epoch 10 train loss: 337.723, val loss: 27590.673, train acc: 0.983, val acc: 0.481
diff 4618.517926269611
Training model M3
epoch 1 train loss: 2024.572, val loss: 8333.965, train acc: 0.938, val acc: 0.294
diff inf
epoch 2 train loss: 1222.977, val loss: 6930.592, train acc: 0.948, val acc: 0.378
diff 1403.3730812222666
epoch 3 train loss: 1526.131, val loss: 10247.819, train acc: 0.946, val acc: 0.322
diff 3317.2278102467835
epoch 4 train loss: 1369.815, val loss: 10139.262, train acc: 0.942, val acc: 0.318
diff 108.55773950676485
epoch 5 train loss: 989.976, val loss: 17490.680, train acc: 0.951, val acc: 0.328
diff 7351.417808177857
epoch 6 train loss: 1068.095, val loss: 7721.814, train acc: 0.948, val acc: 0.360
diff 9768.866029271598
epoch 7 train loss: 878.429, val loss: 8222.332, train acc: 0.957, val acc: 0.384
diff 500.51862332524706
epoch 8 train loss: 913.561, val loss: 9066.853, train acc: 0.956, val acc: 0.380
diff 844.5203746842508
epoch 9 train loss: 1126.070, val loss: 11317.175, train acc: 0.952, val acc: 0.307
diff 2250.3225230185035
epoch 10 train loss: 1137.876, val loss: 8383.297, train acc: 0.954, val acc: 0.366
diff 2933.877590170063
Training model M3
epoch 1 train loss: 3234.749, val loss: 13856.287, train acc: 0.728, val acc: 0.096
diff inf
epoch 2 train loss: 5300.439, val loss: 13301.341, train acc: 0.469, val acc: 0.096
diff 554.9455343922345
epoch 3 train loss: 5293.309, val loss: 13064.249, train acc: 0.474, val acc: 0.096
diff 237.09242219001862
epoch 4 train loss: 5279.806, val loss: 12746.945, train acc: 0.473, val acc: 0.096
diff 317.3033590880714
epoch 5 train loss: 5283.136, val loss: 13623.519, train acc: 0.482, val acc: 0.096
diff 876.5738447905987
epoch 6 train loss: 5271.706, val loss: 12538.433, train acc: 0.483, val acc: 0.096
diff 1085.0866556946803
epoch 7 train loss: 5278.708, val loss: 12282.978, train acc: 0.481, val acc: 0.096
diff 255.45499738434955
epoch 8 train loss: 5253.326, val loss: 13121.951, train acc: 0.490, val acc: 0.096
diff 838.9731954844756
epoch 9 train loss: 5279.268, val loss: 13025.936, train acc: 0.473, val acc: 0.104
diff 96.01459928312397
epoch 10 train loss: 5271.218, val loss: 12710.902, train acc: 0.477, val acc: 0.104
diff 315.0340364260919
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
Training model M3
epoch 1 train loss: 5265.533, val loss: 13838.981, train acc: 0.486, val acc: 0.096
diff inf
epoch 2 train loss: 5265.284, val loss: 13236.814, train acc: 0.466, val acc: 0.096
diff 602.1669761781668
epoch 3 train loss: 5263.676, val loss: 13210.342, train acc: 0.479, val acc: 0.096
diff 26.47185033646565
epoch 4 train loss: 5259.315, val loss: 12736.524, train acc: 0.491, val acc: 0.096
diff 473.8178992421854
epoch 5 train loss: 5262.510, val loss: 13629.731, train acc: 0.486, val acc: 0.096
diff 893.2073486817553
epoch 6 train loss: 5263.930, val loss: 12356.813, train acc: 0.480, val acc: 0.096
diff 1272.9183790240677
epoch 7 train loss: 5264.885, val loss: 12307.852, train acc: 0.481, val acc: 0.096
diff 48.960715419287226
epoch 8 train loss: 5246.203, val loss: 13270.059, train acc: 0.492, val acc: 0.096
diff 962.207217041494
epoch 9 train loss: 5266.725, val loss: 13143.899, train acc: 0.479, val acc: 0.104
diff 126.16024750324686
epoch 10 train loss: 5259.920, val loss: 12750.815, train acc: 0.480, val acc: 0.104
diff 393.08388523320355
training representation using replay loss
training representation using replay loss
training representation using replay loss
