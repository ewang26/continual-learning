Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 13, 'class_balanced': False, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 6456.992, val loss: 672.342, train acc: 0.914, val acc: 0.921
diff inf
epoch 2 train loss: 4314.340, val loss: 798.553, train acc: 0.944, val acc: 0.932
diff 126.21071936864507
epoch 3 train loss: 4373.867, val loss: 806.655, train acc: 0.947, val acc: 0.933
diff 8.102114371837615
epoch 4 train loss: 4261.980, val loss: 376.821, train acc: 0.946, val acc: 0.951
diff 429.8339081762996
epoch 5 train loss: 2723.207, val loss: 409.260, train acc: 0.964, val acc: 0.950
diff 32.43910356287091
epoch 6 train loss: 3084.733, val loss: 386.670, train acc: 0.960, val acc: 0.958
diff 22.590513009229028
epoch 7 train loss: 2809.981, val loss: 386.902, train acc: 0.965, val acc: 0.958
diff 0.2318073307108648
epoch 8 train loss: 2462.994, val loss: 409.587, train acc: 0.967, val acc: 0.956
diff 22.68551434872535
epoch 9 train loss: 2442.381, val loss: 305.408, train acc: 0.968, val acc: 0.962
diff 104.1793166415352
epoch 10 train loss: 2982.891, val loss: 471.049, train acc: 0.966, val acc: 0.950
diff 165.64106734306745
Training model M2
epoch 1 train loss: 10671.441, val loss: 726.065, train acc: 0.884, val acc: 0.934
diff inf
epoch 2 train loss: 6179.033, val loss: 605.854, train acc: 0.932, val acc: 0.943
diff 120.21101890052842
epoch 3 train loss: 5452.401, val loss: 500.064, train acc: 0.941, val acc: 0.949
diff 105.79025287246628
epoch 4 train loss: 4457.101, val loss: 741.087, train acc: 0.950, val acc: 0.933
diff 241.02283057272126
epoch 5 train loss: 4251.117, val loss: 631.403, train acc: 0.954, val acc: 0.947
diff 109.68368129998316
epoch 6 train loss: 4495.592, val loss: 513.035, train acc: 0.952, val acc: 0.953
diff 118.36812370208872
epoch 7 train loss: 8829.821, val loss: 719.181, train acc: 0.910, val acc: 0.941
diff 206.14600352635762
epoch 8 train loss: 5041.170, val loss: 576.267, train acc: 0.948, val acc: 0.945
diff 142.91430079767724
epoch 9 train loss: 6044.747, val loss: 713.108, train acc: 0.942, val acc: 0.934
diff 136.84126455145633
epoch 10 train loss: 4821.128, val loss: 600.589, train acc: 0.950, val acc: 0.952
diff 112.5185527387822
Training model M3
epoch 1 train loss: 5712.298, val loss: 13873.851, train acc: 0.483, val acc: 0.096
diff inf
epoch 2 train loss: 5297.119, val loss: 13283.040, train acc: 0.473, val acc: 0.096
diff 590.8111110366044
epoch 3 train loss: 5289.887, val loss: 14123.740, train acc: 0.478, val acc: 0.096
diff 840.7002046559901
epoch 4 train loss: 5279.597, val loss: 14131.327, train acc: 0.484, val acc: 0.096
diff 7.5869753233109805
epoch 5 train loss: 5299.343, val loss: 13221.674, train acc: 0.481, val acc: 0.096
diff 909.6525669024177
epoch 6 train loss: 5283.961, val loss: 11702.170, train acc: 0.476, val acc: 0.096
diff 1519.5042768690728
epoch 7 train loss: 5289.322, val loss: 12919.429, train acc: 0.478, val acc: 0.096
diff 1217.2586924082952
epoch 8 train loss: 5262.815, val loss: 13307.248, train acc: 0.492, val acc: 0.096
diff 387.81884045366496
epoch 9 train loss: 5292.809, val loss: 13573.733, train acc: 0.476, val acc: 0.104
diff 266.48548866027704
epoch 10 train loss: 5275.329, val loss: 12759.386, train acc: 0.477, val acc: 0.104
diff 814.3468716149855
Training model M3
epoch 1 train loss: 5262.896, val loss: 13806.705, train acc: 0.486, val acc: 0.096
diff inf
epoch 2 train loss: 5263.230, val loss: 13296.628, train acc: 0.466, val acc: 0.104
diff 510.07703114011747
epoch 3 train loss: 5260.790, val loss: 13359.914, train acc: 0.479, val acc: 0.096
diff 63.285745663735725
epoch 4 train loss: 5259.998, val loss: 12784.072, train acc: 0.490, val acc: 0.096
diff 575.8421801397253
epoch 5 train loss: 5262.704, val loss: 13466.874, train acc: 0.486, val acc: 0.096
diff 682.8020008705444
epoch 6 train loss: 5259.075, val loss: 12123.799, train acc: 0.474, val acc: 0.096
diff 1343.0752010117558
epoch 7 train loss: 5263.021, val loss: 12105.548, train acc: 0.478, val acc: 0.096
diff 18.25054408394135
epoch 8 train loss: 5243.194, val loss: 13234.425, train acc: 0.493, val acc: 0.096
diff 1128.8769818009168
epoch 9 train loss: 5266.096, val loss: 13213.851, train acc: 0.481, val acc: 0.104
diff 20.574680186507976
epoch 10 train loss: 5257.657, val loss: 12661.893, train acc: 0.475, val acc: 0.104
diff 551.9577732401103
Training model M3
epoch 1 train loss: 5228.044, val loss: 14069.067, train acc: 0.482, val acc: 0.104
diff inf
epoch 2 train loss: 5227.928, val loss: 13475.929, train acc: 0.468, val acc: 0.104
diff 593.137350670293
epoch 3 train loss: 5223.262, val loss: 13447.079, train acc: 0.484, val acc: 0.096
diff 28.850419219232208
epoch 4 train loss: 5227.507, val loss: 12971.417, train acc: 0.489, val acc: 0.096
diff 475.66206009505004
epoch 5 train loss: 5226.392, val loss: 13680.230, train acc: 0.486, val acc: 0.096
diff 708.8131158195956
epoch 6 train loss: 5224.396, val loss: 12443.809, train acc: 0.479, val acc: 0.096
diff 1236.4210667841944
epoch 7 train loss: 5228.011, val loss: 12358.601, train acc: 0.477, val acc: 0.096
diff 85.2082294997308
epoch 8 train loss: 5211.094, val loss: 13459.048, train acc: 0.496, val acc: 0.096
diff 1100.44700204308
epoch 9 train loss: 5229.888, val loss: 13292.228, train acc: 0.480, val acc: 0.104
diff 166.81919399894832
epoch 10 train loss: 5223.471, val loss: 12940.104, train acc: 0.481, val acc: 0.104
diff 352.12432517741036
