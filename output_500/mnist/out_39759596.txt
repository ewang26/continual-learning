Using CUDA
Running experiment mnist:
Results are stored in: output_500/mnist
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.01, 'batch_size': 60, 'num_centroids': 4, 'model_training_epoch': 10, 'early_stopping_threshold': 0.1, 'random_seed': 14, 'class_balanced': True, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 45354.702, val loss: 4998.341, train acc: 0.128, val acc: 0.109
diff inf
epoch 2 train loss: 44964.179, val loss: 4987.509, train acc: 0.127, val acc: 0.141
diff 10.83125572816789
epoch 3 train loss: 44945.895, val loss: 4994.302, train acc: 0.131, val acc: 0.124
diff 6.792546726858745
epoch 4 train loss: 44949.285, val loss: 4996.237, train acc: 0.126, val acc: 0.124
diff 1.9349596323936566
epoch 5 train loss: 44949.095, val loss: 4990.324, train acc: 0.129, val acc: 0.141
diff 5.912622854288202
epoch 6 train loss: 44938.604, val loss: 5000.967, train acc: 0.127, val acc: 0.124
diff 10.64273453818987
epoch 7 train loss: 44952.246, val loss: 4991.362, train acc: 0.129, val acc: 0.141
diff 9.605410383797789
epoch 8 train loss: 44938.162, val loss: 4994.234, train acc: 0.131, val acc: 0.141
diff 2.872396660191953
epoch 9 train loss: 44945.088, val loss: 4994.460, train acc: 0.128, val acc: 0.121
diff 0.2256045122339856
epoch 10 train loss: 44943.481, val loss: 4989.413, train acc: 0.130, val acc: 0.124
diff 5.047168704762953
Training model M2
epoch 1 train loss: 62765.383, val loss: 6920.691, train acc: 0.099, val acc: 0.097
diff inf
epoch 2 train loss: 62224.964, val loss: 6912.970, train acc: 0.104, val acc: 0.113
diff 7.720992311986265
epoch 3 train loss: 62212.343, val loss: 6908.954, train acc: 0.104, val acc: 0.113
diff 4.0164551546386065
epoch 4 train loss: 62211.131, val loss: 6919.074, train acc: 0.103, val acc: 0.099
diff 10.120379605302332
epoch 5 train loss: 62205.283, val loss: 6915.846, train acc: 0.105, val acc: 0.101
diff 3.2280328097849633
epoch 6 train loss: 62214.910, val loss: 6911.750, train acc: 0.102, val acc: 0.113
diff 4.0965489182253805
epoch 7 train loss: 62216.204, val loss: 6914.878, train acc: 0.105, val acc: 0.099
diff 3.12843829594658
epoch 8 train loss: 62227.571, val loss: 6907.103, train acc: 0.103, val acc: 0.113
diff 7.775433540659833
epoch 9 train loss: 62212.651, val loss: 6909.962, train acc: 0.104, val acc: 0.104
diff 2.8592951102491497
epoch 10 train loss: 62219.863, val loss: 6908.252, train acc: 0.100, val acc: 0.097
diff 1.7102963752322466
Training model M3
epoch 1 train loss: 5780.030, val loss: 13946.434, train acc: 0.478, val acc: 0.096
diff inf
epoch 2 train loss: 5296.289, val loss: 13398.075, train acc: 0.471, val acc: 0.096
diff 548.3589886245591
epoch 3 train loss: 5289.492, val loss: 13982.488, train acc: 0.478, val acc: 0.096
diff 584.4129922346401
epoch 4 train loss: 5279.052, val loss: 14000.063, train acc: 0.484, val acc: 0.096
diff 17.57502254436622
epoch 5 train loss: 5297.842, val loss: 13239.159, train acc: 0.481, val acc: 0.096
diff 760.9031401108386
epoch 6 train loss: 5282.754, val loss: 11753.540, train acc: 0.477, val acc: 0.096
diff 1485.6197403295555
epoch 7 train loss: 5286.768, val loss: 12800.378, train acc: 0.479, val acc: 0.096
diff 1046.8386115943613
epoch 8 train loss: 5259.922, val loss: 13319.471, train acc: 0.492, val acc: 0.096
diff 519.0925888668553
epoch 9 train loss: 5289.291, val loss: 13560.423, train acc: 0.476, val acc: 0.104
diff 240.9522437076139
epoch 10 train loss: 5272.160, val loss: 12683.321, train acc: 0.477, val acc: 0.104
diff 877.1018392288825
Training model M3
epoch 1 train loss: 5259.758, val loss: 13780.073, train acc: 0.487, val acc: 0.096
diff inf
epoch 2 train loss: 5260.762, val loss: 13293.906, train acc: 0.467, val acc: 0.104
diff 486.16723551045106
epoch 3 train loss: 5258.435, val loss: 13159.447, train acc: 0.480, val acc: 0.096
diff 134.45929258953583
epoch 4 train loss: 5258.163, val loss: 12703.315, train acc: 0.489, val acc: 0.096
diff 456.13150750832756
epoch 5 train loss: 5259.763, val loss: 13515.926, train acc: 0.485, val acc: 0.096
diff 812.6104914619118
epoch 6 train loss: 5257.995, val loss: 12162.330, train acc: 0.474, val acc: 0.096
diff 1353.5962288186092
epoch 7 train loss: 5262.217, val loss: 12074.255, train acc: 0.476, val acc: 0.096
diff 88.07505843261242
epoch 8 train loss: 5242.758, val loss: 13211.865, train acc: 0.492, val acc: 0.096
diff 1137.6101068082517
epoch 9 train loss: 5265.672, val loss: 13174.521, train acc: 0.481, val acc: 0.104
diff 37.34346564200496
epoch 10 train loss: 5257.415, val loss: 12660.927, train acc: 0.475, val acc: 0.104
diff 513.5946249799126
Training model M3
epoch 1 train loss: 5254.202, val loss: 13782.770, train acc: 0.483, val acc: 0.104
diff inf
epoch 2 train loss: 5256.220, val loss: 13266.530, train acc: 0.468, val acc: 0.104
diff 516.239167552214
epoch 3 train loss: 5254.300, val loss: 13198.831, train acc: 0.482, val acc: 0.096
diff 67.69926588052476
epoch 4 train loss: 5256.012, val loss: 12675.515, train acc: 0.489, val acc: 0.096
diff 523.3162379169389
epoch 5 train loss: 5255.981, val loss: 13509.013, train acc: 0.485, val acc: 0.096
diff 833.4977039875721
epoch 6 train loss: 5253.985, val loss: 12166.640, train acc: 0.480, val acc: 0.096
diff 1342.3727416758884
epoch 7 train loss: 5258.730, val loss: 12041.029, train acc: 0.477, val acc: 0.096
diff 125.61083480951493
epoch 8 train loss: 5240.144, val loss: 13201.498, train acc: 0.495, val acc: 0.096
diff 1160.468842105558
epoch 9 train loss: 5260.112, val loss: 13109.845, train acc: 0.480, val acc: 0.104
diff 91.65271432373083
epoch 10 train loss: 5253.288, val loss: 12646.918, train acc: 0.480, val acc: 0.104
diff 462.9266955886087
2
2
2
2
