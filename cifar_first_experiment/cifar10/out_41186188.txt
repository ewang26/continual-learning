Using CUDA
Running experiment cifar10:
Results are stored in: cifar_first_experiment/cifar10
with hyperparameters {'p': 0.9, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 100000, 'random_seed': 0, 'class_balanced': True, 'execute_early_stopping': False, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 30713.012, val loss: 2676.907, train acc: 0.466, val acc: 0.596
diff inf
epoch 2 train loss: 22528.150, val loss: 2412.382, train acc: 0.617, val acc: 0.625
diff 264.5242324704677
epoch 3 train loss: 18693.913, val loss: 2278.215, train acc: 0.685, val acc: 0.662
diff 134.1673754915396
epoch 4 train loss: 15537.264, val loss: 2169.698, train acc: 0.741, val acc: 0.679
diff 108.51686080294712
epoch 5 train loss: 12343.190, val loss: 2148.485, train acc: 0.792, val acc: 0.702
diff 21.212937980882543
epoch 6 train loss: 9221.369, val loss: 2438.361, train acc: 0.843, val acc: 0.699
diff 289.87550674970043
epoch 7 train loss: 6730.231, val loss: 2822.671, train acc: 0.888, val acc: 0.694
diff 384.3105984584108
epoch 8 train loss: 5035.904, val loss: 3329.624, train acc: 0.919, val acc: 0.690
diff 506.95280744333377
epoch 9 train loss: 4093.980, val loss: 3266.229, train acc: 0.935, val acc: 0.682
diff 63.394880725861185
epoch 10 train loss: 3453.487, val loss: 4171.358, train acc: 0.943, val acc: 0.670
diff 905.1282967244092
epoch 11 train loss: 3371.046, val loss: 4329.521, train acc: 0.946, val acc: 0.679
diff 158.1636818322222
epoch 12 train loss: 2785.424, val loss: 4424.425, train acc: 0.957, val acc: 0.682
diff 94.90360894828973
epoch 13 train loss: 2855.830, val loss: 5201.774, train acc: 0.956, val acc: 0.687
diff 777.3491219049065
epoch 14 train loss: 2586.818, val loss: 5011.238, train acc: 0.963, val acc: 0.669
diff 190.53605842255547
epoch 15 train loss: 2791.647, val loss: 5040.503, train acc: 0.960, val acc: 0.677
diff 29.264773784211684
epoch 16 train loss: 2315.622, val loss: 5665.479, train acc: 0.967, val acc: 0.672
diff 624.9768112863676
epoch 17 train loss: 2483.856, val loss: 5890.470, train acc: 0.964, val acc: 0.674
diff 224.9906946251067
epoch 18 train loss: 2361.381, val loss: 6525.743, train acc: 0.966, val acc: 0.670
diff 635.2723445598222
epoch 19 train loss: 2274.480, val loss: 6588.123, train acc: 0.969, val acc: 0.672
diff 62.3807071518022
epoch 20 train loss: 2177.484, val loss: 6599.499, train acc: 0.970, val acc: 0.670
diff 11.375984268658613
epoch 21 train loss: 2387.735, val loss: 6421.875, train acc: 0.969, val acc: 0.663
diff 177.6238098009071
epoch 22 train loss: 2457.735, val loss: 6149.869, train acc: 0.969, val acc: 0.684
diff 272.0066030359212
epoch 23 train loss: 1877.232, val loss: 6729.547, train acc: 0.974, val acc: 0.667
diff 579.6779287490072
epoch 24 train loss: 2147.809, val loss: 6767.093, train acc: 0.971, val acc: 0.678
diff 37.546378075668144
epoch 25 train loss: 1927.281, val loss: 7643.856, train acc: 0.974, val acc: 0.663
diff 876.7629689059595
epoch 26 train loss: 2133.810, val loss: 7563.351, train acc: 0.973, val acc: 0.675
diff 80.50508855875978
epoch 27 train loss: 2014.538, val loss: 7840.324, train acc: 0.973, val acc: 0.669
diff 276.9732969209563
epoch 28 train loss: 2111.688, val loss: 7553.448, train acc: 0.974, val acc: 0.666
diff 286.8765920442711
epoch 29 train loss: 1859.740, val loss: 8696.158, train acc: 0.977, val acc: 0.659
diff 1142.7102809328462
epoch 30 train loss: 1995.533, val loss: 8717.700, train acc: 0.974, val acc: 0.668
diff 21.541563867618606
Training model M2
epoch 1 train loss: 40425.024, val loss: 3676.188, train acc: 0.451, val acc: 0.555
diff inf
epoch 2 train loss: 30171.211, val loss: 3257.128, train acc: 0.601, val acc: 0.610
diff 419.06085314004804
epoch 3 train loss: 24159.824, val loss: 3014.038, train acc: 0.684, val acc: 0.657
diff 243.08917280925834
epoch 4 train loss: 19730.660, val loss: 2765.282, train acc: 0.741, val acc: 0.683
diff 248.75603967357347
epoch 5 train loss: 15856.071, val loss: 2820.335, train acc: 0.789, val acc: 0.692
diff 55.05234517110148
epoch 6 train loss: 12346.368, val loss: 2999.223, train acc: 0.839, val acc: 0.685
diff 178.88792761516197
epoch 7 train loss: 9143.312, val loss: 3301.375, train acc: 0.880, val acc: 0.686
diff 302.15212639884203
epoch 8 train loss: 7032.776, val loss: 3985.794, train acc: 0.909, val acc: 0.684
diff 684.4190552622385
epoch 9 train loss: 5601.769, val loss: 4802.068, train acc: 0.929, val acc: 0.669
diff 816.2746503291951
epoch 10 train loss: 5133.122, val loss: 4929.689, train acc: 0.936, val acc: 0.680
diff 127.62066399372725
epoch 11 train loss: 4537.416, val loss: 5310.351, train acc: 0.945, val acc: 0.678
diff 380.6621673481304
epoch 12 train loss: 3890.166, val loss: 6033.423, train acc: 0.952, val acc: 0.685
diff 723.0717199615183
epoch 13 train loss: 4034.414, val loss: 5941.554, train acc: 0.950, val acc: 0.679
diff 91.86859305620965
epoch 14 train loss: 3731.203, val loss: 5708.270, train acc: 0.956, val acc: 0.672
diff 233.28394813438354
epoch 15 train loss: 3768.199, val loss: 6719.299, train acc: 0.955, val acc: 0.680
diff 1011.0285523161283
epoch 16 train loss: 3341.559, val loss: 6917.599, train acc: 0.960, val acc: 0.680
diff 198.29975564646702
epoch 17 train loss: 3439.191, val loss: 7102.716, train acc: 0.961, val acc: 0.668
diff 185.1172841487287
epoch 18 train loss: 3211.859, val loss: 6569.893, train acc: 0.963, val acc: 0.673
diff 532.8232687374511
epoch 19 train loss: 3091.383, val loss: 8683.196, train acc: 0.966, val acc: 0.650
diff 2113.303607506118
epoch 20 train loss: 3303.087, val loss: 7430.649, train acc: 0.965, val acc: 0.669
diff 1252.5470912308701
epoch 21 train loss: 2905.519, val loss: 8072.576, train acc: 0.968, val acc: 0.672
diff 641.9269227486884
epoch 22 train loss: 2856.367, val loss: 8312.214, train acc: 0.969, val acc: 0.686
diff 239.6376828924267
epoch 23 train loss: 3228.614, val loss: 8226.684, train acc: 0.967, val acc: 0.657
diff 85.53022655115092
epoch 24 train loss: 2896.880, val loss: 9312.608, train acc: 0.968, val acc: 0.658
diff 1085.9246392152436
epoch 25 train loss: 3135.419, val loss: 9337.943, train acc: 0.967, val acc: 0.657
diff 25.335158107980533
epoch 26 train loss: 3002.056, val loss: 8630.630, train acc: 0.969, val acc: 0.660
diff 707.3131781244429
epoch 27 train loss: 2805.294, val loss: 9599.100, train acc: 0.973, val acc: 0.667
diff 968.4699550492842
epoch 28 train loss: 3287.421, val loss: 10170.486, train acc: 0.969, val acc: 0.667
diff 571.3860334423971
epoch 29 train loss: 2976.355, val loss: 10855.164, train acc: 0.971, val acc: 0.668
diff 684.6773113184863
epoch 30 train loss: 2848.728, val loss: 9665.503, train acc: 0.972, val acc: 0.667
diff 1189.66040908369
Selecting using KMeansMemorySetManager
Training model M3
epoch 1 train loss: 39108.492, val loss: 3429.667, train acc: 0.465, val acc: 0.592
diff inf
epoch 2 train loss: 28425.212, val loss: 2811.076, train acc: 0.624, val acc: 0.662
diff 618.5907009474231
epoch 3 train loss: 23271.262, val loss: 2364.085, train acc: 0.692, val acc: 0.720
diff 446.99130523447866
epoch 4 train loss: 19449.644, val loss: 2115.115, train acc: 0.744, val acc: 0.758
diff 248.96978907186121
epoch 5 train loss: 16234.105, val loss: 2009.840, train acc: 0.788, val acc: 0.781
diff 105.2745822476038
epoch 6 train loss: 12694.088, val loss: 1716.424, train acc: 0.832, val acc: 0.836
diff 293.4167177887605
epoch 7 train loss: 9907.785, val loss: 1559.376, train acc: 0.871, val acc: 0.861
diff 157.04797793468038
epoch 8 train loss: 7784.049, val loss: 1806.346, train acc: 0.898, val acc: 0.866
diff 246.97017935190547
epoch 9 train loss: 6114.172, val loss: 1901.505, train acc: 0.919, val acc: 0.878
diff 95.15950805587067
epoch 10 train loss: 5238.068, val loss: 1974.855, train acc: 0.933, val acc: 0.887
diff 73.34967978347436
epoch 11 train loss: 4807.434, val loss: 1938.895, train acc: 0.941, val acc: 0.892
diff 35.959836533226735
epoch 12 train loss: 4194.309, val loss: 1914.805, train acc: 0.949, val acc: 0.887
diff 24.08974675225045
epoch 13 train loss: 4195.846, val loss: 1970.565, train acc: 0.949, val acc: 0.901
diff 55.75942831062662
epoch 14 train loss: 3621.611, val loss: 2295.088, train acc: 0.957, val acc: 0.897
diff 324.52321947974565
epoch 15 train loss: 3735.783, val loss: 2343.186, train acc: 0.956, val acc: 0.897
diff 48.0977306094901
epoch 16 train loss: 3572.729, val loss: 2436.436, train acc: 0.958, val acc: 0.894
diff 93.25005175411889
epoch 17 train loss: 3538.389, val loss: 2560.660, train acc: 0.959, val acc: 0.891
diff 124.22378687980563
epoch 18 train loss: 3451.823, val loss: 2249.513, train acc: 0.962, val acc: 0.903
diff 311.1468465212706
epoch 19 train loss: 3257.106, val loss: 2509.271, train acc: 0.964, val acc: 0.906
diff 259.75814482961505
epoch 20 train loss: 3422.126, val loss: 2502.231, train acc: 0.963, val acc: 0.903
diff 7.040363797575083
epoch 21 train loss: 3038.281, val loss: 2452.718, train acc: 0.966, val acc: 0.911
diff 49.513012240357966
epoch 22 train loss: 3369.049, val loss: 2710.934, train acc: 0.965, val acc: 0.899
diff 258.2167360571648
epoch 23 train loss: 3055.825, val loss: 2758.277, train acc: 0.967, val acc: 0.904
diff 47.342615347200535
epoch 24 train loss: 3016.309, val loss: 3012.219, train acc: 0.969, val acc: 0.910
diff 253.94169488772968
epoch 25 train loss: 3221.693, val loss: 2568.259, train acc: 0.967, val acc: 0.910
diff 443.9594598068984
epoch 26 train loss: 2802.145, val loss: 3039.881, train acc: 0.970, val acc: 0.886
diff 471.62211577074913
epoch 27 train loss: 2760.276, val loss: 2818.650, train acc: 0.973, val acc: 0.910
diff 221.23142558883046
epoch 28 train loss: 3254.830, val loss: 3457.984, train acc: 0.968, val acc: 0.888
diff 639.3342761121262
epoch 29 train loss: 2570.680, val loss: 3396.279, train acc: 0.974, val acc: 0.906
diff 61.70468617355118
epoch 30 train loss: 2979.025, val loss: 2797.306, train acc: 0.972, val acc: 0.916
diff 598.9736215959147
Done.
