Using CUDA
Running experiment cifar10:
Results are stored in: cifar_first_experiment/cifar10
with hyperparameters {'p': 0.9, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 100000, 'random_seed': 2, 'class_balanced': True, 'execute_early_stopping': False, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 30213.124, val loss: 2575.518, train acc: 0.478, val acc: 0.587
diff inf
epoch 2 train loss: 21980.089, val loss: 2336.662, train acc: 0.629, val acc: 0.636
diff 238.85568728522412
epoch 3 train loss: 17862.623, val loss: 2224.965, train acc: 0.701, val acc: 0.665
diff 111.69695705858294
epoch 4 train loss: 14371.400, val loss: 2128.651, train acc: 0.760, val acc: 0.688
diff 96.31363168041753
epoch 5 train loss: 10875.867, val loss: 2355.788, train acc: 0.819, val acc: 0.696
diff 227.13605777667226
epoch 6 train loss: 7756.335, val loss: 2406.652, train acc: 0.871, val acc: 0.705
diff 50.864940416274294
epoch 7 train loss: 5444.822, val loss: 3001.019, train acc: 0.911, val acc: 0.709
diff 594.3661427442657
epoch 8 train loss: 4089.745, val loss: 3627.679, train acc: 0.935, val acc: 0.675
diff 626.6600937103863
epoch 9 train loss: 3704.685, val loss: 3814.898, train acc: 0.942, val acc: 0.675
diff 187.21945861478434
epoch 10 train loss: 3083.879, val loss: 4187.344, train acc: 0.952, val acc: 0.686
diff 372.44566373949556
epoch 11 train loss: 2862.516, val loss: 4393.453, train acc: 0.956, val acc: 0.686
diff 206.1087859529771
epoch 12 train loss: 2625.545, val loss: 4696.973, train acc: 0.961, val acc: 0.683
diff 303.51997960242534
epoch 13 train loss: 2902.235, val loss: 4570.625, train acc: 0.958, val acc: 0.690
diff 126.34735508732228
epoch 14 train loss: 2452.441, val loss: 5279.612, train acc: 0.965, val acc: 0.685
diff 708.9866192003356
epoch 15 train loss: 2324.983, val loss: 5060.870, train acc: 0.965, val acc: 0.694
diff 218.74146810114962
epoch 16 train loss: 2359.996, val loss: 5506.981, train acc: 0.966, val acc: 0.683
diff 446.11101110270374
epoch 17 train loss: 2518.366, val loss: 5356.940, train acc: 0.965, val acc: 0.707
diff 150.04147448870663
epoch 18 train loss: 2050.678, val loss: 5596.727, train acc: 0.972, val acc: 0.672
diff 239.78671854973436
epoch 19 train loss: 2419.523, val loss: 6321.114, train acc: 0.968, val acc: 0.669
diff 724.3874122756833
epoch 20 train loss: 2312.489, val loss: 5696.460, train acc: 0.971, val acc: 0.665
diff 624.6542465560424
epoch 21 train loss: 1895.349, val loss: 7191.072, train acc: 0.973, val acc: 0.666
diff 1494.612116835663
epoch 22 train loss: 2228.971, val loss: 7264.642, train acc: 0.971, val acc: 0.680
diff 73.56994855337143
epoch 23 train loss: 1890.126, val loss: 6748.519, train acc: 0.975, val acc: 0.681
diff 516.1232656167449
epoch 24 train loss: 2165.687, val loss: 7204.749, train acc: 0.972, val acc: 0.688
diff 456.2307590228629
epoch 25 train loss: 2353.259, val loss: 6871.284, train acc: 0.971, val acc: 0.682
diff 333.46525808703063
epoch 26 train loss: 1968.013, val loss: 7419.751, train acc: 0.976, val acc: 0.697
diff 548.4668746263405
epoch 27 train loss: 2417.579, val loss: 7436.369, train acc: 0.973, val acc: 0.685
diff 16.618195511555314
epoch 28 train loss: 1917.310, val loss: 7992.640, train acc: 0.976, val acc: 0.672
diff 556.2706144075819
epoch 29 train loss: 1874.261, val loss: 7675.214, train acc: 0.978, val acc: 0.681
diff 317.42578813684486
epoch 30 train loss: 2114.243, val loss: 9157.279, train acc: 0.975, val acc: 0.688
diff 1482.064585026752
Training model M2
epoch 1 train loss: 40458.125, val loss: 3458.134, train acc: 0.446, val acc: 0.582
diff inf
epoch 2 train loss: 29280.588, val loss: 3134.399, train acc: 0.613, val acc: 0.628
diff 323.73417366804324
epoch 3 train loss: 23601.188, val loss: 2772.337, train acc: 0.691, val acc: 0.683
diff 362.0628043723368
epoch 4 train loss: 19292.431, val loss: 2859.867, train acc: 0.748, val acc: 0.679
diff 87.53059061119166
epoch 5 train loss: 15531.424, val loss: 2839.812, train acc: 0.795, val acc: 0.689
diff 20.055522969976664
epoch 6 train loss: 11917.998, val loss: 3124.186, train acc: 0.843, val acc: 0.687
diff 284.3740651005037
epoch 7 train loss: 8953.120, val loss: 3554.930, train acc: 0.884, val acc: 0.689
diff 430.7443807979125
epoch 8 train loss: 7246.425, val loss: 3908.746, train acc: 0.908, val acc: 0.692
diff 353.815492848576
epoch 9 train loss: 5896.559, val loss: 4863.862, train acc: 0.926, val acc: 0.655
diff 955.1166442091835
epoch 10 train loss: 4858.816, val loss: 5395.452, train acc: 0.938, val acc: 0.674
diff 531.589568534604
epoch 11 train loss: 4775.002, val loss: 5894.204, train acc: 0.943, val acc: 0.674
diff 498.75251803374067
epoch 12 train loss: 4384.432, val loss: 5888.151, train acc: 0.948, val acc: 0.681
diff 6.053460203123905
epoch 13 train loss: 4059.400, val loss: 5956.344, train acc: 0.951, val acc: 0.678
diff 68.19327335288563
epoch 14 train loss: 4152.397, val loss: 5953.029, train acc: 0.952, val acc: 0.677
diff 3.3153276918637857
epoch 15 train loss: 3701.596, val loss: 7441.350, train acc: 0.959, val acc: 0.664
diff 1488.3214478831069
epoch 16 train loss: 3751.970, val loss: 7145.372, train acc: 0.957, val acc: 0.666
diff 295.9783070433705
epoch 17 train loss: 3604.152, val loss: 6821.777, train acc: 0.959, val acc: 0.678
diff 323.5953445920977
epoch 18 train loss: 3563.918, val loss: 6807.926, train acc: 0.961, val acc: 0.672
diff 13.850195648200497
epoch 19 train loss: 2988.891, val loss: 7178.726, train acc: 0.966, val acc: 0.674
diff 370.79945176640103
epoch 20 train loss: 3627.385, val loss: 7062.943, train acc: 0.960, val acc: 0.678
diff 115.78259186329615
epoch 21 train loss: 3384.842, val loss: 8397.205, train acc: 0.964, val acc: 0.669
diff 1334.2620238187492
epoch 22 train loss: 3233.105, val loss: 8780.162, train acc: 0.967, val acc: 0.687
diff 382.9565757048513
epoch 23 train loss: 3048.316, val loss: 8682.237, train acc: 0.969, val acc: 0.668
diff 97.92466311382304
epoch 24 train loss: 2873.746, val loss: 8583.844, train acc: 0.969, val acc: 0.666
diff 98.39330022218383
epoch 25 train loss: 3252.155, val loss: 9619.945, train acc: 0.966, val acc: 0.678
diff 1036.101025444228
epoch 26 train loss: 3107.298, val loss: 9509.815, train acc: 0.968, val acc: 0.666
diff 110.13016202224935
epoch 27 train loss: 3232.748, val loss: 8929.759, train acc: 0.968, val acc: 0.686
diff 580.0555283884441
epoch 28 train loss: 2855.686, val loss: 9121.806, train acc: 0.971, val acc: 0.673
diff 192.046568905007
epoch 29 train loss: 2991.832, val loss: 10213.703, train acc: 0.972, val acc: 0.658
diff 1091.8972329526787
epoch 30 train loss: 3265.882, val loss: 10373.245, train acc: 0.970, val acc: 0.682
diff 159.54199775413872
Selecting using KMeansMemorySetManager
Training model M3
epoch 1 train loss: 39874.272, val loss: 3670.644, train acc: 0.455, val acc: 0.563
diff inf
epoch 2 train loss: 29870.577, val loss: 2895.273, train acc: 0.603, val acc: 0.651
diff 775.3710716638766
epoch 3 train loss: 24692.990, val loss: 2505.012, train acc: 0.672, val acc: 0.701
diff 390.26067785490795
epoch 4 train loss: 20799.948, val loss: 2152.693, train acc: 0.724, val acc: 0.746
diff 352.31882666058436
epoch 5 train loss: 17394.611, val loss: 2000.553, train acc: 0.771, val acc: 0.782
diff 152.14031363595745
epoch 6 train loss: 14315.477, val loss: 1811.547, train acc: 0.811, val acc: 0.807
diff 189.00567752260486
epoch 7 train loss: 11380.690, val loss: 1742.636, train acc: 0.851, val acc: 0.839
diff 68.91080975839668
epoch 8 train loss: 9025.584, val loss: 1554.669, train acc: 0.879, val acc: 0.866
diff 187.96746585280675
epoch 9 train loss: 7381.691, val loss: 1728.734, train acc: 0.903, val acc: 0.871
diff 174.064741827312
epoch 10 train loss: 6091.439, val loss: 1879.306, train acc: 0.922, val acc: 0.873
diff 150.57251982497314
epoch 11 train loss: 5275.267, val loss: 2083.597, train acc: 0.932, val acc: 0.875
diff 204.29050654285152
epoch 12 train loss: 5002.026, val loss: 2029.463, train acc: 0.939, val acc: 0.879
diff 54.13351142329634
epoch 13 train loss: 4628.925, val loss: 1813.946, train acc: 0.943, val acc: 0.884
diff 215.51776509177898
epoch 14 train loss: 4146.002, val loss: 2118.301, train acc: 0.950, val acc: 0.888
diff 304.355339913089
epoch 15 train loss: 4267.047, val loss: 2073.228, train acc: 0.950, val acc: 0.907
diff 45.07311978211101
epoch 16 train loss: 3854.854, val loss: 2409.954, train acc: 0.955, val acc: 0.881
diff 336.7261910338102
epoch 17 train loss: 3855.852, val loss: 2369.247, train acc: 0.954, val acc: 0.896
diff 40.70685386983405
epoch 18 train loss: 3559.343, val loss: 2523.493, train acc: 0.958, val acc: 0.895
diff 154.24552686831885
epoch 19 train loss: 3911.505, val loss: 2343.696, train acc: 0.956, val acc: 0.902
diff 179.79679628870008
epoch 20 train loss: 3689.681, val loss: 2723.037, train acc: 0.959, val acc: 0.888
diff 379.3412446917873
epoch 21 train loss: 3515.356, val loss: 2878.385, train acc: 0.961, val acc: 0.892
diff 155.34796068375908
epoch 22 train loss: 3313.302, val loss: 2346.426, train acc: 0.964, val acc: 0.891
diff 531.9593247067232
epoch 23 train loss: 3348.539, val loss: 2794.020, train acc: 0.963, val acc: 0.896
diff 447.59397716155763
epoch 24 train loss: 3691.080, val loss: 2876.105, train acc: 0.962, val acc: 0.883
diff 82.08501891652986
epoch 25 train loss: 3223.130, val loss: 3161.528, train acc: 0.964, val acc: 0.887
diff 285.4237857467224
epoch 26 train loss: 3083.837, val loss: 3122.551, train acc: 0.968, val acc: 0.896
diff 38.97768453909657
epoch 27 train loss: 3455.728, val loss: 2783.300, train acc: 0.965, val acc: 0.898
diff 339.25089966822
epoch 28 train loss: 3153.042, val loss: 3331.316, train acc: 0.969, val acc: 0.883
diff 548.016253534578
epoch 29 train loss: 3298.796, val loss: 3304.431, train acc: 0.966, val acc: 0.895
diff 26.884889570004816
epoch 30 train loss: 2989.235, val loss: 3826.902, train acc: 0.969, val acc: 0.889
diff 522.4709628382652
Done.
