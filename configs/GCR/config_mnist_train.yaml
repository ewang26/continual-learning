# WandB stuff, change according to user
use_wandb: False
wandb_project_name: continuallearning
wandb_profile: alanhsu


# Memory set hyperparameters
memory_set_manager: random
use_memory_set: True # never false
grad_type: None
p: dummar_var
use_random_img: False
num_ideal_models: None
#num_samples: 10

# for gradient evaluating
# p_arr: [0.001, 0.005]
# #num_samples: [10, 10, 10, 10, 10, 10, 10, 10, 10]
# num_samples: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

#testing configuration
p_arr: [0.001]
num_samples: [1] # if training, use only 1 sample

#debugging 
train_debug: False

# Continual learning hyperparameters
learning_manager: mnist_split
#learning_manager: cifar10_split

# Training hyperparameters
lr: 0.001
batch_size: 256
random_seed: 0xC0FFEE
epochs: 50
#epochs: 30

# Model arch 
model:
 type: mlp 
 params: 
   sizes: [784, 100, 10] 
   acts: [relu]

#Example CNN
# model: 
#   type: cnn
#   params: 
#     in_channels: 3 
#     out_channels: 10
#     l1_out_channels: 32
#     l2_out_channels: 32
#     l3_out_channels: 64
#     l4_out_channels: 64


model_save_dir: models/mnist_split #/1/
#model_save_dir: models/mnist_split/ideal_model
#model_save_dir: models/cifar10_split
#model_load_dir: models/mnist_split
#model_load_dir: models/cifar10_split