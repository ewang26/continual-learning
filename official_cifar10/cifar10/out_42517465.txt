Using CUDA
Running experiment cifar10:
Results are stored in: official_cifar10/cifar10
with hyperparameters {'p': 0.2, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 4, 'class_balanced': True, 'execute_early_stopping': False, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 31513.551, val loss: 2814.641, train acc: 0.453, val acc: 0.560
diff inf
epoch 2 train loss: 23120.487, val loss: 2322.676, train acc: 0.610, val acc: 0.642
diff 491.9648940972079
epoch 3 train loss: 18665.670, val loss: 2199.630, train acc: 0.688, val acc: 0.668
diff 123.04574563456572
epoch 4 train loss: 15020.577, val loss: 2154.095, train acc: 0.749, val acc: 0.683
diff 45.5347701687092
epoch 5 train loss: 11613.415, val loss: 2217.707, train acc: 0.808, val acc: 0.702
diff 63.61213955614403
epoch 6 train loss: 8203.218, val loss: 2531.719, train acc: 0.865, val acc: 0.691
diff 314.0111709795342
epoch 7 train loss: 5673.170, val loss: 3026.112, train acc: 0.907, val acc: 0.692
diff 494.3929835549402
epoch 8 train loss: 4417.314, val loss: 3748.576, train acc: 0.929, val acc: 0.672
diff 722.464107617237
epoch 9 train loss: 3547.556, val loss: 3926.199, train acc: 0.944, val acc: 0.685
diff 177.6229630286075
epoch 10 train loss: 3298.230, val loss: 4336.236, train acc: 0.949, val acc: 0.661
diff 410.03763715669356
epoch 11 train loss: 2951.444, val loss: 4416.404, train acc: 0.954, val acc: 0.674
diff 80.16827282819304
epoch 12 train loss: 2614.494, val loss: 4710.485, train acc: 0.962, val acc: 0.663
diff 294.0807057108532
epoch 13 train loss: 2723.102, val loss: 5051.430, train acc: 0.960, val acc: 0.682
diff 340.9446370908954
epoch 14 train loss: 2500.508, val loss: 5541.403, train acc: 0.964, val acc: 0.684
diff 489.9727470313637
epoch 15 train loss: 2124.267, val loss: 5362.362, train acc: 0.967, val acc: 0.680
diff 179.040244283221
epoch 16 train loss: 2554.844, val loss: 5282.215, train acc: 0.965, val acc: 0.680
diff 80.14750658884441
epoch 17 train loss: 2252.232, val loss: 5757.758, train acc: 0.968, val acc: 0.665
diff 475.5435090636902
epoch 18 train loss: 1986.830, val loss: 7099.814, train acc: 0.972, val acc: 0.674
diff 1342.0560672642996
epoch 19 train loss: 2287.301, val loss: 6419.294, train acc: 0.969, val acc: 0.677
diff 680.5203905654271
epoch 20 train loss: 1999.537, val loss: 7403.026, train acc: 0.973, val acc: 0.667
diff 983.7320845049335
epoch 21 train loss: 2048.803, val loss: 6790.054, train acc: 0.973, val acc: 0.675
diff 612.9722970729799
epoch 22 train loss: 2117.006, val loss: 6972.502, train acc: 0.973, val acc: 0.668
diff 182.44820278274983
epoch 23 train loss: 1908.440, val loss: 7662.651, train acc: 0.975, val acc: 0.660
diff 690.1492408117674
epoch 24 train loss: 2080.903, val loss: 7677.866, train acc: 0.973, val acc: 0.660
diff 15.214621638237077
epoch 25 train loss: 2419.216, val loss: 8590.031, train acc: 0.972, val acc: 0.671
diff 912.1653155483882
epoch 26 train loss: 1765.639, val loss: 8301.547, train acc: 0.977, val acc: 0.659
diff 288.4841174670619
epoch 27 train loss: 2174.733, val loss: 8446.016, train acc: 0.973, val acc: 0.665
diff 144.46886743522737
epoch 28 train loss: 1695.715, val loss: 8085.904, train acc: 0.978, val acc: 0.675
diff 360.1118401658232
epoch 29 train loss: 1929.027, val loss: 8423.168, train acc: 0.977, val acc: 0.666
diff 337.2636145731476
epoch 30 train loss: 1974.411, val loss: 8964.852, train acc: 0.976, val acc: 0.672
diff 541.684627648212
Training model M2
epoch 1 train loss: 40052.048, val loss: 3423.240, train acc: 0.452, val acc: 0.577
diff inf
epoch 2 train loss: 28754.415, val loss: 3333.002, train acc: 0.620, val acc: 0.594
diff 90.23820765033497
epoch 3 train loss: 22809.486, val loss: 2756.611, train acc: 0.703, val acc: 0.677
diff 576.390895018832
epoch 4 train loss: 18170.425, val loss: 2924.932, train acc: 0.760, val acc: 0.672
diff 168.32071761018324
epoch 5 train loss: 14031.143, val loss: 3074.500, train acc: 0.816, val acc: 0.679
diff 149.56805554541415
epoch 6 train loss: 10565.960, val loss: 3484.980, train acc: 0.861, val acc: 0.674
diff 410.48017747463246
epoch 7 train loss: 7564.935, val loss: 3906.449, train acc: 0.901, val acc: 0.690
diff 421.46949603647454
epoch 8 train loss: 6122.765, val loss: 4342.668, train acc: 0.921, val acc: 0.694
diff 436.21826266465405
epoch 9 train loss: 5313.796, val loss: 4816.915, train acc: 0.935, val acc: 0.686
diff 474.2472833935726
epoch 10 train loss: 4613.999, val loss: 5091.338, train acc: 0.944, val acc: 0.683
diff 274.4234873876667
epoch 11 train loss: 4389.507, val loss: 5620.934, train acc: 0.946, val acc: 0.686
diff 529.5952375992711
epoch 12 train loss: 4120.234, val loss: 5632.688, train acc: 0.952, val acc: 0.693
diff 11.753831245728179
epoch 13 train loss: 3988.907, val loss: 6156.429, train acc: 0.953, val acc: 0.694
diff 523.7413365738566
epoch 14 train loss: 3565.918, val loss: 6379.714, train acc: 0.957, val acc: 0.696
diff 223.2852639072089
epoch 15 train loss: 3705.008, val loss: 6781.231, train acc: 0.959, val acc: 0.685
diff 401.51722885776144
epoch 16 train loss: 3366.936, val loss: 6963.078, train acc: 0.963, val acc: 0.679
diff 181.8467712854963
epoch 17 train loss: 3565.691, val loss: 6670.998, train acc: 0.961, val acc: 0.677
diff 292.08034219170713
epoch 18 train loss: 3499.692, val loss: 6911.179, train acc: 0.962, val acc: 0.672
diff 240.1816643125012
epoch 19 train loss: 3028.213, val loss: 7727.213, train acc: 0.966, val acc: 0.683
diff 816.0338487920108
epoch 20 train loss: 3321.398, val loss: 8411.910, train acc: 0.964, val acc: 0.669
diff 684.6966836031979
epoch 21 train loss: 3210.048, val loss: 7917.262, train acc: 0.966, val acc: 0.681
diff 494.6479116202627
epoch 22 train loss: 3079.509, val loss: 7855.909, train acc: 0.967, val acc: 0.690
diff 61.35298968762436
epoch 23 train loss: 3143.888, val loss: 8477.317, train acc: 0.968, val acc: 0.677
diff 621.4080882837479
epoch 24 train loss: 2943.218, val loss: 8088.587, train acc: 0.970, val acc: 0.682
diff 388.73034205128897
epoch 25 train loss: 3446.238, val loss: 8265.023, train acc: 0.965, val acc: 0.688
diff 176.43613533069765
epoch 26 train loss: 2737.438, val loss: 8729.585, train acc: 0.973, val acc: 0.677
diff 464.56188203362944
epoch 27 train loss: 3254.787, val loss: 9177.144, train acc: 0.967, val acc: 0.669
diff 447.55886889929025
epoch 28 train loss: 2893.931, val loss: 9772.711, train acc: 0.972, val acc: 0.681
diff 595.5676684415484
epoch 29 train loss: 2933.148, val loss: 9984.270, train acc: 0.972, val acc: 0.681
diff 211.5582398487204
epoch 30 train loss: 3047.376, val loss: 9675.478, train acc: 0.971, val acc: 0.673
diff 308.7917816335921
Selecting using RandomMemorySetManager
RandomMemorySetManager
Start time: 2024-08-04 10:51:00
Training model M3
epoch 1 train loss: 15003.320, val loss: 4672.562, train acc: 0.481, val acc: 0.415
diff inf
epoch 2 train loss: 11235.073, val loss: 4599.820, train acc: 0.618, val acc: 0.471
diff 72.74218381844912
epoch 3 train loss: 9292.767, val loss: 3781.378, train acc: 0.684, val acc: 0.544
diff 818.4418757774929
epoch 4 train loss: 7782.363, val loss: 3822.516, train acc: 0.733, val acc: 0.573
diff 41.13867587607001
epoch 5 train loss: 5953.336, val loss: 3416.454, train acc: 0.795, val acc: 0.631
diff 406.0623239282895
epoch 6 train loss: 4266.348, val loss: 4022.733, train acc: 0.853, val acc: 0.628
diff 606.2785189029082
epoch 7 train loss: 2780.221, val loss: 4547.524, train acc: 0.903, val acc: 0.640
diff 524.7913875402064
epoch 8 train loss: 1959.485, val loss: 5454.829, train acc: 0.934, val acc: 0.628
diff 907.3047394094874
epoch 9 train loss: 1427.318, val loss: 5339.254, train acc: 0.953, val acc: 0.655
diff 115.57447011121167
epoch 10 train loss: 1266.322, val loss: 6642.846, train acc: 0.959, val acc: 0.637
diff 1303.5913613498597
epoch 11 train loss: 1009.033, val loss: 6842.040, train acc: 0.968, val acc: 0.643
diff 199.19474528224964
epoch 12 train loss: 1005.927, val loss: 7349.945, train acc: 0.969, val acc: 0.630
diff 507.90499411116616
epoch 13 train loss: 911.312, val loss: 7704.568, train acc: 0.971, val acc: 0.633
diff 354.6231151052043
epoch 14 train loss: 914.269, val loss: 7312.292, train acc: 0.971, val acc: 0.645
diff 392.27625007574807
epoch 15 train loss: 705.851, val loss: 7476.832, train acc: 0.978, val acc: 0.644
diff 164.5396608867104
epoch 16 train loss: 973.176, val loss: 8956.924, train acc: 0.972, val acc: 0.607
diff 1480.0922314051822
epoch 17 train loss: 703.772, val loss: 7858.350, train acc: 0.980, val acc: 0.646
diff 1098.5742361234988
epoch 18 train loss: 712.740, val loss: 8909.875, train acc: 0.979, val acc: 0.633
diff 1051.5246919922465
epoch 19 train loss: 810.852, val loss: 8516.402, train acc: 0.977, val acc: 0.639
diff 393.4727653808477
epoch 20 train loss: 736.173, val loss: 9606.038, train acc: 0.979, val acc: 0.627
diff 1089.6361963457184
epoch 21 train loss: 597.447, val loss: 9570.243, train acc: 0.982, val acc: 0.633
diff 35.79525155488591
epoch 22 train loss: 649.397, val loss: 9816.800, train acc: 0.981, val acc: 0.635
diff 246.5573571565983
epoch 23 train loss: 643.546, val loss: 8891.882, train acc: 0.982, val acc: 0.647
diff 924.9177825053212
epoch 24 train loss: 597.130, val loss: 9785.753, train acc: 0.984, val acc: 0.650
diff 893.8709035122538
epoch 25 train loss: 786.215, val loss: 9848.212, train acc: 0.978, val acc: 0.632
diff 62.45859696363732
epoch 26 train loss: 466.461, val loss: 10568.134, train acc: 0.986, val acc: 0.632
diff 719.9224259640869
epoch 27 train loss: 737.388, val loss: 11773.998, train acc: 0.982, val acc: 0.620
diff 1205.8637346386586
epoch 28 train loss: 755.764, val loss: 13478.316, train acc: 0.979, val acc: 0.612
diff 1704.3182337101262
epoch 29 train loss: 782.266, val loss: 12262.928, train acc: 0.981, val acc: 0.615
diff 1215.3885587367513
epoch 30 train loss: 550.426, val loss: 12374.696, train acc: 0.987, val acc: 0.626
diff 111.76875821240719
End time: 2024-08-04 11:39:11
Time to complete: 00:48:11.70
Selecting using KMeansMemorySetManager
KMeansMemorySetManager
Start time: 2024-08-04 11:39:11
Training model M3
epoch 1 train loss: 7146.839, val loss: 3743.885, train acc: 0.818, val acc: 0.652
diff inf
epoch 2 train loss: 3219.055, val loss: 5998.062, train acc: 0.896, val acc: 0.647
diff 2254.1768322902053
epoch 3 train loss: 1800.418, val loss: 6915.492, train acc: 0.943, val acc: 0.681
diff 917.430714058647
epoch 4 train loss: 1302.016, val loss: 8599.648, train acc: 0.958, val acc: 0.652
diff 1684.1559610952754
epoch 5 train loss: 984.373, val loss: 7891.626, train acc: 0.969, val acc: 0.689
diff 708.0220252587733
epoch 6 train loss: 759.805, val loss: 8931.140, train acc: 0.976, val acc: 0.678
diff 1039.5131808749302
epoch 7 train loss: 831.924, val loss: 11492.502, train acc: 0.976, val acc: 0.651
diff 2561.3626710431327
epoch 8 train loss: 738.099, val loss: 15645.959, train acc: 0.976, val acc: 0.624
diff 4153.456579344764
epoch 9 train loss: 653.514, val loss: 12278.762, train acc: 0.982, val acc: 0.662
diff 3367.196461880636
epoch 10 train loss: 541.406, val loss: 15946.796, train acc: 0.983, val acc: 0.629
diff 3668.033804429342
epoch 11 train loss: 763.977, val loss: 12460.161, train acc: 0.980, val acc: 0.649
diff 3486.6351027960573
epoch 12 train loss: 677.284, val loss: 14129.916, train acc: 0.982, val acc: 0.647
diff 1669.7545507589275
epoch 13 train loss: 626.792, val loss: 14591.787, train acc: 0.983, val acc: 0.636
diff 461.8714623484084
epoch 14 train loss: 480.095, val loss: 22681.548, train acc: 0.987, val acc: 0.585
diff 8089.761179560823
epoch 15 train loss: 690.150, val loss: 15079.567, train acc: 0.985, val acc: 0.632
diff 7601.9814147441575
epoch 16 train loss: 444.105, val loss: 15805.259, train acc: 0.988, val acc: 0.649
diff 725.6924892421466
epoch 17 train loss: 521.655, val loss: 18570.263, train acc: 0.985, val acc: 0.626
diff 2765.003761893624
epoch 18 train loss: 610.325, val loss: 16920.444, train acc: 0.982, val acc: 0.635
diff 1649.8191132469146
epoch 19 train loss: 592.086, val loss: 16438.359, train acc: 0.984, val acc: 0.628
diff 482.0850853601296
epoch 20 train loss: 570.393, val loss: 15286.868, train acc: 0.985, val acc: 0.628
diff 1151.4909130066007
epoch 21 train loss: 430.590, val loss: 18378.535, train acc: 0.989, val acc: 0.628
diff 3091.6669497215335
epoch 22 train loss: 496.077, val loss: 23353.962, train acc: 0.986, val acc: 0.605
diff 4975.426687940086
epoch 23 train loss: 315.027, val loss: 22062.607, train acc: 0.991, val acc: 0.616
diff 1291.3548843337412
epoch 24 train loss: 643.131, val loss: 21741.232, train acc: 0.985, val acc: 0.611
diff 321.37452751614546
epoch 25 train loss: 565.364, val loss: 19658.456, train acc: 0.986, val acc: 0.628
diff 2082.776516260641
epoch 26 train loss: 684.644, val loss: 20578.557, train acc: 0.986, val acc: 0.627
diff 920.1013822579953
epoch 27 train loss: 280.270, val loss: 19945.335, train acc: 0.993, val acc: 0.633
diff 633.221754254635
epoch 28 train loss: 698.264, val loss: 23451.989, train acc: 0.984, val acc: 0.605
diff 3506.6539269283276
epoch 29 train loss: 351.372, val loss: 23476.071, train acc: 0.990, val acc: 0.615
diff 24.0819203912979
epoch 30 train loss: 330.686, val loss: 23005.910, train acc: 0.991, val acc: 0.626
diff 470.16136922308215
End time: 2024-08-04 12:24:47
Time to complete: 00:45:36.10
Selecting using LambdaMemorySetManager
LambdaMemorySetManager
Start time: 2024-08-04 12:24:47
Training model M3
epoch 1 train loss: 13293.882, val loss: 3391.951, train acc: 0.716, val acc: 0.646
diff inf
epoch 2 train loss: 5874.693, val loss: 2898.660, train acc: 0.816, val acc: 0.720
diff 493.2917637065193
epoch 3 train loss: 3024.714, val loss: 3071.342, train acc: 0.899, val acc: 0.766
diff 172.68274773419307
epoch 4 train loss: 1573.295, val loss: 3442.679, train acc: 0.950, val acc: 0.779
diff 371.33652470378684
epoch 5 train loss: 1237.234, val loss: 3816.622, train acc: 0.961, val acc: 0.787
diff 373.9434841385496
epoch 6 train loss: 1091.526, val loss: 4396.206, train acc: 0.965, val acc: 0.777
diff 579.5836427785771
epoch 7 train loss: 660.677, val loss: 5084.382, train acc: 0.979, val acc: 0.771
diff 688.17538137269
epoch 8 train loss: 971.351, val loss: 5737.241, train acc: 0.971, val acc: 0.777
diff 652.8596259077385
epoch 9 train loss: 673.707, val loss: 5663.443, train acc: 0.981, val acc: 0.769
diff 73.79856749503506
epoch 10 train loss: 847.433, val loss: 5868.518, train acc: 0.976, val acc: 0.770
diff 205.07555774475168
epoch 11 train loss: 476.966, val loss: 6092.341, train acc: 0.985, val acc: 0.767
diff 223.82264751517323
epoch 12 train loss: 776.938, val loss: 5781.426, train acc: 0.980, val acc: 0.761
diff 310.9150751775178
epoch 13 train loss: 523.039, val loss: 6721.077, train acc: 0.985, val acc: 0.767
diff 939.651699436472
epoch 14 train loss: 649.096, val loss: 7528.200, train acc: 0.982, val acc: 0.761
diff 807.1225404638863
epoch 15 train loss: 549.565, val loss: 6409.209, train acc: 0.984, val acc: 0.762
diff 1118.9912563663092
epoch 16 train loss: 557.117, val loss: 6605.659, train acc: 0.986, val acc: 0.763
diff 196.45019966857035
epoch 17 train loss: 460.301, val loss: 8453.288, train acc: 0.985, val acc: 0.768
diff 1847.6291179965774
epoch 18 train loss: 749.450, val loss: 7891.732, train acc: 0.981, val acc: 0.770
diff 561.5556886877948
epoch 19 train loss: 698.541, val loss: 6897.675, train acc: 0.982, val acc: 0.770
diff 994.0570498915722
epoch 20 train loss: 355.068, val loss: 7478.435, train acc: 0.990, val acc: 0.782
diff 580.7601190095456
epoch 21 train loss: 380.266, val loss: 9536.657, train acc: 0.989, val acc: 0.767
diff 2058.221812810825
epoch 22 train loss: 834.927, val loss: 8700.990, train acc: 0.980, val acc: 0.767
diff 835.6670016580465
epoch 23 train loss: 472.849, val loss: 9541.809, train acc: 0.988, val acc: 0.765
diff 840.8188068025611
epoch 24 train loss: 847.056, val loss: 9466.849, train acc: 0.983, val acc: 0.765
diff 74.96047967079903
epoch 25 train loss: 458.040, val loss: 9060.159, train acc: 0.988, val acc: 0.773
diff 406.6898817608417
epoch 26 train loss: 786.506, val loss: 11727.700, train acc: 0.983, val acc: 0.737
diff 2667.5408959799606
epoch 27 train loss: 679.165, val loss: 10186.365, train acc: 0.984, val acc: 0.773
diff 1541.3343299990047
epoch 28 train loss: 348.286, val loss: 9297.839, train acc: 0.991, val acc: 0.759
diff 888.5260492731632
epoch 29 train loss: 679.712, val loss: 10931.680, train acc: 0.985, val acc: 0.749
diff 1633.8411118526546
epoch 30 train loss: 754.679, val loss: 9296.293, train acc: 0.982, val acc: 0.769
diff 1635.3870053658193
End time: 2024-08-04 13:10:38
Time to complete: 00:45:50.77
Selecting using iCaRL
iCaRL (icarl)
Start time: 2024-08-04 13:10:38
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
training representation using icarl loss
Training model M3
epoch 1 train loss: 11696.606, val loss: 3176.490, train acc: 0.767, val acc: 0.713
diff inf
epoch 2 train loss: 4534.981, val loss: 2922.649, train acc: 0.859, val acc: 0.752
diff 253.8405101455387
epoch 3 train loss: 2337.981, val loss: 3142.754, train acc: 0.926, val acc: 0.771
diff 220.104831879421
epoch 4 train loss: 1634.514, val loss: 3371.149, train acc: 0.948, val acc: 0.783
diff 228.39535878927518
epoch 5 train loss: 1084.230, val loss: 3525.445, train acc: 0.965, val acc: 0.795
diff 154.2961428438739
epoch 6 train loss: 874.845, val loss: 3779.124, train acc: 0.973, val acc: 0.797
diff 253.67902719826452
epoch 7 train loss: 957.248, val loss: 4414.370, train acc: 0.971, val acc: 0.801
diff 635.2458478071385
epoch 8 train loss: 1037.010, val loss: 4462.301, train acc: 0.971, val acc: 0.781
diff 47.93112201351687
epoch 9 train loss: 494.850, val loss: 4823.089, train acc: 0.985, val acc: 0.804
diff 360.78760030263584
epoch 10 train loss: 711.502, val loss: 5204.977, train acc: 0.981, val acc: 0.777
diff 381.8878621689755
epoch 11 train loss: 751.835, val loss: 5294.753, train acc: 0.981, val acc: 0.746
diff 89.77615118822814
epoch 12 train loss: 685.139, val loss: 5538.345, train acc: 0.980, val acc: 0.799
diff 243.5921285348004
epoch 13 train loss: 612.252, val loss: 5947.853, train acc: 0.985, val acc: 0.782
diff 409.50733859415686
epoch 14 train loss: 740.780, val loss: 6506.109, train acc: 0.982, val acc: 0.771
diff 558.2568413306517
epoch 15 train loss: 854.118, val loss: 5796.044, train acc: 0.980, val acc: 0.782
diff 710.0654724629985
epoch 16 train loss: 441.282, val loss: 6949.912, train acc: 0.989, val acc: 0.780
diff 1153.8676271600953
epoch 17 train loss: 879.195, val loss: 7322.707, train acc: 0.980, val acc: 0.750
diff 372.79536439944786
epoch 18 train loss: 650.822, val loss: 7047.582, train acc: 0.984, val acc: 0.775
diff 275.1252867448229
epoch 19 train loss: 609.796, val loss: 6944.898, train acc: 0.988, val acc: 0.761
diff 102.68390084678322
epoch 20 train loss: 848.528, val loss: 6720.734, train acc: 0.984, val acc: 0.763
diff 224.16418763658749
epoch 21 train loss: 630.970, val loss: 7566.129, train acc: 0.985, val acc: 0.763
diff 845.3958297712306
epoch 22 train loss: 608.755, val loss: 7457.317, train acc: 0.986, val acc: 0.763
diff 108.8121476921524
epoch 23 train loss: 885.103, val loss: 7321.680, train acc: 0.983, val acc: 0.769
diff 135.63723340599427
epoch 24 train loss: 619.388, val loss: 7144.744, train acc: 0.986, val acc: 0.760
diff 176.93564169093588
epoch 25 train loss: 416.737, val loss: 7574.472, train acc: 0.992, val acc: 0.748
diff 429.72741623982256
epoch 26 train loss: 884.412, val loss: 8797.153, train acc: 0.984, val acc: 0.759
diff 1222.6811686842539
epoch 27 train loss: 781.957, val loss: 9286.047, train acc: 0.985, val acc: 0.748
diff 488.8941530938191
epoch 28 train loss: 640.157, val loss: 8105.467, train acc: 0.989, val acc: 0.749
diff 1180.579979438242
epoch 29 train loss: 725.303, val loss: 7568.353, train acc: 0.986, val acc: 0.763
diff 537.1143973097505
epoch 30 train loss: 461.228, val loss: 7831.759, train acc: 0.992, val acc: 0.756
diff 263.40635483134884
End time: 2024-08-04 15:54:47
Time to complete: 02:44:09.18
Selecting using iCaRL
iCaRL (replay)
Start time: 2024-08-04 15:54:47
training representation using replay loss
training representation using replay loss
