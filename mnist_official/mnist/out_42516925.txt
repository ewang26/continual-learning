Using CPU
Running experiment mnist:
Results are stored in: mnist_official/mnist
with hyperparameters {'p': 0.5, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 1000000, 'random_seed': 0, 'class_balanced': True, 'execute_early_stopping': False, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 6457.438, val loss: 677.027, train acc: 0.905, val acc: 0.916
diff inf
epoch 2 train loss: 3595.675, val loss: 360.441, train acc: 0.947, val acc: 0.956
diff 316.5862004202927
epoch 3 train loss: 2736.557, val loss: 382.301, train acc: 0.961, val acc: 0.958
diff 21.859961198077087
epoch 4 train loss: 2422.738, val loss: 308.849, train acc: 0.965, val acc: 0.963
diff 73.45111975543352
epoch 5 train loss: 2100.118, val loss: 301.023, train acc: 0.970, val acc: 0.966
diff 7.825973234251478
epoch 6 train loss: 1744.924, val loss: 403.866, train acc: 0.974, val acc: 0.962
diff 102.8420961312516
epoch 7 train loss: 1691.541, val loss: 326.148, train acc: 0.976, val acc: 0.965
diff 77.71782604696
epoch 8 train loss: 1504.997, val loss: 451.044, train acc: 0.979, val acc: 0.950
diff 124.89625834160984
epoch 9 train loss: 1509.100, val loss: 341.705, train acc: 0.978, val acc: 0.969
diff 109.33910839322272
epoch 10 train loss: 1364.019, val loss: 262.645, train acc: 0.980, val acc: 0.973
diff 79.06019408588776
epoch 11 train loss: 1270.026, val loss: 274.384, train acc: 0.982, val acc: 0.976
diff 11.739733994267112
epoch 12 train loss: 1293.527, val loss: 322.595, train acc: 0.981, val acc: 0.969
diff 48.21039393408773
epoch 13 train loss: 1076.606, val loss: 301.384, train acc: 0.984, val acc: 0.972
diff 21.211022767486384
epoch 14 train loss: 1179.293, val loss: 260.998, train acc: 0.983, val acc: 0.978
diff 40.38562102811528
epoch 15 train loss: 1103.260, val loss: 278.288, train acc: 0.984, val acc: 0.970
diff 17.289969433027807
epoch 16 train loss: 890.691, val loss: 357.530, train acc: 0.988, val acc: 0.973
diff 79.2418404448444
epoch 17 train loss: 1043.981, val loss: 305.970, train acc: 0.986, val acc: 0.977
diff 51.56034229155165
epoch 18 train loss: 1029.870, val loss: 385.352, train acc: 0.985, val acc: 0.972
diff 79.38274088935657
epoch 19 train loss: 884.392, val loss: 449.511, train acc: 0.987, val acc: 0.971
diff 64.15908804908997
epoch 20 train loss: 1029.071, val loss: 344.073, train acc: 0.986, val acc: 0.975
diff 105.43854558790946
epoch 21 train loss: 890.198, val loss: 461.230, train acc: 0.988, val acc: 0.966
diff 117.15667812042136
epoch 22 train loss: 962.585, val loss: 398.981, train acc: 0.987, val acc: 0.972
diff 62.24903226293242
epoch 23 train loss: 933.910, val loss: 471.129, train acc: 0.988, val acc: 0.966
diff 72.14891662132885
epoch 24 train loss: 810.500, val loss: 383.136, train acc: 0.990, val acc: 0.970
diff 87.99318465230152
epoch 25 train loss: 824.041, val loss: 675.571, train acc: 0.989, val acc: 0.971
diff 292.4351646484745
epoch 26 train loss: 857.855, val loss: 681.150, train acc: 0.990, val acc: 0.966
diff 5.578675631108695
epoch 27 train loss: 907.226, val loss: 586.180, train acc: 0.990, val acc: 0.972
diff 94.96964565546682
epoch 28 train loss: 760.053, val loss: 467.230, train acc: 0.990, val acc: 0.977
diff 118.95066882847811
epoch 29 train loss: 857.710, val loss: 396.621, train acc: 0.990, val acc: 0.977
diff 70.60890163241129
epoch 30 train loss: 694.303, val loss: 604.542, train acc: 0.991, val acc: 0.970
diff 207.9213732867288
Training model M2
epoch 1 train loss: 11075.761, val loss: 758.575, train acc: 0.870, val acc: 0.923
diff inf
epoch 2 train loss: 6176.702, val loss: 702.256, train acc: 0.930, val acc: 0.932
diff 56.31914123177205
epoch 3 train loss: 5028.183, val loss: 613.386, train acc: 0.943, val acc: 0.940
diff 88.8702974567218
epoch 4 train loss: 4441.998, val loss: 573.907, train acc: 0.950, val acc: 0.949
diff 39.47879037534733
epoch 5 train loss: 3909.573, val loss: 584.067, train acc: 0.955, val acc: 0.946
diff 10.159921679095646
epoch 6 train loss: 3531.865, val loss: 570.653, train acc: 0.958, val acc: 0.949
diff 13.41366533345331
epoch 7 train loss: 3246.356, val loss: 517.519, train acc: 0.963, val acc: 0.958
diff 53.13463585032605
epoch 8 train loss: 3059.168, val loss: 546.180, train acc: 0.965, val acc: 0.958
diff 28.661633277425153
epoch 9 train loss: 2851.237, val loss: 472.393, train acc: 0.967, val acc: 0.961
diff 73.78685875593493
epoch 10 train loss: 2725.139, val loss: 523.741, train acc: 0.969, val acc: 0.953
diff 51.3478571549021
epoch 11 train loss: 2603.965, val loss: 569.021, train acc: 0.969, val acc: 0.955
diff 45.28025081379792
epoch 12 train loss: 2414.437, val loss: 582.045, train acc: 0.972, val acc: 0.954
diff 13.023825798938333
epoch 13 train loss: 2335.872, val loss: 822.566, train acc: 0.972, val acc: 0.933
diff 240.52092634616815
epoch 14 train loss: 2230.964, val loss: 695.392, train acc: 0.974, val acc: 0.952
diff 127.17405293351703
epoch 15 train loss: 2132.495, val loss: 705.011, train acc: 0.977, val acc: 0.952
diff 9.61898121841375
epoch 16 train loss: 2213.002, val loss: 659.356, train acc: 0.975, val acc: 0.955
diff 45.654717819637085
