Using CUDA
Running experiment cifar10:
Results are stored in: output_500_new/cifar10
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 0.1, 'random_seed': 4, 'class_balanced': True, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 31513.551, val loss: 2814.641, train acc: 0.453, val acc: 0.560
diff inf
epoch 2 train loss: 23120.487, val loss: 2322.676, train acc: 0.610, val acc: 0.642
diff 491.9648940972079
epoch 3 train loss: 18665.670, val loss: 2199.630, train acc: 0.688, val acc: 0.668
diff 123.04574563456572
epoch 4 train loss: 15020.577, val loss: 2154.095, train acc: 0.749, val acc: 0.683
diff 45.5347701687092
epoch 5 train loss: 11613.415, val loss: 2217.707, train acc: 0.808, val acc: 0.702
diff 63.61213955614403
epoch 6 train loss: 8203.218, val loss: 2531.719, train acc: 0.865, val acc: 0.691
diff 314.0111709795342
epoch 7 train loss: 5673.170, val loss: 3026.112, train acc: 0.907, val acc: 0.692
diff 494.3929835549402
epoch 8 train loss: 4417.314, val loss: 3748.576, train acc: 0.929, val acc: 0.672
diff 722.464107617237
epoch 9 train loss: 3547.556, val loss: 3926.199, train acc: 0.944, val acc: 0.685
diff 177.6229630286075
