Using CUDA
Running experiment cifar10:
Results are stored in: output_500_new/cifar10
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 0.1, 'random_seed': 5, 'class_balanced': True, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 30949.548, val loss: 2772.024, train acc: 0.464, val acc: 0.551
diff inf
epoch 2 train loss: 22586.413, val loss: 2361.212, train acc: 0.621, val acc: 0.647
diff 410.8118117834392
epoch 3 train loss: 18143.281, val loss: 2178.878, train acc: 0.694, val acc: 0.673
diff 182.33433993746485
epoch 4 train loss: 14383.345, val loss: 2182.693, train acc: 0.763, val acc: 0.673
diff 3.8147746691179236
epoch 5 train loss: 10812.895, val loss: 2456.641, train acc: 0.821, val acc: 0.677
diff 273.9478467930435
epoch 6 train loss: 7487.716, val loss: 2919.578, train acc: 0.874, val acc: 0.672
diff 462.9378304829088
epoch 7 train loss: 5434.910, val loss: 3435.810, train acc: 0.914, val acc: 0.675
diff 516.2317101848439
epoch 8 train loss: 4109.735, val loss: 3917.163, train acc: 0.935, val acc: 0.666
diff 481.3529273708068
