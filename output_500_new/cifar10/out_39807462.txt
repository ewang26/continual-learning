Using CUDA
Running experiment cifar10:
Results are stored in: output_500_new/cifar10
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 0.1, 'random_seed': 3, 'class_balanced': True, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 31002.529, val loss: 2720.981, train acc: 0.463, val acc: 0.566
diff inf
epoch 2 train loss: 22875.345, val loss: 2412.854, train acc: 0.614, val acc: 0.631
diff 308.1270348512958
epoch 3 train loss: 18606.746, val loss: 2185.177, train acc: 0.691, val acc: 0.667
diff 227.6772730844409
epoch 4 train loss: 14824.921, val loss: 2167.385, train acc: 0.753, val acc: 0.685
diff 17.792247041295468
epoch 5 train loss: 11318.973, val loss: 2455.976, train acc: 0.813, val acc: 0.684
diff 288.591558921029
epoch 6 train loss: 8105.658, val loss: 2697.816, train acc: 0.864, val acc: 0.679
diff 241.83932791709913
epoch 7 train loss: 5700.279, val loss: 3227.019, train acc: 0.908, val acc: 0.678
diff 529.2035721528491
epoch 8 train loss: 4366.836, val loss: 3653.312, train acc: 0.930, val acc: 0.674
diff 426.2925127452604
epoch 9 train loss: 3496.277, val loss: 3991.446, train acc: 0.944, val acc: 0.664
diff 338.1346911889277
epoch 10 train loss: 2909.297, val loss: 4316.509, train acc: 0.956, val acc: 0.671
diff 325.0624797754849
epoch 11 train loss: 2694.272, val loss: 5187.996, train acc: 0.959, val acc: 0.661
diff 871.4872146516209
epoch 12 train loss: 2943.737, val loss: 4843.392, train acc: 0.958, val acc: 0.670
diff 344.60445323521526
epoch 13 train loss: 2623.944, val loss: 5158.387, train acc: 0.961, val acc: 0.677
diff 314.9955628421403
epoch 14 train loss: 2422.579, val loss: 6386.916, train acc: 0.964, val acc: 0.658
diff 1228.5291211548338
epoch 15 train loss: 2453.944, val loss: 6045.860, train acc: 0.965, val acc: 0.659
diff 341.05616450816797
epoch 16 train loss: 2074.205, val loss: 6056.771, train acc: 0.971, val acc: 0.664
diff 10.910518202781532
epoch 17 train loss: 2349.534, val loss: 5944.472, train acc: 0.967, val acc: 0.657
diff 112.29808348405822
epoch 18 train loss: 2118.774, val loss: 6458.038, train acc: 0.971, val acc: 0.659
diff 513.5654580743403
epoch 19 train loss: 2361.346, val loss: 6415.514, train acc: 0.968, val acc: 0.668
diff 42.52372680713779
epoch 20 train loss: 2201.058, val loss: 6567.992, train acc: 0.971, val acc: 0.657
diff 152.47782292099873
epoch 21 train loss: 2015.230, val loss: 7074.017, train acc: 0.974, val acc: 0.660
diff 506.025026608002
epoch 22 train loss: 1768.801, val loss: 7149.779, train acc: 0.975, val acc: 0.664
diff 75.76227059670782
epoch 23 train loss: 1940.275, val loss: 7468.076, train acc: 0.975, val acc: 0.662
diff 318.2969407521614
epoch 24 train loss: 1899.211, val loss: 7188.351, train acc: 0.976, val acc: 0.666
diff 279.72502797993457
epoch 25 train loss: 2002.378, val loss: 7466.361, train acc: 0.976, val acc: 0.675
diff 278.01000814598046
epoch 26 train loss: 2047.407, val loss: 8243.722, train acc: 0.974, val acc: 0.654
diff 777.3605250202718
epoch 27 train loss: 1796.822, val loss: 8471.744, train acc: 0.978, val acc: 0.670
diff 228.02241466805208
epoch 28 train loss: 2179.632, val loss: 7660.519, train acc: 0.973, val acc: 0.666
diff 811.2256065044758
epoch 29 train loss: 1823.709, val loss: 7947.853, train acc: 0.978, val acc: 0.662
diff 287.3339771004612
