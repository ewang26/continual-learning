Using CUDA
Running experiment cifar10:
Results are stored in: output_500_new/cifar10
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 0.1, 'random_seed': 7, 'class_balanced': True, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 30806.183, val loss: 2697.474, train acc: 0.465, val acc: 0.576
diff inf
epoch 2 train loss: 22612.308, val loss: 2371.880, train acc: 0.616, val acc: 0.628
diff 325.5936722528545
epoch 3 train loss: 18471.843, val loss: 2207.146, train acc: 0.688, val acc: 0.671
diff 164.73435255850063
epoch 4 train loss: 14951.801, val loss: 2145.764, train acc: 0.751, val acc: 0.680
diff 61.38202549474954
epoch 5 train loss: 11628.933, val loss: 2297.571, train acc: 0.807, val acc: 0.666
diff 151.80684460672137
epoch 6 train loss: 8206.476, val loss: 2548.696, train acc: 0.864, val acc: 0.682
diff 251.1252300515057
epoch 7 train loss: 5834.046, val loss: 2943.174, train acc: 0.903, val acc: 0.703
diff 394.47865502792183
epoch 8 train loss: 4269.094, val loss: 3635.338, train acc: 0.930, val acc: 0.671
diff 692.1633739262352
epoch 9 train loss: 3778.689, val loss: 4122.244, train acc: 0.941, val acc: 0.672
diff 486.90633962209495
epoch 10 train loss: 3343.500, val loss: 4096.480, train acc: 0.948, val acc: 0.681
diff 25.763669137405486
epoch 11 train loss: 3097.775, val loss: 4794.878, train acc: 0.954, val acc: 0.676
diff 698.3971825430508
epoch 12 train loss: 2660.494, val loss: 5357.323, train acc: 0.958, val acc: 0.655
diff 562.4458548649282
epoch 13 train loss: 2741.037, val loss: 5445.446, train acc: 0.958, val acc: 0.680
diff 88.12235329145915
epoch 14 train loss: 2448.435, val loss: 5150.751, train acc: 0.966, val acc: 0.671
diff 294.6946212326393
epoch 15 train loss: 2564.209, val loss: 5739.216, train acc: 0.962, val acc: 0.670
diff 588.4646243720754
epoch 16 train loss: 2375.239, val loss: 5685.995, train acc: 0.964, val acc: 0.672
diff 53.22130058126368
epoch 17 train loss: 2328.321, val loss: 6230.197, train acc: 0.968, val acc: 0.676
diff 544.2019553362143
epoch 18 train loss: 2310.156, val loss: 6138.084, train acc: 0.969, val acc: 0.671
diff 92.11201193178749
epoch 19 train loss: 2259.607, val loss: 6480.656, train acc: 0.969, val acc: 0.675
diff 342.57159728828265
epoch 20 train loss: 2202.909, val loss: 6602.588, train acc: 0.970, val acc: 0.667
diff 121.93215413943926
epoch 21 train loss: 2342.319, val loss: 6857.666, train acc: 0.970, val acc: 0.675
diff 255.07737278470813
epoch 22 train loss: 2165.129, val loss: 6815.195, train acc: 0.972, val acc: 0.675
diff 42.470774008894296
epoch 23 train loss: 2193.083, val loss: 6608.922, train acc: 0.972, val acc: 0.665
diff 206.2724616255855
epoch 24 train loss: 1881.302, val loss: 7061.405, train acc: 0.975, val acc: 0.681
diff 452.48304691785233
