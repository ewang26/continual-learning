Using CUDA
Running experiment cifar10:
Results are stored in: output_500_new/cifar10
with hyperparameters {'p': 0.01, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 0.1, 'random_seed': 7, 'class_balanced': True, 'exp_name': 'cifar10'}


Files already downloaded and verified
Files already downloaded and verified
task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 30806.183, val loss: 2697.474, train acc: 0.465, val acc: 0.576
diff inf
epoch 2 train loss: 22612.308, val loss: 2371.880, train acc: 0.616, val acc: 0.628
diff 325.5936722528545
epoch 3 train loss: 18471.843, val loss: 2207.146, train acc: 0.688, val acc: 0.671
diff 164.73435255850063
epoch 4 train loss: 14951.801, val loss: 2145.764, train acc: 0.751, val acc: 0.680
diff 61.38202549474954
epoch 5 train loss: 11628.933, val loss: 2297.571, train acc: 0.807, val acc: 0.666
diff 151.80684460672137
epoch 6 train loss: 8206.476, val loss: 2548.696, train acc: 0.864, val acc: 0.682
diff 251.1252300515057
