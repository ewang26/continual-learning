Using CUDA
Running experiment mnist:
Results are stored in: output_500_new/mnist
with hyperparameters {'p': 0.05, 'T': 5, 'learning_rate': 0.001, 'batch_size': 50, 'num_centroids': 4, 'model_training_epoch': 30, 'early_stopping_threshold': 0.1, 'random_seed': 19, 'class_balanced': True, 'exp_name': 'mnist'}


task 0, classes 0, 1
task 1, classes 2, 3
task 2, classes 4, 5
task 3, classes 6, 7
task 4, classes 8, 9
Training models M1 and M2
Training model M1
epoch 1 train loss: 2581.645, val loss: 128.726, train acc: 0.964, val acc: 0.982
diff inf
epoch 2 train loss: 776.277, val loss: 119.953, train acc: 0.989, val acc: 0.988
diff 8.77245172822387
epoch 3 train loss: 470.566, val loss: 143.835, train acc: 0.993, val acc: 0.985
diff 23.882253879470795
epoch 4 train loss: 391.915, val loss: 94.535, train acc: 0.995, val acc: 0.993
diff 49.30033355658219
epoch 5 train loss: 343.675, val loss: 114.515, train acc: 0.995, val acc: 0.991
diff 19.980206873918675
epoch 6 train loss: 183.470, val loss: 142.540, train acc: 0.997, val acc: 0.988
diff 28.024698064908776
epoch 7 train loss: 212.309, val loss: 177.586, train acc: 0.997, val acc: 0.989
diff 35.04627608313976
epoch 8 train loss: 137.535, val loss: 255.927, train acc: 0.998, val acc: 0.982
diff 78.34089534678282
epoch 9 train loss: 229.711, val loss: 214.889, train acc: 0.997, val acc: 0.985
diff 41.03793007985391
epoch 10 train loss: 63.396, val loss: 174.088, train acc: 0.999, val acc: 0.990
diff 40.80079035393726
epoch 11 train loss: 168.583, val loss: 264.908, train acc: 0.998, val acc: 0.988
diff 90.81946175597429
epoch 12 train loss: 141.008, val loss: 216.000, train acc: 0.998, val acc: 0.990
diff 48.90810153174158
epoch 13 train loss: 114.577, val loss: 377.474, train acc: 0.999, val acc: 0.985
diff 161.4737689726037
epoch 14 train loss: 167.622, val loss: 209.875, train acc: 0.999, val acc: 0.993
diff 167.59827621412308
epoch 15 train loss: 125.867, val loss: 362.304, train acc: 0.999, val acc: 0.985
diff 152.42919343868465
epoch 16 train loss: 148.979, val loss: 309.592, train acc: 0.999, val acc: 0.992
diff 52.71212935999063
epoch 17 train loss: 171.014, val loss: 312.270, train acc: 0.998, val acc: 0.991
diff 2.677513266672463
epoch 18 train loss: 158.434, val loss: 255.983, train acc: 0.998, val acc: 0.991
diff 56.28631640423396
epoch 19 train loss: 174.490, val loss: 398.529, train acc: 0.998, val acc: 0.987
diff 142.5454990575127
epoch 20 train loss: 102.761, val loss: 324.230, train acc: 0.999, val acc: 0.989
diff 74.29863600625157
epoch 21 train loss: 107.139, val loss: 348.217, train acc: 0.999, val acc: 0.990
diff 23.98655439810858
epoch 22 train loss: 152.368, val loss: 426.483, train acc: 0.999, val acc: 0.987
diff 78.26586022051009
epoch 23 train loss: 116.525, val loss: 259.271, train acc: 0.999, val acc: 0.992
diff 167.21162995556557
epoch 24 train loss: 51.686, val loss: 304.319, train acc: 1.000, val acc: 0.992
diff 45.047625799513355
epoch 25 train loss: 167.742, val loss: 287.162, train acc: 0.999, val acc: 0.991
diff 17.156381645106478
epoch 26 train loss: 45.271, val loss: 352.308, train acc: 1.000, val acc: 0.992
diff 65.14533624335883
epoch 27 train loss: 82.015, val loss: 377.925, train acc: 0.999, val acc: 0.992
diff 25.61693635488797
